{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (f) Noise regularization\n",
    "### Learning images of letters after learning images of digits + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.cuda as cuda\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "try:\n",
    "    import accimage\n",
    "except ImportError:\n",
    "    accimage = None\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from SpykeTorch import snn\n",
    "from SpykeTorch import functional as sf\n",
    "from SpykeTorch import visualization as vis\n",
    "from SpykeTorch import utils\n",
    "\n",
    "import struct\n",
    "import glob\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rule\n",
    "\n",
    "class STDP(nn.Module):\n",
    "    def __init__(self, conv_layer, learning_rate, eps_std_percent=0.0, \\\n",
    "                 use_stabilizer = True, lower_bound = 0, upper_bound = 1):\n",
    "        super(STDP, self).__init__()\n",
    "        self.conv_layer = conv_layer\n",
    "        if isinstance(learning_rate, list):\n",
    "            self.learning_rate = learning_rate\n",
    "        else:\n",
    "            self.learning_rate = [learning_rate] * conv_layer.out_channels\n",
    "        for i in range(conv_layer.out_channels):\n",
    "            self.learning_rate[i] = (Parameter(torch.tensor([self.learning_rate[i][0]])),\n",
    "                            Parameter(torch.tensor([self.learning_rate[i][1]])))\n",
    "            self.register_parameter('ltp_' + str(i), self.learning_rate[i][0])\n",
    "            self.register_parameter('ltd_' + str(i), self.learning_rate[i][1])\n",
    "            self.learning_rate[i][0].requires_grad_(False)\n",
    "            self.learning_rate[i][1].requires_grad_(False)\n",
    "        self.use_stabilizer = use_stabilizer\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "        self.eps_std_percent = eps_std_percent\n",
    "\n",
    "    def get_pre_post_ordering(self, input_spikes, output_spikes, winners):\n",
    "\n",
    "        # accumulating input and output spikes to get latencies\n",
    "        input_latencies = torch.sum(input_spikes, dim=0)\n",
    "        output_latencies = torch.sum(output_spikes, dim=0)\n",
    "        result = []\n",
    "        for winner in winners:\n",
    "            # generating repeated output tensor with the same size of the receptive field\n",
    "            out_tensor = torch.ones(*self.conv_layer.kernel_size, device=output_latencies.device) * output_latencies[winner]\n",
    "            # slicing input tensor with the same size of the receptive field centered around winner\n",
    "            # since there is no padding, there is no need to shift it to the center\n",
    "            in_tensor = input_latencies[:,winner[-2]:winner[-2]+self.conv_layer.kernel_size[-2],winner[-1]:winner[-1]+self.conv_layer.kernel_size[-1]]\n",
    "            result.append(torch.ge(in_tensor,out_tensor))\n",
    "        return result\n",
    "\n",
    "    # the simple STDP rule was supplemented with noise: \n",
    "    # eps_std_percent - %% standard deviation of random small addition to learning rate\n",
    "    # gets prepost pairings, winners, weights, and learning rates (all shoud be tensors)        \n",
    "    def forward(self, input_spikes, potentials, output_spikes, winners=None, kwta = 1, inhibition_radius = 0):\n",
    "        if winners is None:\n",
    "            winners = sf.get_k_winners(potentials, kwta, inhibition_radius, output_spikes)\n",
    "        \n",
    "        pairings = self.get_pre_post_ordering(input_spikes, output_spikes, winners)\n",
    "\n",
    "        lr = torch.zeros_like(self.conv_layer.weight)\n",
    "        epsilon = torch.torch.zeros_like(lr)\n",
    "        \n",
    "        for i in range(len(winners)):\n",
    "            \n",
    "            f = winners[i][0]            \n",
    "            \n",
    "            lr_0 = self.learning_rate[f][0].item()\n",
    "            lr_1 = self.learning_rate[f][1].item()\n",
    "            \n",
    "            eps_std_0 = np.abs(lr_0) * self.eps_std_percent # standard deviation of random small addition to learning_rate_0\n",
    "            eps_std_1 = np.abs(lr_1) * self.eps_std_percent # standard deviation of random small addition to learning_rate_1\n",
    "\n",
    "            if eps_std_0 == 0:\n",
    "                eps_0 = torch.zeros(1).cuda()\n",
    "            else:\n",
    "                eps_0 = torch.normal(mean=torch.zeros(1).cuda(), std=eps_std_0)\n",
    "                \n",
    "            if eps_std_1 == 0:\n",
    "                eps_1 = torch.zeros(1).cuda()\n",
    "            else:\n",
    "                eps_1 = torch.normal(mean=torch.zeros(1).cuda(), std=eps_std_1)\n",
    "            \n",
    "            learning_rate_0 = torch.nn.Parameter(torch.ones(1).cuda()*lr_0 + eps_0, requires_grad=False)\n",
    "            learning_rate_1 = torch.nn.Parameter(torch.ones(1).cuda()*lr_1 + eps_1, requires_grad=False)\n",
    "            \n",
    "            two_learning_rate = (learning_rate_0, learning_rate_1)\n",
    "            lr[f] = torch.where(pairings[i], *(two_learning_rate))\n",
    "\n",
    "        self.conv_layer.weight += \\\n",
    "        lr * ((self.conv_layer.weight-self.lower_bound) * (self.upper_bound-self.conv_layer.weight) \\\n",
    "              if self.use_stabilizer else 1) \n",
    "        self.conv_layer.weight.clamp_(self.lower_bound, self.upper_bound)\n",
    "\n",
    "    def update_learning_rate(self, feature, ap, an):\n",
    "        self.learning_rate[feature][0][0] = ap\n",
    "        self.learning_rate[feature][1][0] = an\n",
    "\n",
    "    def update_all_learning_rate(self, ap, an):\n",
    "        for feature in range(self.conv_layer.out_channels):\n",
    "            self.learning_rate[feature][0][0] = ap\n",
    "            self.learning_rate[feature][1][0] = an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class MozafariMNIST2018(nn.Module):\n",
    "    \n",
    "    def __init__(self, eps_std_percent=0.0):\n",
    "        \n",
    "        super(MozafariMNIST2018, self).__init__()\n",
    "\n",
    "        self.conv1 = snn.Convolution(6, 30, 5, 0.8, 0.05)\n",
    "        self.conv1_t = 15\n",
    "        self.k1 = 5\n",
    "        self.r1 = 3\n",
    "\n",
    "        self.conv2 = snn.Convolution(30, 250, 3, 0.8, 0.05)\n",
    "        self.conv2_t = 10\n",
    "        self.k2 = 8\n",
    "        self.r2 = 1\n",
    "\n",
    "        self.conv3 = snn.Convolution(250, 200, 5, 0.8, 0.05)\n",
    "        \n",
    "        self.eps_std_percent = eps_std_percent\n",
    "\n",
    "        self.stdp1 = STDP(self.conv1, (0.004, -0.003))\n",
    "        self.stdp2 = STDP(self.conv2, (0.004, -0.003))\n",
    "        self.stdp3 = STDP(self.conv3, (0.004, -0.003), self.eps_std_percent, False, 0.2, 0.8)\n",
    "        self.anti_stdp3 = STDP(self.conv3, (-0.004, 0.0005), self.eps_std_percent, False, 0.2, 0.8)\n",
    "        self.max_ap = Parameter(torch.Tensor([0.15]))\n",
    "\n",
    "        self.decision_map = []\n",
    "        for i in range(10):\n",
    "            self.decision_map.extend([i]*20)\n",
    "\n",
    "        self.ctx = {\"input_spikes\":None, \"potentials\":None, \"output_spikes\":None, \"winners\":None}\n",
    "        self.spk_cnt1 = 0\n",
    "        self.spk_cnt2 = 0\n",
    "\n",
    "    def forward(self, input, max_layer):\n",
    "        \n",
    "        input = sf.pad(input.float(), (2,2,2,2), 0)\n",
    "        \n",
    "        if self.training:\n",
    "            pot = self.conv1(input)\n",
    "            spk, pot = sf.fire(pot, self.conv1_t, True)\n",
    "            if max_layer == 1:\n",
    "                self.spk_cnt1 += 1\n",
    "                if self.spk_cnt1 >= 500:\n",
    "                    self.spk_cnt1 = 0\n",
    "                    ap = torch.tensor(self.stdp1.learning_rate[0][0].item(), device=self.stdp1.learning_rate[0][0].device) * 2\n",
    "                    ap = torch.min(ap, self.max_ap)\n",
    "                    an = ap * -0.75\n",
    "                    self.stdp1.update_all_learning_rate(ap.item(), an.item())\n",
    "                pot = sf.pointwise_inhibition(pot)\n",
    "                spk = pot.sign()\n",
    "                winners = sf.get_k_winners(pot, self.k1, self.r1, spk)\n",
    "                self.ctx[\"input_spikes\"] = input\n",
    "                self.ctx[\"potentials\"] = pot\n",
    "                self.ctx[\"output_spikes\"] = spk\n",
    "                self.ctx[\"winners\"] = winners\n",
    "                return spk, pot\n",
    "            \n",
    "            spk_in = sf.pad(sf.pooling(spk, 2, 2), (1,1,1,1))\n",
    "            pot = self.conv2(spk_in)\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "            if max_layer == 2:\n",
    "                self.spk_cnt2 += 1\n",
    "                if self.spk_cnt2 >= 500:\n",
    "                    self.spk_cnt2 = 0\n",
    "                    ap = torch.tensor(self.stdp2.learning_rate[0][0].item(), device=self.stdp2.learning_rate[0][0].device) * 2\n",
    "                    ap = torch.min(ap, self.max_ap)\n",
    "                    an = ap * -0.75\n",
    "                    self.stdp2.update_all_learning_rate(ap.item(), an.item())\n",
    "                pot = sf.pointwise_inhibition(pot)\n",
    "                spk = pot.sign()\n",
    "                winners = sf.get_k_winners(pot, self.k2, self.r2, spk)\n",
    "                self.ctx[\"input_spikes\"] = spk_in\n",
    "                self.ctx[\"potentials\"] = pot\n",
    "                self.ctx[\"output_spikes\"] = spk\n",
    "                self.ctx[\"winners\"] = winners\n",
    "                return spk, pot\n",
    "            \n",
    "            spk_in = sf.pad(sf.pooling(spk, 3, 3), (2,2,2,2))\n",
    "            pot = self.conv3(spk_in)\n",
    "            spk = sf.fire(pot)\n",
    "            winners = sf.get_k_winners(pot, 1, 0, spk)\n",
    "            self.ctx[\"input_spikes\"] = spk_in\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            output = -1\n",
    "            if len(winners) != 0:\n",
    "                output = self.decision_map[winners[0][0]]\n",
    "            return output\n",
    "        \n",
    "        else:\n",
    "            pot = self.conv1(input)\n",
    "            spk, pot = sf.fire(pot, self.conv1_t, True)\n",
    "            if max_layer == 1:\n",
    "                return spk, pot\n",
    "            \n",
    "            pot = self.conv2(sf.pad(sf.pooling(spk, 2, 2), (1,1,1,1)))\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "            if max_layer == 2:\n",
    "                return spk, pot\n",
    "            pot = self.conv3(sf.pad(sf.pooling(spk, 3, 3), (2,2,2,2)))\n",
    "            spk = sf.fire(pot)\n",
    "            winners = sf.get_k_winners(pot, 1, 0, spk)\n",
    "            output = -1\n",
    "            if len(winners) != 0:\n",
    "                output = self.decision_map[winners[0][0]]\n",
    "            return output\n",
    "\n",
    "    def stdp(self, layer_idx):\n",
    "        if layer_idx == 1:\n",
    "            self.stdp1(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 2:\n",
    "            self.stdp2(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "\n",
    "    def update_learning_rates(self, stdp_ap, stdp_an, anti_stdp_ap, anti_stdp_an):\n",
    "        self.stdp3.update_all_learning_rate(stdp_ap, stdp_an)\n",
    "        self.anti_stdp3.update_all_learning_rate(anti_stdp_an, anti_stdp_ap)\n",
    "\n",
    "    def reward(self):\n",
    "        self.stdp3(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "\n",
    "    def punish(self):\n",
    "        self.anti_stdp3(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test\n",
    "\n",
    "def train_unsupervise(network, data, layer_idx):\n",
    "    network.train()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "        network(data_in, layer_idx)\n",
    "        network.stdp(layer_idx)\n",
    "\n",
    "def train_rl(network, data, target):\n",
    "    network.train()\n",
    "    perf = np.array([0,0,0]) # correct, wrong, silence\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        target_in = target[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "            target_in = target_in.cuda()\n",
    "        d = network(data_in, 3)\n",
    "        if d != -1:\n",
    "            if d == target_in:\n",
    "                perf[0]+=1\n",
    "                network.reward()\n",
    "            else:\n",
    "                perf[1]+=1\n",
    "                network.punish()\n",
    "        else:\n",
    "            perf[2]+=1\n",
    "    return perf/len(data)\n",
    "\n",
    "def test(network, data, target):\n",
    "    network.eval()\n",
    "    perf = np.array([0,0,0]) # correct, wrong, silence\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        target_in = target[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "            target_in = target_in.cuda()\n",
    "        d = network(data_in, 3)\n",
    "        if d != -1:\n",
    "            if d == target_in:\n",
    "                perf[0]+=1\n",
    "            else:\n",
    "                perf[1]+=1\n",
    "        else:\n",
    "            perf[2]+=1\n",
    "    return perf/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_graph(parametr_set):\n",
    "\n",
    "    plt.subplots(figsize=(15, 5))\n",
    "\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['train']*100, color='cyan', label='train')\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['test']*100, color='blue', marker = 'o', label='test')\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['test_previous']*100, linestyle = ':', color='red', label='test of previous images')\n",
    "    plt.xlabel('epochs', loc='right', fontsize=17)\n",
    "    plt.ylabel('accuracy, %',  loc='top', fontsize=17)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training of the 3rd layer\n",
    "\n",
    "def third_layer(file_name_net, file_name_csv, adaptive_int, previous_epochs, epochs, \n",
    "                train_loader, test_loader, test_previous_loader,\n",
    "                model, apr, anr, app, anp, parametr_set, steps=None, percent=20, it_continues=False):  \n",
    "    \n",
    "    '''\n",
    "    file_name_net - name of file for saving state_dict of model\n",
    "    file_name_csv - name of file for saving parameters of model in each epoch\n",
    "    adaptive_int - learning rate parameter\n",
    "    previous_epochs - if before model had training in current period\n",
    "    it_continues - is it continue of 3-rd layer training or not (False or True)\n",
    "    percent - percent of moving weights (calculated from the number of high range weights)\n",
    "    '''\n",
    "\n",
    "    adaptive_min=0 \n",
    "\n",
    "    if not it_continues:\n",
    "\n",
    "        previous_epochs = 0\n",
    "        counter = 0\n",
    "\n",
    "        apr_adapt = ((1.0 - 1.0 / 10) * adaptive_int + adaptive_min) * apr\n",
    "        anr_adapt = ((1.0 - 1.0 / 10) * adaptive_int + adaptive_min) * anr\n",
    "        app_adapt = ((1.0 / 10) * adaptive_int + adaptive_min) * app\n",
    "        anp_adapt = ((1.0 / 10) * adaptive_int + adaptive_min) * anp\n",
    "        \n",
    "        best_train = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "        best_test = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "        best_test_previous = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "\n",
    "    else:\n",
    "      \n",
    "        if len(parametr_set.loc[parametr_set['test'] == parametr_set['test'].max(), 'epoch']) == 1:\n",
    "            optim_index = int(parametr_set.loc[parametr_set['test'] == parametr_set['test'].max(), 'epoch'].item())\n",
    "        else:\n",
    "            optim_index = int(parametr_set.loc[parametr_set['test'] == parametr_set['test'].max(), 'epoch'].tolist()[-1])\n",
    "\n",
    "        if len(parametr_set.loc[parametr_set['train'] == parametr_set['train'].max(), 'epoch']) == 1:\n",
    "            best_train_index = int(parametr_set.loc[parametr_set['train'] == parametr_set['train'].max(), 'epoch'].item())\n",
    "        else:\n",
    "            best_train_index = int(parametr_set.loc[parametr_set['train'] == parametr_set['train'].max(), 'epoch'].tolist()[-1])\n",
    "\n",
    "        if len(parametr_set.loc[parametr_set['test_previous'] == parametr_set['test_previous'].max(), 'epoch']) == 1:\n",
    "            best_test_previous_index = int(parametr_set.loc[parametr_set['test_previous'] == parametr_set['test_previous'].max(), 'epoch'].item())\n",
    "        else:\n",
    "            best_test_previous_index = int(parametr_set.loc[parametr_set['test_previous'] == parametr_set['test_previous'].max(), 'epoch'].tolist()[-1])\n",
    "        \n",
    "        max_index = int(parametr_set.index.max())\n",
    "        counter = (max_index + 1)\n",
    "\n",
    "        param_best_train = parametr_set['train'].iloc[best_train_index]\n",
    "        param_best_test = parametr_set['test'].iloc[optim_index]\n",
    "        param_best_test_previous = parametr_set['test_previous'].iloc[best_test_previous_index]\n",
    "\n",
    "        apr_adapt = parametr_set['apr_adapt'].iloc[optim_index]\n",
    "        anr_adapt = parametr_set['anr_adapt'].iloc[optim_index]\n",
    "        app_adapt = parametr_set['app_adapt'].iloc[optim_index]\n",
    "        anp_adapt = parametr_set['anp_adapt'].iloc[optim_index]\n",
    "        \n",
    "        for i in range(len(mozafari.stdp3.learning_rate)):\n",
    "            mozafari.stdp3.learning_rate[i][0].fill_(parametr_set['stdp3.learning_rate[0]'].iloc[optim_index])\n",
    "            mozafari.stdp3.learning_rate[i][1].fill_(parametr_set['stdp3.learning_rate[1]'].iloc[optim_index])\n",
    "            mozafari.anti_stdp3.learning_rate[0][0].fill_(parametr_set['anti_stdp3.learning_rate[0]'].iloc[optim_index])\n",
    "            mozafari.anti_stdp3.learning_rate[0][0].fill_(parametr_set['anti_stdp3.learning_rate[1]'].iloc[optim_index])\n",
    "\n",
    "        best_train = np.array([param_best_train,1-param_best_train,0.0,best_train_index]) # correct, wrong, silence, epoch\n",
    "        best_test = np.array([param_best_test,1-param_best_test,0.0,optim_index]) # correct, wrong, silence, epoch\n",
    "        best_test_previous = np.array([param_best_test_previous,1-param_best_test_previous,0.0,best_test_previous_index]) # correct, wrong, silence, epoch\n",
    "    \n",
    "    # list of 3-rd layer weights\n",
    "\n",
    "    dim_0, dim_1, dim_2, dim_3 = tuple(mozafari.conv3.weight.size())\n",
    "    total_size = dim_0 * dim_1 * dim_2 * dim_3\n",
    "  \n",
    "    # indexes of weights\n",
    "    indexes_i = []    \n",
    "    indexes_j = []        \n",
    "    indexes_k = []        \n",
    "    indexes_m = []    \n",
    "    \n",
    "    # values of weights\n",
    "    item_values = []  \n",
    "    \n",
    "    for i in range(dim_0):\n",
    "        for j in range(dim_1):\n",
    "            for k in range(dim_2):\n",
    "                for m in range(dim_3):\n",
    "                    indexes_i.append(i)\n",
    "                    indexes_j.append(j)\n",
    "                    indexes_k.append(k)\n",
    "                    indexes_m.append(m)\n",
    "                    item_values.append(mozafari.conv3.weight[i][j][k][m].item())\n",
    "\n",
    "    indexes_dim_0 = pd.Series(indexes_i, name='dim_0') \n",
    "    indexes_dim_1 = pd.Series(indexes_j, name='dim_1')\n",
    "    indexes_dim_2 = pd.Series(indexes_k, name='dim_2')\n",
    "    indexes_dim_3 = pd.Series(indexes_m, name='dim_3')\n",
    "    item_values = pd.Series(item_values, name='value_0')\n",
    "            \n",
    "    conv3_data = pd.concat([item_values, indexes_dim_0, indexes_dim_1, indexes_dim_2, indexes_dim_3], axis=1)\n",
    "    \n",
    "    high_percent = 85 #percent of high range weights\n",
    "    percentile_value = np.percentile(item_values, high_percent)\n",
    "    \n",
    "    conv3_data['low_range_0'] = 0\n",
    "    conv3_data.loc[conv3_data['value_0'] < percentile_value,'low_range_0'] = 1\n",
    "    \n",
    "    try:\n",
    "        high_range_counter = conv3_data['low_range_0'].value_counts()[0] \n",
    "    except:\n",
    "        high_range_counter = 1\n",
    " \n",
    "    moving_quantity = int((percent/100)*high_range_counter) #quantity of moving items in each epoch\n",
    "    \n",
    "    if steps is None:\n",
    "        steps = int(total_size*high_percent/(100*moving_quantity))   #steps of weights moving \n",
    "    print(f'Weight moving will be during {steps} epochs')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        seconds_epoch_0 = time.time() \n",
    "        \n",
    "        print('-'*50)\n",
    "        print(\"Epoch #: \", epoch + previous_epochs)\n",
    "        \n",
    "        perf_train = np.array([0.0,0.0,0.0]) \n",
    "        \n",
    "        for data,targets in train_loader:\n",
    "                \n",
    "            if epoch < steps: \n",
    "                \n",
    "                print(f'Values of high range weights in epoch#{epoch} [{percentile_value :.3f}:0.800] (top {100-high_percent}%)')\n",
    "                low_range_indexes = list(conv3_data.index[conv3_data['low_range_'+str(epoch)] == 1])\n",
    "                moving_items = random.sample(low_range_indexes, np.minimum(moving_quantity, len(low_range_indexes)))\n",
    "                moving_indexes = conv3_data.loc[conv3_data.index.isin(moving_items)]\n",
    "\n",
    "                print(f'Quantity of moving points in epoch#{epoch + previous_epochs} = {len(moving_indexes.index)} items' \n",
    "                      f' ({len(moving_indexes.index)/(total_size-high_range_counter)*100 :.1f}% of moving points)')\n",
    "\n",
    "                for q in range(len(moving_indexes.index)):\n",
    "                    mozafari.conv3.weight \\\n",
    "                    [moving_indexes['dim_0'].iloc[q]][moving_indexes['dim_1'].iloc[q]][moving_indexes['dim_2'].iloc[q]][moving_indexes['dim_3'].iloc[q]]. \\\n",
    "                    fill_(np.random.normal(loc=0.8, scale=0.05))  \n",
    "              \n",
    "            perf_train_batch = train_rl(model, data, targets)\n",
    "    \n",
    "            if epoch < steps:  \n",
    "            \n",
    "                # new values of weights (after learning)\n",
    "                item_values = []       \n",
    "                for i in range(dim_0):\n",
    "                    for j in range(dim_1):\n",
    "                        for k in range(dim_2):\n",
    "                            for m in range(dim_3):\n",
    "                                item_values.append(mozafari.conv3.weight[i][j][k][m].item())\n",
    "            \n",
    "                item_values = pd.Series(item_values, name='value_'+str(epoch+1))\n",
    "                percentile_value = np.percentile(item_values, high_percent) #new cutting off high range weights\n",
    "                conv3_data = pd.concat([conv3_data, item_values], axis=1)\n",
    "                \n",
    "                conv3_data['low_range_'+str(epoch+1)] = 0\n",
    "                conv3_data.loc[conv3_data['value_'+str(epoch+1)] < percentile_value,'low_range_'+str(epoch+1)] = 1\n",
    "       \n",
    "            #update adaptive learning rates\n",
    "            apr_adapt = apr * (perf_train_batch[1] * adaptive_int + adaptive_min)\n",
    "            anr_adapt = anr * (perf_train_batch[1] * adaptive_int + adaptive_min)\n",
    "            app_adapt = app * (perf_train_batch[0] * adaptive_int + adaptive_min)\n",
    "            anp_adapt = anp * (perf_train_batch[0] * adaptive_int + adaptive_min)\n",
    "            parametr_set.loc[counter, 'epoch'] = epoch + previous_epochs\n",
    "            parametr_set.loc[counter, 'apr_adapt'] = apr_adapt\n",
    "            parametr_set.loc[counter, 'anr_adapt'] = anr_adapt\n",
    "            parametr_set.loc[counter, 'app_adapt'] = app_adapt\n",
    "            parametr_set.loc[counter, 'anp_adapt'] = anp_adapt\n",
    "            parametr_set.loc[counter, 'stdp3.learning_rate[0]'] = mozafari.stdp3.learning_rate[0][0].item()\n",
    "            parametr_set.loc[counter, 'stdp3.learning_rate[1]'] = mozafari.stdp3.learning_rate[0][1].item()\n",
    "            parametr_set.loc[counter, 'anti_stdp3.learning_rate[0]'] = mozafari.anti_stdp3.learning_rate[0][0].item()\n",
    "            parametr_set.loc[counter, 'anti_stdp3.learning_rate[1]'] = mozafari.anti_stdp3.learning_rate[0][1].item()\n",
    "            parametr_set.loc[counter, 'train'] = perf_train_batch[0]\n",
    "\n",
    "            model.update_learning_rates(apr_adapt, anr_adapt, app_adapt, anp_adapt)\n",
    "            perf_train += perf_train_batch\n",
    "            \n",
    "        perf_train /= len(train_loader)\n",
    "\n",
    "        if best_train[0] <= perf_train[0]:\n",
    "            best_train = np.append(perf_train, epoch + previous_epochs)\n",
    "        print(f\"Current Train: {perf_train[0]*100 :.2f}%\")\n",
    "        #print(\"   Best Train:\", best_train)\n",
    "\n",
    "        for data,targets in test_loader:\n",
    "            perf_test = test(model, data, targets)\n",
    "            parametr_set.loc[counter, 'test'] = perf_test[0]\n",
    "            if best_test[0] <= perf_test[0]:\n",
    "                best_test = np.append(perf_test, epoch + previous_epochs)\n",
    "                torch.save(model.state_dict(), file_name_net)\n",
    "            print(f\"Current Test: {perf_test[0]*100 :.2f}%\")\n",
    "            #print(\"    Best Test:\", best_test)\n",
    "\n",
    "        if isinstance(test_previous_loader, DataLoader):\n",
    "            for data,targets in test_previous_loader:\n",
    "                perf_test_previous = test(model, data, targets)\n",
    "                parametr_set.loc[counter, 'test_previous'] = perf_test_previous[0]\n",
    "                if best_test_previous[0] <= perf_test_previous[0]:\n",
    "                    best_test_previous = np.append(perf_test_previous, epoch + previous_epochs)\n",
    "                print(f\"Current Test Previous: {perf_test_previous[0]*100 :.2f}%\")\n",
    "                #print(\"    Best Test Previous:\", best_test_previous)\n",
    "                \n",
    "        else:\n",
    "            parametr_set.loc[counter, 'test_previous'] = 0\n",
    "            \n",
    "        counter += 1\n",
    "                                                 \n",
    "        seconds_epoch_1 = time.time()  \n",
    "        print(f'Operational time of epoch #{epoch + previous_epochs}: '\n",
    "                  f'{int((seconds_epoch_1 - seconds_epoch_0)//60)} min {int((seconds_epoch_1 - seconds_epoch_0)%60)} sec') \n",
    "    \n",
    "    parametr_set.to_csv(file_name_csv)\n",
    "    \n",
    "    print('=='*10, 'SUMMARY', '=='*10)\n",
    "    print(f\"        Best Train: {best_train[0]*100 :.2f}% on {best_train[3] :.0f} epoch\")\n",
    "    print(f\"         Best Test: {best_test[0]*100 :.2f}% on {best_test[3] :.0f} epoch\")\n",
    "    print(f\"Best Test Previous: {best_test_previous[0]*100 :.2f}% on {best_test_previous[3] :.0f} epoch\")\n",
    "    \n",
    "    return parametr_set, counter, (previous_epochs+epochs), apr, anr, app, anp, conv3_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "class S1C1Transform:\n",
    "    \n",
    "    def __init__(self, filter, PIL_type=False, timesteps = 15):\n",
    "        self.PIL_type = PIL_type\n",
    "        self.to_pil_image = transforms.ToPILImage()    \n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.filter = filter\n",
    "        self.temporal_transform = utils.Intensity2Latency(timesteps)\n",
    "        self.cnt = 0\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        if self.cnt % 20000 == 0:\n",
    "            print(f'{self.cnt} images')\n",
    "        if self.PIL_type:\n",
    "            image = self.to_pil_image(image)\n",
    "        self.cnt+=1\n",
    "        image = self.to_tensor(image) * 255\n",
    "        image.unsqueeze_(0)\n",
    "        image = self.filter(image)\n",
    "        image = sf.local_normalization(image, 8)\n",
    "        temporal_image = self.temporal_transform(image)\n",
    "        return temporal_image.sign().byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "kernels = [ utils.DoGKernel(3,3/9,6/9),\n",
    "            utils.DoGKernel(3,6/9,3/9),\n",
    "            utils.DoGKernel(7,7/9,14/9),\n",
    "            utils.DoGKernel(7,14/9,7/9),\n",
    "            utils.DoGKernel(13,13/9,26/9),\n",
    "            utils.DoGKernel(13,26/9,13/9)]\n",
    "\n",
    "filter = utils.Filter(kernels, padding = 6, thresholds = 50)\n",
    "\n",
    "s1c1 = S1C1Transform(filter)\n",
    "s1c1_PIL = S1C1Transform(filter, PIL_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "class CustomTensorDataset(Dataset):\n",
    "    \"\"\"TensorDataset with support of transforms.\"\"\"\n",
    "    \n",
    "    def __init__(self, tensors, transform=None):\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[0][index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        y = self.tensors[1][index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensors[0].size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of 10 capital letters\n",
    "24000 train images + 4000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of 10 capital letters from EMNIST\n",
    "\n",
    "path = f'./data/EMNIST_own/capital_letters/'\n",
    "\n",
    "test_letter_labels = torch.load(f'{path}Mozafari_capital_letters_test_labels.pt', map_location=torch.device('cpu'))\n",
    "test_letters = torch.load(f'{path}Mozafari_capital_letters_test_images.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "train_letter_labels = torch.load(f'{path}Mozafari_capital_letters_train_labels.pt', map_location=torch.device('cpu'))\n",
    "train_letters = torch.load(f'{path}Mozafari_capital_letters_train_images.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element permutation\n",
    "\n",
    "train_order_l = torch.randperm(train_letter_labels.shape[0])\n",
    "test_order_l = torch.randperm(test_letter_labels.shape[0])\n",
    "\n",
    "train_letter_labels = train_letter_labels[train_order_l].view(train_letter_labels.size())\n",
    "train_letters = train_letters[train_order_l].view(train_letters.size())\n",
    "\n",
    "test_letter_labels = test_letter_labels[test_order_l].view(test_letter_labels.size())\n",
    "test_letters = test_letters[test_order_l].view(test_letters.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_letter_set = CustomTensorDataset(tensors=(train_letters, train_letter_labels), transform=s1c1_PIL)\n",
    "test_letter_set = CustomTensorDataset(tensors=(test_letters, test_letter_labels), transform=s1c1_PIL)\n",
    "\n",
    "train_letter_loader = DataLoader(train_letter_set, batch_size=len(train_letter_set))\n",
    "test_letter_loader = DataLoader(test_letter_set, batch_size=len(test_letter_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24000]), torch.Size([4000]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_letter_labels.size(), test_letter_labels.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of 10 MNIST digits\n",
    "Reduction 60000 train + 10000 test images to 24000 train + 4000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the set of 10 digit images, the same size as the set of letters (2400 trains + 400 tests per class)\n",
    "# the MNIST data was pre-divided into 10 classes\n",
    "path = f'./data/MNIST_0_1_2_3_4_5_6_7_8_9/'\n",
    "\n",
    "for i in classes: \n",
    "    globals()[f'train_digit_{i}_images'] = torch.load(f'{path}train_images_{i}.pt', map_location=torch.device('cpu'))[0:2400]\n",
    "    globals()[f'train_digit_{i}_labels'] = torch.load(f'{path}train_labels_{i}.pt', map_location=torch.device('cpu'))[0:2400]\n",
    "    globals()[f'test_digit_{i}_images'] = torch.load(f'{path}test_images_{i}.pt', map_location=torch.device('cpu'))[0:400]\n",
    "    globals()[f'test_digit_{i}_labels'] = torch.load(f'{path}test_labels_{i}.pt', map_location=torch.device('cpu'))[0:400]\n",
    "\n",
    "train_MNIST_labels = globals()[f'train_digit_0_labels']\n",
    "train_MNIST_images = globals()[f'train_digit_0_images']\n",
    "test_MNIST_labels = globals()[f'test_digit_0_labels']\n",
    "test_MNIST_images = globals()[f'test_digit_0_images']                                 \n",
    "\n",
    "for i in range(1, 10):\n",
    "    train_MNIST_labels = torch.cat((train_MNIST_labels, globals()[f'train_digit_{i}_labels']), 0)\n",
    "    train_MNIST_images = torch.cat((train_MNIST_images, globals()[f'train_digit_{i}_images']), 0)\n",
    "\n",
    "    test_MNIST_labels = torch.cat((test_MNIST_labels, globals()[f'test_digit_{i}_labels']), 0)\n",
    "    test_MNIST_images = torch.cat((test_MNIST_images, globals()[f'test_digit_{i}_images']), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24000]), torch.Size([4000]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_MNIST_labels.size(), test_MNIST_labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element permutation\n",
    "\n",
    "train_order = torch.randperm(train_MNIST_labels.shape[0])\n",
    "test_order = torch.randperm(test_MNIST_labels.shape[0])\n",
    "\n",
    "train_MNIST_labels = train_MNIST_labels[train_order].view(train_MNIST_labels.size())\n",
    "train_MNIST_images = train_MNIST_images[train_order].view(train_MNIST_images.size())\n",
    "\n",
    "test_MNIST_labels = test_MNIST_labels[test_order].view(test_MNIST_labels.size())\n",
    "test_MNIST_images = test_MNIST_images[test_order].view(test_MNIST_images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MNIST_set = CustomTensorDataset(tensors=(train_MNIST_images, train_MNIST_labels), transform=s1c1_PIL)\n",
    "test_MNIST_set = CustomTensorDataset(tensors=(test_MNIST_images, test_MNIST_labels), transform=s1c1_PIL)\n",
    "\n",
    "train_MNIST_loader = DataLoader(train_MNIST_set, batch_size=len(train_MNIST_set))\n",
    "test_MNIST_loader = DataLoader(test_MNIST_set, batch_size=len(test_MNIST_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined set of digit set + capital letter set\n",
    "\n",
    "48000 train + 8000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of digits + letters \n",
    "\n",
    "train_combi_labels = torch.cat((train_MNIST_labels, train_letter_labels), 0)\n",
    "train_combi_images = torch.cat((train_MNIST_images, train_letters), 0)\n",
    "test_combi_labels = torch.cat((test_MNIST_labels, test_letter_labels), 0)\n",
    "test_combi_images = torch.cat((test_MNIST_images, test_letters), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element permutation\n",
    "\n",
    "train_order_c = torch.randperm(train_combi_labels.shape[0])\n",
    "test_order_c = torch.randperm(test_combi_labels.shape[0])\n",
    "\n",
    "train_combi_labels = train_combi_labels[train_order_c].view(train_combi_labels.size())\n",
    "train_combi_images = train_combi_images[train_order_c].view(train_combi_images.size())\n",
    "\n",
    "test_combi_labels = test_combi_labels[test_order_c].view(test_combi_labels.size())\n",
    "test_combi_images = test_combi_images[test_order_c].view(test_combi_images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combi_set = CustomTensorDataset(tensors=(train_combi_images, train_combi_labels), transform=s1c1_PIL)\n",
    "test_combi_set = CustomTensorDataset(tensors=(test_combi_images, test_combi_labels), transform=s1c1_PIL)\n",
    "\n",
    "train_combi_loader = DataLoader(train_combi_set, batch_size=len(train_combi_set))\n",
    "test_combi_loader = DataLoader(test_combi_set, batch_size=len(test_combi_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([48000]), torch.Size([8000]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_combi_labels.size(), test_combi_labels.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model activation\n",
    "variable _eps_std_percent_ is the standard deviation of the random small addition to the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation of the random small addition to the learning rate\n",
    "eps_std_percent = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MozafariMNIST2018(\n",
       "  (conv1): Convolution()\n",
       "  (conv2): Convolution()\n",
       "  (conv3): Convolution()\n",
       "  (stdp1): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (stdp2): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (stdp3): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (anti_stdp3): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mozafari = MozafariMNIST2018(eps_std_percent)\n",
    "\n",
    "use_cuda = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "if use_cuda:\n",
    "    mozafari.cuda()   \n",
    "    \n",
    "mozafari.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous learning  \n",
    "Training on set of letters (1st and 2nd layers on letters without noise, 3rd layer on letters with noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving all values of parameters before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_from_scratch = {'stdp1': [mozafari.stdp1.learning_rate[0][0].item(), \n",
    "                                        mozafari.stdp1.learning_rate[0][1].item()],\n",
    "                              'stdp2': [mozafari.stdp2.learning_rate[0][0].item(), \n",
    "                                        mozafari.stdp2.learning_rate[0][1].item()],\n",
    "                              'stdp3': [mozafari.stdp3.learning_rate[0][0].item(), \n",
    "                                        mozafari.stdp3.learning_rate[0][1].item()],\n",
    "                              'anti_stdp3': [mozafari.anti_stdp3.learning_rate[0][0].item(), \n",
    "                                             mozafari.anti_stdp3.learning_rate[0][1].item()]\n",
    "                             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading weights of model pretrained on digits with noise\n",
    "Trained with noise parameter: eps_std_percent - standard deviation for random small additive to learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file \"saved_digits_with_noise_0.net\" is the result of the file \"(f)_Noise_regularization_(digits+noise).ipynb\"\n",
    "mozafari.load_state_dict(torch.load(\"saved_digits_with_noise_0.net\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the first layer\n",
      "Epoch 0\n",
      "0 images\n",
      "20000 images\n",
      "Iteration 0\n",
      "Done!\n",
      "Epoch 1\n",
      "40000 images\n",
      "Iteration 0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the first layer\")\n",
    "\n",
    "for epoch in range(2):\n",
    "    print(\"Epoch\", epoch)\n",
    "    iter = 0\n",
    "    for data, targets in train_letter_loader:\n",
    "        print(\"Iteration\", iter)\n",
    "        train_unsupervise(mozafari, data, 1)\n",
    "        print(\"Done!\")\n",
    "        iter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the second layer\n",
      "Epoch 0\n",
      "60000 images\n",
      "Iteration 0\n",
      "Done!\n",
      "Epoch 1\n",
      "80000 images\n",
      "Iteration 0\n",
      "Done!\n",
      "Epoch 2\n",
      "100000 images\n",
      "Iteration 0\n",
      "Done!\n",
      "Epoch 3\n",
      "120000 images\n",
      "140000 images\n",
      "Iteration 0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the second layer\")\n",
    "\n",
    "for epoch in range(4):\n",
    "    print(\"Epoch\", epoch)\n",
    "    iter = 0\n",
    "    for data,targets in train_letter_loader:\n",
    "        print(\"Iteration\", iter)\n",
    "        train_unsupervise(mozafari, data, 2)\n",
    "        print(\"Done!\")\n",
    "        iter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the third layer\n",
    "Training with noise parameter: eps_std_percent - standard deviation for random small additive to learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving learning_rates \n",
    "\n",
    "for i in range(len(mozafari.stdp3.learning_rate)):\n",
    "                    mozafari.stdp3.learning_rate[i][0].fill_(learning_rate_from_scratch['stdp3'][0])\n",
    "                    mozafari.stdp3.learning_rate[i][1].fill_(learning_rate_from_scratch['stdp3'][1])\n",
    "                    mozafari.anti_stdp3.learning_rate[i][0].fill_(learning_rate_from_scratch['anti_stdp3'][0])\n",
    "                    mozafari.anti_stdp3.learning_rate[i][1].fill_(learning_rate_from_scratch['anti_stdp3'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial adaptive learning rates\n",
    "\n",
    "apr = mozafari.stdp3.learning_rate[0][0].item()\n",
    "anr = mozafari.stdp3.learning_rate[0][1].item()\n",
    "app = mozafari.anti_stdp3.learning_rate[0][1].item()\n",
    "anp = mozafari.anti_stdp3.learning_rate[0][0].item()\n",
    "               \n",
    "parametr_set = pd.DataFrame(columns=['epoch', 'train', 'test', 'test_previous',   \n",
    "                                 'apr_adapt', 'anr_adapt', 'app_adapt', 'anp_adapt', \n",
    "                                 'stdp3.learning_rate[0]', 'stdp3.learning_rate[1]',\n",
    "                                 'anti_stdp3.learning_rate[0]', 'anti_stdp3.learning_rate[1]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* eps_std_percent = 0.5       <== %% standard deviation for random small additive to learning rate\n",
    "* eps_std_0 = np.abs(lr_0) * self.eps_std_percent     \n",
    "* eps_std_1 = np.abs(lr_1) * self.eps_std_percent     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight moving will be during 0 epochs\n",
      "--------------------------------------------------\n",
      "Epoch #:  0\n",
      "160000 images\n",
      "Current Train: 53.24%\n",
      "Current Test: 65.80%\n",
      "Current Test Previous: 56.17%\n",
      "Operational time of epoch #0: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  1\n",
      "180000 images\n",
      "Current Train: 66.42%\n",
      "200000 images\n",
      "Current Test: 65.70%\n",
      "Current Test Previous: 55.67%\n",
      "Operational time of epoch #1: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  2\n",
      "220000 images\n",
      "Current Train: 70.09%\n",
      "Current Test: 69.45%\n",
      "Current Test Previous: 66.25%\n",
      "Operational time of epoch #2: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  3\n",
      "240000 images\n",
      "260000 images\n",
      "Current Train: 72.64%\n",
      "Current Test: 72.58%\n",
      "Current Test Previous: 71.17%\n",
      "Operational time of epoch #3: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  4\n",
      "280000 images\n",
      "Current Train: 74.82%\n",
      "Current Test: 74.67%\n",
      "300000 images\n",
      "Current Test Previous: 70.10%\n",
      "Operational time of epoch #4: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  5\n",
      "320000 images\n",
      "Current Train: 76.41%\n",
      "Current Test: 75.83%\n",
      "Current Test Previous: 70.58%\n",
      "Operational time of epoch #5: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  6\n",
      "340000 images\n",
      "Current Train: 77.21%\n",
      "360000 images\n",
      "Current Test: 76.48%\n",
      "Current Test Previous: 74.28%\n",
      "Operational time of epoch #6: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  7\n",
      "380000 images\n",
      "Current Train: 78.00%\n",
      "Current Test: 77.18%\n",
      "Current Test Previous: 74.45%\n",
      "Operational time of epoch #7: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  8\n",
      "400000 images\n",
      "420000 images\n",
      "Current Train: 78.67%\n",
      "Current Test: 77.40%\n",
      "Current Test Previous: 75.05%\n",
      "Operational time of epoch #8: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  9\n",
      "440000 images\n",
      "Current Train: 79.44%\n",
      "Current Test: 78.20%\n",
      "460000 images\n",
      "Current Test Previous: 74.35%\n",
      "Operational time of epoch #9: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  10\n",
      "480000 images\n",
      "Current Train: 80.08%\n",
      "Current Test: 78.67%\n",
      "Current Test Previous: 75.17%\n",
      "Operational time of epoch #10: 2 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  11\n",
      "500000 images\n",
      "Current Train: 80.44%\n",
      "520000 images\n",
      "Current Test: 79.72%\n",
      "Current Test Previous: 75.35%\n",
      "Operational time of epoch #11: 2 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  12\n",
      "540000 images\n",
      "Current Train: 81.09%\n",
      "Current Test: 79.57%\n",
      "Current Test Previous: 74.60%\n",
      "Operational time of epoch #12: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  13\n",
      "560000 images\n",
      "580000 images\n",
      "Current Train: 81.40%\n",
      "Current Test: 80.40%\n",
      "Current Test Previous: 75.10%\n",
      "Operational time of epoch #13: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  14\n",
      "600000 images\n",
      "Current Train: 81.78%\n",
      "Current Test: 81.25%\n",
      "620000 images\n",
      "Current Test Previous: 75.50%\n",
      "Operational time of epoch #14: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  15\n",
      "640000 images\n",
      "Current Train: 82.25%\n",
      "Current Test: 81.50%\n",
      "Current Test Previous: 75.48%\n",
      "Operational time of epoch #15: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  16\n",
      "660000 images\n",
      "Current Train: 82.61%\n",
      "680000 images\n",
      "Current Test: 81.70%\n",
      "Current Test Previous: 75.85%\n",
      "Operational time of epoch #16: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  17\n",
      "700000 images\n",
      "Current Train: 82.85%\n",
      "Current Test: 81.92%\n",
      "Current Test Previous: 75.65%\n",
      "Operational time of epoch #17: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  18\n",
      "720000 images\n",
      "740000 images\n",
      "Current Train: 83.26%\n",
      "Current Test: 82.45%\n",
      "Current Test Previous: 76.88%\n",
      "Operational time of epoch #18: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  19\n",
      "760000 images\n",
      "Current Train: 83.41%\n",
      "Current Test: 82.45%\n",
      "780000 images\n",
      "Current Test Previous: 76.33%\n",
      "Operational time of epoch #19: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  20\n",
      "800000 images\n",
      "Current Train: 83.79%\n",
      "Current Test: 83.12%\n",
      "Current Test Previous: 75.33%\n",
      "Operational time of epoch #20: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  21\n",
      "820000 images\n",
      "Current Train: 84.11%\n",
      "840000 images\n",
      "Current Test: 82.93%\n",
      "Current Test Previous: 75.52%\n",
      "Operational time of epoch #21: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  22\n",
      "860000 images\n",
      "Current Train: 84.11%\n",
      "Current Test: 83.53%\n",
      "Current Test Previous: 73.98%\n",
      "Operational time of epoch #22: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  23\n",
      "880000 images\n",
      "900000 images\n",
      "Current Train: 84.17%\n",
      "Current Test: 83.33%\n",
      "Current Test Previous: 74.58%\n",
      "Operational time of epoch #23: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  24\n",
      "920000 images\n",
      "Current Train: 84.42%\n",
      "Current Test: 83.45%\n",
      "940000 images\n",
      "Current Test Previous: 74.83%\n",
      "Operational time of epoch #24: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  25\n",
      "960000 images\n",
      "Current Train: 84.70%\n",
      "Current Test: 83.78%\n",
      "Current Test Previous: 74.33%\n",
      "Operational time of epoch #25: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  26\n",
      "980000 images\n",
      "Current Train: 84.75%\n",
      "1000000 images\n",
      "Current Test: 84.00%\n",
      "Current Test Previous: 75.12%\n",
      "Operational time of epoch #26: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  27\n",
      "1020000 images\n",
      "Current Train: 84.98%\n",
      "Current Test: 84.20%\n",
      "Current Test Previous: 73.58%\n",
      "Operational time of epoch #27: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  28\n",
      "1040000 images\n",
      "1060000 images\n",
      "Current Train: 85.12%\n",
      "Current Test: 84.15%\n",
      "Current Test Previous: 73.70%\n",
      "Operational time of epoch #28: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  29\n",
      "1080000 images\n",
      "Current Train: 85.28%\n",
      "Current Test: 84.47%\n",
      "1100000 images\n",
      "Current Test Previous: 74.98%\n",
      "Operational time of epoch #29: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  30\n",
      "1120000 images\n",
      "Current Train: 85.30%\n",
      "Current Test: 84.03%\n",
      "Current Test Previous: 72.62%\n",
      "Operational time of epoch #30: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  31\n",
      "1140000 images\n",
      "Current Train: 85.42%\n",
      "1160000 images\n",
      "Current Test: 84.52%\n",
      "Current Test Previous: 74.17%\n",
      "Operational time of epoch #31: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  32\n",
      "1180000 images\n",
      "Current Train: 85.99%\n",
      "Current Test: 85.02%\n",
      "Current Test Previous: 69.75%\n",
      "Operational time of epoch #32: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  33\n",
      "1200000 images\n",
      "1220000 images\n",
      "Current Train: 85.95%\n",
      "Current Test: 84.62%\n",
      "Current Test Previous: 71.62%\n",
      "Operational time of epoch #33: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  34\n",
      "1240000 images\n",
      "Current Train: 86.23%\n",
      "Current Test: 85.40%\n",
      "1260000 images\n",
      "Current Test Previous: 71.92%\n",
      "Operational time of epoch #34: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  35\n",
      "1280000 images\n",
      "Current Train: 86.40%\n",
      "Current Test: 85.55%\n",
      "Current Test Previous: 72.08%\n",
      "Operational time of epoch #35: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  36\n",
      "1300000 images\n",
      "Current Train: 86.67%\n",
      "1320000 images\n",
      "Current Test: 85.70%\n",
      "Current Test Previous: 71.20%\n",
      "Operational time of epoch #36: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  37\n",
      "1340000 images\n",
      "Current Train: 86.70%\n",
      "Current Test: 85.00%\n",
      "Current Test Previous: 72.10%\n",
      "Operational time of epoch #37: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  38\n",
      "1360000 images\n",
      "1380000 images\n",
      "Current Train: 86.81%\n",
      "Current Test: 85.08%\n",
      "Current Test Previous: 73.90%\n",
      "Operational time of epoch #38: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  39\n",
      "1400000 images\n",
      "Current Train: 87.23%\n",
      "Current Test: 85.82%\n",
      "1420000 images\n",
      "Current Test Previous: 70.78%\n",
      "Operational time of epoch #39: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440000 images\n",
      "Current Train: 87.23%\n",
      "Current Test: 85.97%\n",
      "Current Test Previous: 72.28%\n",
      "Operational time of epoch #40: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  41\n",
      "1460000 images\n",
      "Current Train: 87.24%\n",
      "1480000 images\n",
      "Current Test: 85.85%\n",
      "Current Test Previous: 69.30%\n",
      "Operational time of epoch #41: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  42\n",
      "1500000 images\n",
      "Current Train: 87.42%\n",
      "Current Test: 86.42%\n",
      "Current Test Previous: 71.50%\n",
      "Operational time of epoch #42: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  43\n",
      "1520000 images\n",
      "1540000 images\n",
      "Current Train: 87.40%\n",
      "Current Test: 86.08%\n",
      "Current Test Previous: 70.28%\n",
      "Operational time of epoch #43: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  44\n",
      "1560000 images\n",
      "Current Train: 87.60%\n",
      "Current Test: 85.88%\n",
      "1580000 images\n",
      "Current Test Previous: 71.47%\n",
      "Operational time of epoch #44: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  45\n",
      "1600000 images\n",
      "Current Train: 87.76%\n",
      "Current Test: 86.38%\n",
      "Current Test Previous: 70.67%\n",
      "Operational time of epoch #45: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  46\n",
      "1620000 images\n",
      "Current Train: 87.88%\n",
      "1640000 images\n",
      "Current Test: 86.35%\n",
      "Current Test Previous: 70.88%\n",
      "Operational time of epoch #46: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  47\n",
      "1660000 images\n",
      "Current Train: 87.88%\n",
      "Current Test: 86.02%\n",
      "Current Test Previous: 69.80%\n",
      "Operational time of epoch #47: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  48\n",
      "1680000 images\n",
      "1700000 images\n",
      "Current Train: 87.99%\n",
      "Current Test: 86.52%\n",
      "Current Test Previous: 69.58%\n",
      "Operational time of epoch #48: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  49\n",
      "1720000 images\n",
      "Current Train: 88.13%\n",
      "Current Test: 86.38%\n",
      "1740000 images\n",
      "Current Test Previous: 68.95%\n",
      "Operational time of epoch #49: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  50\n",
      "1760000 images\n",
      "Current Train: 88.18%\n",
      "Current Test: 87.12%\n",
      "Current Test Previous: 69.77%\n",
      "Operational time of epoch #50: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  51\n",
      "1780000 images\n",
      "Current Train: 88.28%\n",
      "1800000 images\n",
      "Current Test: 86.72%\n",
      "Current Test Previous: 72.52%\n",
      "Operational time of epoch #51: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  52\n",
      "1820000 images\n",
      "Current Train: 88.22%\n",
      "Current Test: 87.22%\n",
      "Current Test Previous: 71.55%\n",
      "Operational time of epoch #52: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  53\n",
      "1840000 images\n",
      "1860000 images\n",
      "Current Train: 88.37%\n",
      "Current Test: 87.05%\n",
      "Current Test Previous: 71.08%\n",
      "Operational time of epoch #53: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  54\n",
      "1880000 images\n",
      "Current Train: 88.65%\n",
      "Current Test: 87.20%\n",
      "1900000 images\n",
      "Current Test Previous: 69.33%\n",
      "Operational time of epoch #54: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  55\n",
      "1920000 images\n",
      "Current Train: 88.59%\n",
      "Current Test: 86.98%\n",
      "Current Test Previous: 72.62%\n",
      "Operational time of epoch #55: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  56\n",
      "1940000 images\n",
      "Current Train: 88.74%\n",
      "1960000 images\n",
      "Current Test: 87.62%\n",
      "Current Test Previous: 71.33%\n",
      "Operational time of epoch #56: 2 min 32 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  57\n",
      "1980000 images\n",
      "Current Train: 88.92%\n",
      "Current Test: 87.67%\n",
      "Current Test Previous: 71.55%\n",
      "Operational time of epoch #57: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  58\n",
      "2000000 images\n",
      "2020000 images\n",
      "Current Train: 88.92%\n",
      "Current Test: 87.72%\n",
      "Current Test Previous: 73.10%\n",
      "Operational time of epoch #58: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  59\n",
      "2040000 images\n",
      "Current Train: 89.01%\n",
      "Current Test: 87.83%\n",
      "2060000 images\n",
      "Current Test Previous: 72.08%\n",
      "Operational time of epoch #59: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  60\n",
      "2080000 images\n",
      "Current Train: 89.17%\n",
      "Current Test: 87.58%\n",
      "Current Test Previous: 72.00%\n",
      "Operational time of epoch #60: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  61\n",
      "2100000 images\n",
      "Current Train: 89.18%\n",
      "2120000 images\n",
      "Current Test: 87.28%\n",
      "Current Test Previous: 71.85%\n",
      "Operational time of epoch #61: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  62\n",
      "2140000 images\n",
      "Current Train: 89.20%\n",
      "Current Test: 87.90%\n",
      "Current Test Previous: 72.38%\n",
      "Operational time of epoch #62: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  63\n",
      "2160000 images\n",
      "2180000 images\n",
      "Current Train: 89.35%\n",
      "Current Test: 87.35%\n",
      "Current Test Previous: 71.40%\n",
      "Operational time of epoch #63: 2 min 35 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  64\n",
      "2200000 images\n",
      "Current Train: 89.34%\n",
      "Current Test: 87.60%\n",
      "2220000 images\n",
      "Current Test Previous: 68.67%\n",
      "Operational time of epoch #64: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  65\n",
      "2240000 images\n",
      "Current Train: 89.47%\n",
      "Current Test: 87.58%\n",
      "Current Test Previous: 71.43%\n",
      "Operational time of epoch #65: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  66\n",
      "2260000 images\n",
      "Current Train: 89.56%\n",
      "2280000 images\n",
      "Current Test: 87.38%\n",
      "Current Test Previous: 71.70%\n",
      "Operational time of epoch #66: 2 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  67\n",
      "2300000 images\n",
      "Current Train: 89.47%\n",
      "Current Test: 87.17%\n",
      "Current Test Previous: 71.30%\n",
      "Operational time of epoch #67: 2 min 35 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  68\n",
      "2320000 images\n",
      "2340000 images\n",
      "Current Train: 89.56%\n",
      "Current Test: 87.52%\n",
      "Current Test Previous: 71.47%\n",
      "Operational time of epoch #68: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  69\n",
      "2360000 images\n",
      "Current Train: 89.50%\n",
      "Current Test: 87.78%\n",
      "2380000 images\n",
      "Current Test Previous: 71.45%\n",
      "Operational time of epoch #69: 2 min 33 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  70\n",
      "2400000 images\n",
      "Current Train: 89.62%\n",
      "Current Test: 87.42%\n",
      "Current Test Previous: 68.30%\n",
      "Operational time of epoch #70: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  71\n",
      "2420000 images\n",
      "Current Train: 89.71%\n",
      "2440000 images\n",
      "Current Test: 87.75%\n",
      "Current Test Previous: 72.22%\n",
      "Operational time of epoch #71: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  72\n",
      "2460000 images\n",
      "Current Train: 89.72%\n",
      "Current Test: 87.50%\n",
      "Current Test Previous: 70.70%\n",
      "Operational time of epoch #72: 2 min 35 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  73\n",
      "2480000 images\n",
      "2500000 images\n",
      "Current Train: 90.02%\n",
      "Current Test: 87.35%\n",
      "Current Test Previous: 68.53%\n",
      "Operational time of epoch #73: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  74\n",
      "2520000 images\n",
      "Current Train: 89.65%\n",
      "Current Test: 88.00%\n",
      "2540000 images\n",
      "Current Test Previous: 70.95%\n",
      "Operational time of epoch #74: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  75\n",
      "2560000 images\n",
      "Current Train: 89.89%\n",
      "Current Test: 87.67%\n",
      "Current Test Previous: 70.78%\n",
      "Operational time of epoch #75: 2 min 34 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  76\n",
      "2580000 images\n",
      "Current Train: 89.94%\n",
      "2600000 images\n",
      "Current Test: 87.75%\n",
      "Current Test Previous: 69.53%\n",
      "Operational time of epoch #76: 2 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  77\n",
      "2620000 images\n",
      "Current Train: 89.82%\n",
      "Current Test: 87.75%\n",
      "Current Test Previous: 70.60%\n",
      "Operational time of epoch #77: 2 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  78\n",
      "2640000 images\n",
      "2660000 images\n",
      "Current Train: 89.85%\n",
      "Current Test: 88.30%\n",
      "Current Test Previous: 68.27%\n",
      "Operational time of epoch #78: 2 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  79\n",
      "2680000 images\n",
      "Current Train: 89.89%\n",
      "Current Test: 87.48%\n",
      "2700000 images\n",
      "Current Test Previous: 69.15%\n",
      "Operational time of epoch #79: 2 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720000 images\n",
      "Current Train: 89.87%\n",
      "Current Test: 87.95%\n",
      "Current Test Previous: 69.38%\n",
      "Operational time of epoch #80: 2 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  81\n",
      "2740000 images\n",
      "Current Train: 89.99%\n",
      "2760000 images\n",
      "Current Test: 87.78%\n",
      "Current Test Previous: 67.65%\n",
      "Operational time of epoch #81: 2 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  82\n",
      "2780000 images\n",
      "Current Train: 89.97%\n",
      "Current Test: 87.92%\n",
      "Current Test Previous: 69.25%\n",
      "Operational time of epoch #82: 2 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  83\n",
      "2800000 images\n",
      "2820000 images\n",
      "Current Train: 90.22%\n",
      "Current Test: 87.83%\n",
      "Current Test Previous: 67.85%\n",
      "Operational time of epoch #83: 2 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  84\n",
      "2840000 images\n",
      "Current Train: 89.91%\n",
      "Current Test: 87.85%\n",
      "2860000 images\n",
      "Current Test Previous: 70.75%\n",
      "Operational time of epoch #84: 2 min 35 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  85\n",
      "2880000 images\n",
      "Current Train: 90.12%\n",
      "Current Test: 88.10%\n",
      "Current Test Previous: 68.40%\n",
      "Operational time of epoch #85: 2 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  86\n",
      "2900000 images\n",
      "Current Train: 90.03%\n",
      "2920000 images\n",
      "Current Test: 88.20%\n",
      "Current Test Previous: 67.73%\n",
      "Operational time of epoch #86: 2 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  87\n",
      "2940000 images\n",
      "Current Train: 90.19%\n",
      "Current Test: 88.05%\n",
      "Current Test Previous: 66.57%\n",
      "Operational time of epoch #87: 2 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  88\n",
      "2960000 images\n",
      "2980000 images\n",
      "Current Train: 90.27%\n",
      "Current Test: 87.80%\n",
      "Current Test Previous: 68.03%\n",
      "Operational time of epoch #88: 2 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  89\n",
      "3000000 images\n",
      "Current Train: 90.20%\n",
      "Current Test: 87.95%\n",
      "3020000 images\n",
      "Current Test Previous: 67.75%\n",
      "Operational time of epoch #89: 2 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  90\n",
      "3040000 images\n",
      "Current Train: 90.18%\n",
      "Current Test: 88.22%\n",
      "Current Test Previous: 68.25%\n",
      "Operational time of epoch #90: 2 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  91\n",
      "3060000 images\n",
      "Current Train: 90.42%\n",
      "3080000 images\n",
      "Current Test: 87.75%\n",
      "Current Test Previous: 65.97%\n",
      "Operational time of epoch #91: 2 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  92\n",
      "3100000 images\n",
      "Current Train: 90.47%\n",
      "Current Test: 87.85%\n",
      "Current Test Previous: 66.57%\n",
      "Operational time of epoch #92: 2 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  93\n",
      "3120000 images\n",
      "3140000 images\n",
      "Current Train: 90.29%\n",
      "Current Test: 87.70%\n",
      "Current Test Previous: 71.00%\n",
      "Operational time of epoch #93: 2 min 35 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  94\n",
      "3160000 images\n",
      "Current Train: 90.55%\n",
      "Current Test: 88.30%\n",
      "3180000 images\n",
      "Current Test Previous: 67.97%\n",
      "Operational time of epoch #94: 2 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  95\n",
      "3200000 images\n",
      "Current Train: 90.51%\n",
      "Current Test: 88.10%\n",
      "Current Test Previous: 69.23%\n",
      "Operational time of epoch #95: 2 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  96\n",
      "3220000 images\n",
      "Current Train: 90.38%\n",
      "3240000 images\n",
      "Current Test: 87.67%\n",
      "Current Test Previous: 69.12%\n",
      "Operational time of epoch #96: 2 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  97\n",
      "3260000 images\n",
      "Current Train: 90.53%\n",
      "Current Test: 87.80%\n",
      "Current Test Previous: 68.35%\n",
      "Operational time of epoch #97: 2 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  98\n",
      "3280000 images\n",
      "3300000 images\n",
      "Current Train: 90.45%\n",
      "Current Test: 88.52%\n",
      "Current Test Previous: 69.97%\n",
      "Operational time of epoch #98: 2 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  99\n",
      "3320000 images\n",
      "Current Train: 90.61%\n",
      "Current Test: 88.17%\n",
      "3340000 images\n",
      "Current Test Previous: 67.53%\n",
      "Operational time of epoch #99: 2 min 38 sec\n",
      "==================== SUMMARY ====================\n",
      "        Best Train: 90.61% on 99 epoch\n",
      "         Best Test: 88.52% on 98 epoch\n",
      "Best Test Previous: 76.88% on 18 epoch\n"
     ]
    }
   ],
   "source": [
    "first_test = third_layer(file_name_net=\"saved_letters_after_digits+noise_total_0.net\",\n",
    "                        file_name_csv='parameter_set_letters_after_digits+noise_0.csv',\n",
    "                        adaptive_int=1.0, previous_epochs=0, epochs=100, \n",
    "                        train_loader=train_letter_loader, \n",
    "                        test_loader=test_letter_loader, \n",
    "                        test_previous_loader=test_MNIST_loader,\n",
    "                        model=mozafari, apr=apr, anr=anr, app=app, anp=anp, \n",
    "                        parametr_set=parametr_set, steps=0, percent=0, it_continues=False)\n",
    "\n",
    "parametr_set = first_test[0] \n",
    "counter = first_test[1] \n",
    "previous_epochs = first_test[2]\n",
    "apr = first_test[3] \n",
    "anr = first_test[4] \n",
    "app = first_test[5] \n",
    "anp = first_test[6]\n",
    "conv3_data_train = first_test[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "curve_graph(parametr_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
