{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (d) Few-short self-remainder (0.25% stored samples)\n",
    "### Training on a depleted set of digits + set of letters after training on a set of digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.cuda as cuda\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "try:\n",
    "    import accimage\n",
    "except ImportError:\n",
    "    accimage = None\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from SpykeTorch import snn\n",
    "from SpykeTorch import functional as sf\n",
    "from SpykeTorch import visualization as vis\n",
    "from SpykeTorch import utils\n",
    "\n",
    "import struct\n",
    "import glob\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#import import_ipynb\n",
    "#from MozafariMNIST2018_class import MozafariMNIST2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MozafariMNIST2018(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(MozafariMNIST2018, self).__init__()\n",
    "\n",
    "        self.conv1 = snn.Convolution(6, 30, 5, 0.8, 0.05)\n",
    "        self.conv1_t = 15\n",
    "        self.k1 = 5\n",
    "        self.r1 = 3\n",
    "\n",
    "        self.conv2 = snn.Convolution(30, 250, 3, 0.8, 0.05)\n",
    "        self.conv2_t = 10\n",
    "        self.k2 = 8\n",
    "        self.r2 = 1\n",
    "\n",
    "        self.conv3 = snn.Convolution(250, 200, 5, 0.8, 0.05)\n",
    "\n",
    "        self.stdp1 = snn.STDP(self.conv1, (0.004, -0.003))\n",
    "        self.stdp2 = snn.STDP(self.conv2, (0.004, -0.003))\n",
    "        self.stdp3 = snn.STDP(self.conv3, (0.004, -0.003), False, 0.2, 0.8)\n",
    "        self.anti_stdp3 = snn.STDP(self.conv3, (-0.004, 0.0005), False, 0.2, 0.8)\n",
    "        self.max_ap = Parameter(torch.Tensor([0.15]))\n",
    "\n",
    "        self.decision_map = []\n",
    "        for i in range(10):\n",
    "            self.decision_map.extend([i]*20)\n",
    "\n",
    "        self.ctx = {\"input_spikes\":None, \"potentials\":None, \"output_spikes\":None, \"winners\":None}\n",
    "        self.spk_cnt1 = 0\n",
    "        self.spk_cnt2 = 0\n",
    "\n",
    "    def forward(self, input, max_layer):\n",
    "        \n",
    "        input = sf.pad(input.float(), (2,2,2,2), 0)\n",
    "        \n",
    "        if self.training:\n",
    "            pot = self.conv1(input)\n",
    "            spk, pot = sf.fire(pot, self.conv1_t, True)\n",
    "            if max_layer == 1:\n",
    "                self.spk_cnt1 += 1\n",
    "                if self.spk_cnt1 >= 500:\n",
    "                    self.spk_cnt1 = 0\n",
    "                    ap = torch.tensor(self.stdp1.learning_rate[0][0].item(), device=self.stdp1.learning_rate[0][0].device) * 2\n",
    "                    ap = torch.min(ap, self.max_ap)\n",
    "                    an = ap * -0.75\n",
    "                    self.stdp1.update_all_learning_rate(ap.item(), an.item())\n",
    "                pot = sf.pointwise_inhibition(pot)\n",
    "                spk = pot.sign()\n",
    "                winners = sf.get_k_winners(pot, self.k1, self.r1, spk)\n",
    "                self.ctx[\"input_spikes\"] = input\n",
    "                self.ctx[\"potentials\"] = pot\n",
    "                self.ctx[\"output_spikes\"] = spk\n",
    "                self.ctx[\"winners\"] = winners\n",
    "                return spk, pot\n",
    "            \n",
    "            spk_in = sf.pad(sf.pooling(spk, 2, 2), (1,1,1,1))\n",
    "            pot = self.conv2(spk_in)\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "            if max_layer == 2:\n",
    "                self.spk_cnt2 += 1\n",
    "                if self.spk_cnt2 >= 500:\n",
    "                    self.spk_cnt2 = 0\n",
    "                    ap = torch.tensor(self.stdp2.learning_rate[0][0].item(), device=self.stdp2.learning_rate[0][0].device) * 2\n",
    "                    ap = torch.min(ap, self.max_ap)\n",
    "                    an = ap * -0.75\n",
    "                    self.stdp2.update_all_learning_rate(ap.item(), an.item())\n",
    "                pot = sf.pointwise_inhibition(pot)\n",
    "                spk = pot.sign()\n",
    "                winners = sf.get_k_winners(pot, self.k2, self.r2, spk)\n",
    "                self.ctx[\"input_spikes\"] = spk_in\n",
    "                self.ctx[\"potentials\"] = pot\n",
    "                self.ctx[\"output_spikes\"] = spk\n",
    "                self.ctx[\"winners\"] = winners\n",
    "                return spk, pot\n",
    "            \n",
    "            spk_in = sf.pad(sf.pooling(spk, 3, 3), (2,2,2,2))\n",
    "            pot = self.conv3(spk_in)\n",
    "            spk = sf.fire(pot)\n",
    "            winners = sf.get_k_winners(pot, 1, 0, spk)\n",
    "            self.ctx[\"input_spikes\"] = spk_in\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            output = -1\n",
    "            if len(winners) != 0:\n",
    "                output = self.decision_map[winners[0][0]]\n",
    "            return output\n",
    "        \n",
    "        else:\n",
    "            pot = self.conv1(input)\n",
    "            spk, pot = sf.fire(pot, self.conv1_t, True)\n",
    "            if max_layer == 1:\n",
    "                return spk, pot\n",
    "            \n",
    "            pot = self.conv2(sf.pad(sf.pooling(spk, 2, 2), (1,1,1,1)))\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "            if max_layer == 2:\n",
    "                return spk, pot\n",
    "            pot = self.conv3(sf.pad(sf.pooling(spk, 3, 3), (2,2,2,2)))\n",
    "            spk = sf.fire(pot)\n",
    "            winners = sf.get_k_winners(pot, 1, 0, spk)\n",
    "            output = -1\n",
    "            if len(winners) != 0:\n",
    "                output = self.decision_map[winners[0][0]]\n",
    "            return output\n",
    "\n",
    "    def stdp(self, layer_idx):\n",
    "        if layer_idx == 1:\n",
    "            self.stdp1(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 2:\n",
    "            self.stdp2(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "\n",
    "    def update_learning_rates(self, stdp_ap, stdp_an, anti_stdp_ap, anti_stdp_an):\n",
    "        self.stdp3.update_all_learning_rate(stdp_ap, stdp_an)\n",
    "        self.anti_stdp3.update_all_learning_rate(anti_stdp_an, anti_stdp_ap)\n",
    "\n",
    "    def reward(self):\n",
    "        self.stdp3(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "\n",
    "    def punish(self):\n",
    "        self.anti_stdp3(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test\n",
    "\n",
    "def train_unsupervise(network, data, layer_idx):\n",
    "    network.train()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "        network(data_in, layer_idx)\n",
    "        network.stdp(layer_idx)\n",
    "\n",
    "def train_rl(network, data, target):\n",
    "    network.train()\n",
    "    perf = np.array([0,0,0]) # correct, wrong, silence\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        target_in = target[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "            target_in = target_in.cuda()\n",
    "        d = network(data_in, 3)\n",
    "        if d != -1:\n",
    "            if d == target_in:\n",
    "                perf[0]+=1\n",
    "                network.reward()\n",
    "            else:\n",
    "                perf[1]+=1\n",
    "                network.punish()\n",
    "        else:\n",
    "            perf[2]+=1\n",
    "    return perf/len(data)\n",
    "\n",
    "def test(network, data, target):\n",
    "    network.eval()\n",
    "    perf = np.array([0,0,0]) # correct, wrong, silence\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        target_in = target[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "            target_in = target_in.cuda()\n",
    "        d = network(data_in, 3)\n",
    "        if d != -1:\n",
    "            if d == target_in:\n",
    "                perf[0]+=1\n",
    "            else:\n",
    "                perf[1]+=1\n",
    "        else:\n",
    "            perf[2]+=1\n",
    "    return perf/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_graph(parametr_set):\n",
    "\n",
    "    plt.subplots(figsize=(15, 5))\n",
    "\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['train']*100, color='cyan', label='train')\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['test']*100, color='blue', marker = 'o', label='test')\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['test_previous']*100, linestyle = ':', color='red', label='test of previous images')\n",
    "    plt.xlabel('epochs', loc='right', fontsize=17)\n",
    "    plt.ylabel('accuracy, %',  loc='top', fontsize=17)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train of 3-rd layer\n",
    "\n",
    "def third_layer(file_name_net, file_name_csv, adaptive_int, previous_epochs, epochs, \n",
    "                train_loader, test_loader, test_previous_loader,\n",
    "                model, apr, anr, app, anp, parametr_set, steps=None, percent=20, it_continues=False):  \n",
    "    \n",
    "    '''\n",
    "    file_name_net - name of file for saving state_dict of model\n",
    "    file_name_csv - name of file for saving parameters of model in each epoch\n",
    "    adaptive_int - learning rate parameter\n",
    "    previous_epochs - if before model had training in current period\n",
    "    it_continues - is it continue of 3-rd layer training or not (False or True)\n",
    "    percent - percent of moving weights (calculated from the number of high range weights)\n",
    "    '''\n",
    "\n",
    "    adaptive_min=0 \n",
    "\n",
    "    if not it_continues:\n",
    "\n",
    "        previous_epochs = 0\n",
    "        counter = 0\n",
    "\n",
    "        apr_adapt = ((1.0 - 1.0 / 10) * adaptive_int + adaptive_min) * apr\n",
    "        anr_adapt = ((1.0 - 1.0 / 10) * adaptive_int + adaptive_min) * anr\n",
    "        app_adapt = ((1.0 / 10) * adaptive_int + adaptive_min) * app\n",
    "        anp_adapt = ((1.0 / 10) * adaptive_int + adaptive_min) * anp\n",
    "        \n",
    "        best_train = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "        best_test = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "        best_test_previous = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "\n",
    "    else:\n",
    "      \n",
    "        if len(parametr_set.loc[parametr_set['test'] == parametr_set['test'].max(), 'epoch']) == 1:\n",
    "            optim_index = int(parametr_set.loc[parametr_set['test'] == parametr_set['test'].max(), 'epoch'].item())\n",
    "        else:\n",
    "            optim_index = int(parametr_set.loc[parametr_set['test'] == parametr_set['test'].max(), 'epoch'].tolist()[-1])\n",
    "\n",
    "        if len(parametr_set.loc[parametr_set['train'] == parametr_set['train'].max(), 'epoch']) == 1:\n",
    "            best_train_index = int(parametr_set.loc[parametr_set['train'] == parametr_set['train'].max(), 'epoch'].item())\n",
    "        else:\n",
    "            best_train_index = int(parametr_set.loc[parametr_set['train'] == parametr_set['train'].max(), 'epoch'].tolist()[-1])\n",
    "\n",
    "        if len(parametr_set.loc[parametr_set['test_previous'] == parametr_set['test_previous'].max(), 'epoch']) == 1:\n",
    "            best_test_previous_index = int(parametr_set.loc[parametr_set['test_previous'] == parametr_set['test_previous'].max(), 'epoch'].item())\n",
    "        else:\n",
    "            best_test_previous_index = int(parametr_set.loc[parametr_set['test_previous'] == parametr_set['test_previous'].max(), 'epoch'].tolist()[-1])\n",
    "        \n",
    "        max_index = int(parametr_set.index.max())\n",
    "        counter = (max_index + 1)\n",
    "\n",
    "        param_best_train = parametr_set['train'].iloc[best_train_index]\n",
    "        param_best_test = parametr_set['test'].iloc[optim_index]\n",
    "        param_best_test_previous = parametr_set['test_previous'].iloc[best_test_previous_index]\n",
    "\n",
    "        apr_adapt = parametr_set['apr_adapt'].iloc[optim_index]\n",
    "        anr_adapt = parametr_set['anr_adapt'].iloc[optim_index]\n",
    "        app_adapt = parametr_set['app_adapt'].iloc[optim_index]\n",
    "        anp_adapt = parametr_set['anp_adapt'].iloc[optim_index]\n",
    "        \n",
    "        for i in range(len(mozafari.stdp3.learning_rate)):\n",
    "            mozafari.stdp3.learning_rate[i][0].fill_(parametr_set['stdp3.learning_rate[0]'].iloc[optim_index])\n",
    "            mozafari.stdp3.learning_rate[i][1].fill_(parametr_set['stdp3.learning_rate[1]'].iloc[optim_index])\n",
    "            mozafari.anti_stdp3.learning_rate[0][0].fill_(parametr_set['anti_stdp3.learning_rate[0]'].iloc[optim_index])\n",
    "            mozafari.anti_stdp3.learning_rate[0][0].fill_(parametr_set['anti_stdp3.learning_rate[1]'].iloc[optim_index])\n",
    "\n",
    "        best_train = np.array([param_best_train,1-param_best_train,0.0,best_train_index]) # correct, wrong, silence, epoch\n",
    "        best_test = np.array([param_best_test,1-param_best_test,0.0,optim_index]) # correct, wrong, silence, epoch\n",
    "        best_test_previous = np.array([param_best_test_previous,1-param_best_test_previous,0.0,best_test_previous_index]) # correct, wrong, silence, epoch\n",
    "    \n",
    "    # list of 3-rd layer weights\n",
    "\n",
    "    dim_0, dim_1, dim_2, dim_3 = tuple(mozafari.conv3.weight.size())\n",
    "    total_size = dim_0 * dim_1 * dim_2 * dim_3\n",
    "  \n",
    "    # indexes of weights\n",
    "    indexes_i = []    \n",
    "    indexes_j = []        \n",
    "    indexes_k = []        \n",
    "    indexes_m = []    \n",
    "    \n",
    "    # values of weights\n",
    "    item_values = []  \n",
    "    \n",
    "    for i in range(dim_0):\n",
    "        for j in range(dim_1):\n",
    "            for k in range(dim_2):\n",
    "                for m in range(dim_3):\n",
    "                    indexes_i.append(i)\n",
    "                    indexes_j.append(j)\n",
    "                    indexes_k.append(k)\n",
    "                    indexes_m.append(m)\n",
    "                    item_values.append(mozafari.conv3.weight[i][j][k][m].item())\n",
    "\n",
    "    indexes_dim_0 = pd.Series(indexes_i, name='dim_0') \n",
    "    indexes_dim_1 = pd.Series(indexes_j, name='dim_1')\n",
    "    indexes_dim_2 = pd.Series(indexes_k, name='dim_2')\n",
    "    indexes_dim_3 = pd.Series(indexes_m, name='dim_3')\n",
    "    item_values = pd.Series(item_values, name='value_0')\n",
    "            \n",
    "    conv3_data = pd.concat([item_values, indexes_dim_0, indexes_dim_1, indexes_dim_2, indexes_dim_3], axis=1)\n",
    "    \n",
    "    high_percent = 85 #percent of high range weights\n",
    "    percentile_value = np.percentile(item_values, high_percent)\n",
    "    \n",
    "    conv3_data['low_range_0'] = 0\n",
    "    conv3_data.loc[conv3_data['value_0'] < percentile_value,'low_range_0'] = 1\n",
    "    \n",
    "    try:\n",
    "        high_range_counter = conv3_data['low_range_0'].value_counts()[0] \n",
    "    except:\n",
    "        high_range_counter = 1\n",
    " \n",
    "    moving_quantity = int((percent/100)*high_range_counter) #quantity of moving items in each epoch\n",
    "    \n",
    "    if steps is None:\n",
    "        steps = int(total_size*high_percent/(100*moving_quantity))   #steps of weights moving \n",
    "    print(f'Weight moving will be during {steps} epochs')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        seconds_epoch_0 = time.time() \n",
    "        \n",
    "        print('-'*50)\n",
    "        print(\"Epoch #: \", epoch + previous_epochs)\n",
    "        \n",
    "        perf_train = np.array([0.0,0.0,0.0]) \n",
    "        \n",
    "        for data,targets in train_loader:\n",
    "                \n",
    "            if epoch < steps: \n",
    "                \n",
    "                print(f'Values of high range weights in epoch#{epoch} [{percentile_value :.3f}:0.800] (top {100-high_percent}%)')\n",
    "                low_range_indexes = list(conv3_data.index[conv3_data['low_range_'+str(epoch)] == 1])\n",
    "                moving_items = random.sample(low_range_indexes, np.minimum(moving_quantity, len(low_range_indexes)))\n",
    "                moving_indexes = conv3_data.loc[conv3_data.index.isin(moving_items)]\n",
    "\n",
    "                print(f'Quantity of moving points in epoch#{epoch + previous_epochs} = {len(moving_indexes.index)} items' \n",
    "                      f' ({len(moving_indexes.index)/(total_size-high_range_counter)*100 :.1f}% of moving points)')\n",
    "\n",
    "                for q in range(len(moving_indexes.index)):\n",
    "                    mozafari.conv3.weight \\\n",
    "                    [moving_indexes['dim_0'].iloc[q]][moving_indexes['dim_1'].iloc[q]][moving_indexes['dim_2'].iloc[q]][moving_indexes['dim_3'].iloc[q]]. \\\n",
    "                    fill_(np.random.normal(loc=0.8, scale=0.05))  \n",
    "              \n",
    "            perf_train_batch = train_rl(model, data, targets)\n",
    "    \n",
    "            if epoch < steps:  \n",
    "            \n",
    "                # new values of weights (after learning)\n",
    "                item_values = []       \n",
    "                for i in range(dim_0):\n",
    "                    for j in range(dim_1):\n",
    "                        for k in range(dim_2):\n",
    "                            for m in range(dim_3):\n",
    "                                item_values.append(mozafari.conv3.weight[i][j][k][m].item())\n",
    "            \n",
    "                item_values = pd.Series(item_values, name='value_'+str(epoch+1))\n",
    "                percentile_value = np.percentile(item_values, high_percent) #new cutting off high range weights\n",
    "                conv3_data = pd.concat([conv3_data, item_values], axis=1)\n",
    "                \n",
    "                conv3_data['low_range_'+str(epoch+1)] = 0\n",
    "                conv3_data.loc[conv3_data['value_'+str(epoch+1)] < percentile_value,'low_range_'+str(epoch+1)] = 1\n",
    "       \n",
    "            #update adaptive learning rates\n",
    "            apr_adapt = apr * (perf_train_batch[1] * adaptive_int + adaptive_min)\n",
    "            anr_adapt = anr * (perf_train_batch[1] * adaptive_int + adaptive_min)\n",
    "            app_adapt = app * (perf_train_batch[0] * adaptive_int + adaptive_min)\n",
    "            anp_adapt = anp * (perf_train_batch[0] * adaptive_int + adaptive_min)\n",
    "            parametr_set.loc[counter, 'epoch'] = epoch + previous_epochs\n",
    "            parametr_set.loc[counter, 'apr_adapt'] = apr_adapt\n",
    "            parametr_set.loc[counter, 'anr_adapt'] = anr_adapt\n",
    "            parametr_set.loc[counter, 'app_adapt'] = app_adapt\n",
    "            parametr_set.loc[counter, 'anp_adapt'] = anp_adapt\n",
    "            parametr_set.loc[counter, 'stdp3.learning_rate[0]'] = mozafari.stdp3.learning_rate[0][0].item()\n",
    "            parametr_set.loc[counter, 'stdp3.learning_rate[1]'] = mozafari.stdp3.learning_rate[0][1].item()\n",
    "            parametr_set.loc[counter, 'anti_stdp3.learning_rate[0]'] = mozafari.anti_stdp3.learning_rate[0][0].item()\n",
    "            parametr_set.loc[counter, 'anti_stdp3.learning_rate[1]'] = mozafari.anti_stdp3.learning_rate[0][1].item()\n",
    "            parametr_set.loc[counter, 'train'] = perf_train_batch[0]\n",
    "\n",
    "            model.update_learning_rates(apr_adapt, anr_adapt, app_adapt, anp_adapt)\n",
    "            perf_train += perf_train_batch\n",
    "            \n",
    "        perf_train /= len(train_loader)\n",
    "\n",
    "        if best_train[0] <= perf_train[0]:\n",
    "            best_train = np.append(perf_train, epoch + previous_epochs)\n",
    "        print(f\"Current Train: {perf_train[0]*100 :.2f}%\")\n",
    "        #print(\"   Best Train:\", best_train)\n",
    "\n",
    "        for data,targets in test_loader:\n",
    "            perf_test = test(model, data, targets)\n",
    "            parametr_set.loc[counter, 'test'] = perf_test[0]\n",
    "            if best_test[0] <= perf_test[0]:\n",
    "                best_test = np.append(perf_test, epoch + previous_epochs)\n",
    "                torch.save(model.state_dict(), file_name_net)\n",
    "            print(f\"Current Test: {perf_test[0]*100 :.2f}%\")\n",
    "            #print(\"    Best Test:\", best_test)\n",
    "\n",
    "        if isinstance(test_previous_loader, DataLoader):\n",
    "            for data,targets in test_previous_loader:\n",
    "                perf_test_previous = test(model, data, targets)\n",
    "                parametr_set.loc[counter, 'test_previous'] = perf_test_previous[0]\n",
    "                if best_test_previous[0] <= perf_test_previous[0]:\n",
    "                    best_test_previous = np.append(perf_test_previous, epoch + previous_epochs)\n",
    "                print(f\"Current Test Previous: {perf_test_previous[0]*100 :.2f}%\")\n",
    "                #print(\"    Best Test Previous:\", best_test_previous)\n",
    "                \n",
    "        else:\n",
    "            parametr_set.loc[counter, 'test_previous'] = 0\n",
    "            \n",
    "        counter += 1\n",
    "                                                 \n",
    "        seconds_epoch_1 = time.time()  \n",
    "        print(f'Operational time of epoch #{epoch + previous_epochs}: '\n",
    "                  f'{int((seconds_epoch_1 - seconds_epoch_0)//60)} min {int((seconds_epoch_1 - seconds_epoch_0)%60)} sec') \n",
    "    \n",
    "    parametr_set.to_csv(file_name_csv)\n",
    "    \n",
    "    print('=='*10, 'SUMMARY', '=='*10)\n",
    "    print(f\"        Best Train: {best_train[0]*100 :.2f}% on {best_train[3] :.0f} epoch\")\n",
    "    print(f\"         Best Test: {best_test[0]*100 :.2f}% on {best_test[3] :.0f} epoch\")\n",
    "    print(f\"Best Test Previous: {best_test_previous[0]*100 :.2f}% on {best_test_previous[3] :.0f} epoch\")\n",
    "    \n",
    "    return parametr_set, counter, (previous_epochs+epochs), apr, anr, app, anp, conv3_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "class S1C1Transform:\n",
    "    \n",
    "    def __init__(self, filter, PIL_type=False, timesteps = 15):\n",
    "        self.PIL_type = PIL_type\n",
    "        self.to_pil_image = transforms.ToPILImage()    \n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.filter = filter\n",
    "        self.temporal_transform = utils.Intensity2Latency(timesteps)\n",
    "        self.cnt = 0\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        if self.cnt % 10000 == 0:\n",
    "            print(f'{self.cnt} images')\n",
    "        if self.PIL_type:\n",
    "            image = self.to_pil_image(image)\n",
    "        self.cnt+=1\n",
    "        image = self.to_tensor(image) * 255\n",
    "        image.unsqueeze_(0)\n",
    "        image = self.filter(image)\n",
    "        image = sf.local_normalization(image, 8)\n",
    "        temporal_image = self.temporal_transform(image)\n",
    "        return temporal_image.sign().byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "kernels = [ utils.DoGKernel(3,3/9,6/9),\n",
    "            utils.DoGKernel(3,6/9,3/9),\n",
    "            utils.DoGKernel(7,7/9,14/9),\n",
    "            utils.DoGKernel(7,14/9,7/9),\n",
    "            utils.DoGKernel(13,13/9,26/9),\n",
    "            utils.DoGKernel(13,26/9,13/9)]\n",
    "\n",
    "filter = utils.Filter(kernels, padding = 6, thresholds = 50)\n",
    "\n",
    "s1c1 = S1C1Transform(filter)\n",
    "s1c1_PIL = S1C1Transform(filter, PIL_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "class CustomTensorDataset(Dataset):\n",
    "    \"\"\"TensorDataset with support of transforms.\"\"\"\n",
    "    \n",
    "    def __init__(self, tensors, transform=None):\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[0][index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        y = self.tensors[1][index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensors[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "\n",
    "def pred(network, data, target):\n",
    "    prediction_d = []\n",
    "    target_ = [] \n",
    "    network.eval()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        data_in = data[i]\n",
    "        target_in = target[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "            target_in = target_in.cuda()\n",
    "        pred_d = network(data_in, 3)\n",
    "            \n",
    "        prediction_d.append(pred_d)\n",
    "        target_.append(target_in)\n",
    "        \n",
    "    return prediction_d, target_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depleted digit sets\n",
    "24000 train and 4000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the set contains only 0.25% of the original images of 10 digits (the rest of the images are duplicates of the original)\n",
    "\n",
    "path = f'./data/MNIST_depleted_sets/'\n",
    "\n",
    "for i in classes:\n",
    "    globals()[f'train_depleted_digit_{i}_images'] = \\\n",
    "        torch.load(f'{path}depleted_train_{i}_images.pt', map_location=torch.device('cpu'))[0:2400]\n",
    "    globals()[f'test_depleted_digit_{i}_images'] = \\\n",
    "        torch.load(f'{path}depleted_test_{i}_images.pt', map_location=torch.device('cpu'))[0:400]\n",
    "    globals()[f'train_depleted_digit_{i}_lables'] = \\\n",
    "        torch.load(f'{path}depleted_train_{i}_lables.pt', map_location=torch.device('cpu'))[0:2400]\n",
    "    globals()[f'test_depleted_digit_{i}_lables'] = \\\n",
    "        torch.load(f'{path}depleted_test_{i}_lables.pt', map_location=torch.device('cpu'))[0:400]\n",
    "    \n",
    "train_depleted_digit_images = train_depleted_digit_0_images\n",
    "train_depleted_digit_lables = train_depleted_digit_0_lables\n",
    "\n",
    "test_depleted_digit_images = test_depleted_digit_0_images\n",
    "test_depleted_digit_lables = test_depleted_digit_0_lables\n",
    "    \n",
    "for i in range(1, 10):    \n",
    "    train_depleted_digit_images = torch.cat((train_depleted_digit_images, \\\n",
    "                                                        globals()[f'train_depleted_digit_{i}_images']), 0)\n",
    "    train_depleted_digit_lables = torch.cat((train_depleted_digit_lables, \\\n",
    "                                                            globals()[f'train_depleted_digit_{i}_lables']), 0)\n",
    "    \n",
    "    test_depleted_digit_images = torch.cat((test_depleted_digit_images, \\\n",
    "                                                        globals()[f'test_depleted_digit_{i}_images']), 0)\n",
    "    test_depleted_digit_lables = torch.cat((test_depleted_digit_lables, \\\n",
    "                                                            globals()[f'test_depleted_digit_{i}_lables']), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element permutation\n",
    "\n",
    "train_order = torch.randperm(train_depleted_digit_lables.shape[0])\n",
    "test_order = torch.randperm(test_depleted_digit_lables.shape[0])\n",
    "\n",
    "train_depleted_digit_lables = train_depleted_digit_lables[train_order].view(train_depleted_digit_lables.size())\n",
    "train_depleted_digit_images = train_depleted_digit_images[train_order].view(train_depleted_digit_images.size())\n",
    "\n",
    "test_depleted_digit_lables = test_depleted_digit_lables[test_order].view(test_depleted_digit_lables.size())\n",
    "test_depleted_digit_images = test_depleted_digit_images[test_order].view(test_depleted_digit_images.size())\n",
    "\n",
    "# Loaders\n",
    "\n",
    "train_depleted_digit_set = CustomTensorDataset(tensors=(train_depleted_digit_images, train_depleted_digit_lables), transform=s1c1_PIL)\n",
    "test_depleted_digit_set = CustomTensorDataset(tensors=(test_depleted_digit_images, test_depleted_digit_lables), transform=s1c1_PIL)\n",
    "\n",
    "train_depleted_digit_loader = DataLoader(train_depleted_digit_set, batch_size=len(train_depleted_digit_set))\n",
    "test_depleted_digit_loader = DataLoader(test_depleted_digit_set, batch_size=len(test_depleted_digit_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of 10 MNIST digits\n",
    "60000 train images + 10000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial dataset\n",
    "\n",
    "data_root = \"data\"\n",
    "\n",
    "MNIST_train = utils.CacheDataset(torchvision.datasets.MNIST(root=data_root, train=True, download=True, transform = s1c1))\n",
    "MNIST_test = utils.CacheDataset(torchvision.datasets.MNIST(root=data_root, train=False, download=True, transform = s1c1))\n",
    "\n",
    "train_MNIST_loader = DataLoader(MNIST_train, batch_size=len(MNIST_train), shuffle=False)\n",
    "test_MNIST_loader = DataLoader(MNIST_test, batch_size=len(MNIST_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of 10 capital letters\n",
    "24000 train images + 4000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of 10 capital letters from EMNIST\n",
    "\n",
    "path = f'./data/EMNIST_own/capital_letters/'\n",
    "\n",
    "test_letter_labels = torch.load(f'{path}Mozafari_capital_letters_test_labels.pt', map_location=torch.device('cpu'))\n",
    "test_letters = torch.load(f'{path}Mozafari_capital_letters_test_images.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "train_letter_labels = torch.load(f'{path}Mozafari_capital_letters_train_labels.pt', map_location=torch.device('cpu'))\n",
    "train_letters = torch.load(f'{path}Mozafari_capital_letters_train_images.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "# Element permutation\n",
    "\n",
    "train_order_l = torch.randperm(train_letter_labels.shape[0])\n",
    "test_order_l = torch.randperm(test_letter_labels.shape[0])\n",
    "\n",
    "train_letter_labels = train_letter_labels[train_order_l].view(train_letter_labels.size())\n",
    "train_letters = train_letters[train_order_l].view(train_letters.size())\n",
    "\n",
    "test_letter_labels = test_letter_labels[test_order_l].view(test_letter_labels.size())\n",
    "test_letters = test_letters[test_order_l].view(test_letters.size())\n",
    "\n",
    "# Loaders\n",
    "\n",
    "train_letter_set = CustomTensorDataset(tensors=(train_letters, train_letter_labels), transform=s1c1_PIL)\n",
    "test_letter_set = CustomTensorDataset(tensors=(test_letters, test_letter_labels), transform=s1c1_PIL)\n",
    "\n",
    "train_letter_loader = DataLoader(train_letter_set, batch_size=len(train_letter_set))\n",
    "test_letter_loader = DataLoader(test_letter_set, batch_size=len(test_letter_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined set of depleted digit set + capital letter set\n",
    "\n",
    "48000 train + 8000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined set\n",
    "\n",
    "train_combi_labels = torch.cat((train_depleted_digit_lables, train_letter_labels), 0)\n",
    "train_combi_images = torch.cat((train_depleted_digit_images, train_letters), 0)\n",
    "test_combi_labels = torch.cat((test_depleted_digit_lables, test_letter_labels), 0)\n",
    "test_combi_images = torch.cat((test_depleted_digit_images, test_letters), 0)\n",
    "\n",
    "# Element permutation\n",
    "\n",
    "train_order_c = torch.randperm(train_combi_labels.shape[0])\n",
    "test_order_c = torch.randperm(test_combi_labels.shape[0])\n",
    "\n",
    "train_combi_labels = train_combi_labels[train_order_c].view(train_combi_labels.size())\n",
    "train_combi_images = train_combi_images[train_order_c].view(train_combi_images.size())\n",
    "\n",
    "test_combi_labels = test_combi_labels[test_order_c].view(test_combi_labels.size())\n",
    "test_combi_images = test_combi_images[test_order_c].view(test_combi_images.size())\n",
    "\n",
    "# Loaders\n",
    "\n",
    "train_combi_set = CustomTensorDataset(tensors=(train_combi_images, \\\n",
    "                                                train_combi_labels), transform=s1c1_PIL)\n",
    "test_combi_set = CustomTensorDataset(tensors=(test_combi_images, \\\n",
    "                                                test_combi_labels), transform=s1c1_PIL)\n",
    "\n",
    "train_combi_loader = DataLoader(train_combi_set, batch_size=len(train_combi_set))\n",
    "test_combi_loader = DataLoader(test_combi_set, batch_size=len(test_combi_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mozafari = MozafariMNIST2018()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MozafariMNIST2018(\n",
       "  (conv1): Convolution()\n",
       "  (conv2): Convolution()\n",
       "  (conv3): Convolution()\n",
       "  (stdp1): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (stdp2): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (stdp3): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (anti_stdp3): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    mozafari.cuda()   \n",
    "\n",
    "mozafari.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous learning  \n",
    "Training on combi set of digits (depleted set, 0.25% stored samples) + letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving all values of parameters before training on digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_from_scratch = {'stdp1': [mozafari.stdp1.learning_rate[0][0].item(), \n",
    "                                        mozafari.stdp1.learning_rate[0][1].item()],\n",
    "                              'stdp2': [mozafari.stdp2.learning_rate[0][0].item(), \n",
    "                                        mozafari.stdp2.learning_rate[0][1].item()],\n",
    "                              'stdp3': [mozafari.stdp3.learning_rate[0][0].item(), \n",
    "                                        mozafari.stdp3.learning_rate[0][1].item()],\n",
    "                              'anti_stdp3': [mozafari.anti_stdp3.learning_rate[0][0].item(), \n",
    "                                             mozafari.anti_stdp3.learning_rate[0][1].item()]\n",
    "                             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of SNN trained on 24,000 images of digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file \"saved_24000_digits.net\" is the result of the file \"Initial_learning_of_SNN_on_digits.ipynb\"\n",
    "mozafari.load_state_dict(torch.load(\"saved_24000_digits.net\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the first layer\n",
      "Epoch 0\n",
      "0 images\n",
      "10000 images\n",
      "20000 images\n",
      "30000 images\n",
      "40000 images\n",
      "Iteration 0\n",
      "Done!\n",
      "Epoch 1\n",
      "50000 images\n",
      "60000 images\n",
      "70000 images\n",
      "80000 images\n",
      "90000 images\n",
      "Iteration 0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the first layer\")\n",
    "\n",
    "for epoch in range(2):\n",
    "    print(\"Epoch\", epoch)\n",
    "    iter = 0\n",
    "    for data, targets in train_combi_loader:\n",
    "        print(\"Iteration\", iter)\n",
    "        train_unsupervise(mozafari, data, 1)\n",
    "        print(\"Done!\")\n",
    "        iter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the second layer\n",
      "Epoch 0\n",
      "100000 images\n",
      "110000 images\n",
      "120000 images\n",
      "130000 images\n",
      "140000 images\n",
      "Iteration 0\n",
      "Done!\n",
      "Epoch 1\n",
      "150000 images\n",
      "160000 images\n",
      "170000 images\n",
      "180000 images\n",
      "190000 images\n",
      "Iteration 0\n",
      "Done!\n",
      "Epoch 2\n",
      "200000 images\n",
      "210000 images\n",
      "220000 images\n",
      "230000 images\n",
      "Iteration 0\n",
      "Done!\n",
      "Epoch 3\n",
      "240000 images\n",
      "250000 images\n",
      "260000 images\n",
      "270000 images\n",
      "280000 images\n",
      "Iteration 0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the second layer\")\n",
    "\n",
    "for epoch in range(4):\n",
    "    print(\"Epoch\", epoch)\n",
    "    iter = 0\n",
    "    for data,targets in train_combi_loader:\n",
    "        print(\"Iteration\", iter)\n",
    "        train_unsupervise(mozafari, data, 2)\n",
    "        print(\"Done!\")\n",
    "        iter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the third layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving learning_rates \n",
    "\n",
    "for i in range(len(mozafari.stdp3.learning_rate)):\n",
    "                    mozafari.stdp3.learning_rate[i][0].fill_(learning_rate_from_scratch['stdp3'][0])\n",
    "                    mozafari.stdp3.learning_rate[i][1].fill_(learning_rate_from_scratch['stdp3'][1])\n",
    "                    mozafari.anti_stdp3.learning_rate[i][0].fill_(learning_rate_from_scratch['anti_stdp3'][0])\n",
    "                    mozafari.anti_stdp3.learning_rate[i][1].fill_(learning_rate_from_scratch['anti_stdp3'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial adaptive learning rates\n",
    "\n",
    "apr = mozafari.stdp3.learning_rate[0][0].item()\n",
    "anr = mozafari.stdp3.learning_rate[0][1].item()\n",
    "app = mozafari.anti_stdp3.learning_rate[0][1].item()\n",
    "anp = mozafari.anti_stdp3.learning_rate[0][0].item()\n",
    "               \n",
    "parametr_set = pd.DataFrame(columns=['epoch', 'train', 'test', 'test_previous',   \n",
    "                                 'apr_adapt', 'anr_adapt', 'app_adapt', 'anp_adapt', \n",
    "                                 'stdp3.learning_rate[0]', 'stdp3.learning_rate[1]',\n",
    "                                 'anti_stdp3.learning_rate[0]', 'anti_stdp3.learning_rate[1]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight moving will be during 0 epochs\n",
      "--------------------------------------------------\n",
      "Epoch #:  0\n",
      "290000 images\n",
      "300000 images\n",
      "310000 images\n",
      "320000 images\n",
      "330000 images\n",
      "Current Train: 70.46%\n",
      "Current Test: 50.18%\n",
      "0 images\n",
      "Current Test Previous: 59.71%\n",
      "Operational time of epoch #0: 4 min 12 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  1\n",
      "340000 images\n",
      "350000 images\n",
      "360000 images\n",
      "370000 images\n",
      "380000 images\n",
      "Current Train: 75.98%\n",
      "390000 images\n",
      "Current Test: 54.17%\n",
      "Current Test Previous: 65.57%\n",
      "Operational time of epoch #1: 3 min 54 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  2\n",
      "400000 images\n",
      "410000 images\n",
      "420000 images\n",
      "430000 images\n",
      "Current Train: 77.21%\n",
      "440000 images\n",
      "Current Test: 55.75%\n",
      "Current Test Previous: 71.66%\n",
      "Operational time of epoch #2: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  3\n",
      "450000 images\n",
      "460000 images\n",
      "470000 images\n",
      "480000 images\n",
      "490000 images\n",
      "Current Train: 77.96%\n",
      "Current Test: 56.97%\n",
      "Current Test Previous: 74.57%\n",
      "Operational time of epoch #3: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  4\n",
      "500000 images\n",
      "510000 images\n",
      "520000 images\n",
      "530000 images\n",
      "540000 images\n",
      "Current Train: 78.42%\n",
      "Current Test: 57.83%\n",
      "Current Test Previous: 75.64%\n",
      "Operational time of epoch #4: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  5\n",
      "550000 images\n",
      "560000 images\n",
      "570000 images\n",
      "580000 images\n",
      "590000 images\n",
      "Current Train: 78.80%\n",
      "Current Test: 58.50%\n",
      "Current Test Previous: 75.91%\n",
      "Operational time of epoch #5: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  6\n",
      "600000 images\n",
      "610000 images\n",
      "620000 images\n",
      "630000 images\n",
      "640000 images\n",
      "Current Train: 79.65%\n",
      "650000 images\n",
      "Current Test: 60.38%\n",
      "Current Test Previous: 75.21%\n",
      "Operational time of epoch #6: 3 min 50 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  7\n",
      "660000 images\n",
      "670000 images\n",
      "680000 images\n",
      "690000 images\n",
      "Current Train: 80.80%\n",
      "700000 images\n",
      "Current Test: 62.58%\n",
      "Current Test Previous: 75.69%\n",
      "Operational time of epoch #7: 3 min 50 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  8\n",
      "710000 images\n",
      "720000 images\n",
      "730000 images\n",
      "740000 images\n",
      "750000 images\n",
      "Current Train: 81.51%\n",
      "Current Test: 63.35%\n",
      "Current Test Previous: 76.23%\n",
      "Operational time of epoch #8: 3 min 48 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  9\n",
      "760000 images\n",
      "770000 images\n",
      "780000 images\n",
      "790000 images\n",
      "800000 images\n",
      "Current Train: 81.88%\n",
      "Current Test: 64.05%\n",
      "Current Test Previous: 76.70%\n",
      "Operational time of epoch #9: 3 min 46 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  10\n",
      "810000 images\n",
      "820000 images\n",
      "830000 images\n",
      "840000 images\n",
      "850000 images\n",
      "Current Train: 82.07%\n",
      "Current Test: 64.60%\n",
      "Current Test Previous: 76.76%\n",
      "Operational time of epoch #10: 3 min 47 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  11\n",
      "860000 images\n",
      "870000 images\n",
      "880000 images\n",
      "890000 images\n",
      "900000 images\n",
      "Current Train: 82.27%\n",
      "910000 images\n",
      "Current Test: 64.78%\n",
      "Current Test Previous: 76.62%\n",
      "Operational time of epoch #11: 3 min 51 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  12\n",
      "920000 images\n",
      "930000 images\n",
      "940000 images\n",
      "950000 images\n",
      "Current Train: 82.36%\n",
      "960000 images\n",
      "Current Test: 64.72%\n",
      "Current Test Previous: 76.56%\n",
      "Operational time of epoch #12: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  13\n",
      "970000 images\n",
      "980000 images\n",
      "990000 images\n",
      "1000000 images\n",
      "1010000 images\n",
      "Current Train: 82.47%\n",
      "Current Test: 64.95%\n",
      "Current Test Previous: 76.43%\n",
      "Operational time of epoch #13: 3 min 43 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  14\n",
      "1020000 images\n",
      "1030000 images\n",
      "1040000 images\n",
      "1050000 images\n",
      "1060000 images\n",
      "Current Train: 82.54%\n",
      "Current Test: 65.18%\n",
      "Current Test Previous: 76.49%\n",
      "Operational time of epoch #14: 3 min 46 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  15\n",
      "1070000 images\n",
      "1080000 images\n",
      "1090000 images\n",
      "1100000 images\n",
      "1110000 images\n",
      "Current Train: 82.62%\n",
      "Current Test: 65.38%\n",
      "Current Test Previous: 76.60%\n",
      "Operational time of epoch #15: 3 min 47 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  16\n",
      "1120000 images\n",
      "1130000 images\n",
      "1140000 images\n",
      "1150000 images\n",
      "1160000 images\n",
      "Current Train: 82.74%\n",
      "1170000 images\n",
      "Current Test: 65.53%\n",
      "Current Test Previous: 76.51%\n",
      "Operational time of epoch #16: 3 min 47 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  17\n",
      "1180000 images\n",
      "1190000 images\n",
      "1200000 images\n",
      "1210000 images\n",
      "Current Train: 82.82%\n",
      "1220000 images\n",
      "Current Test: 65.83%\n",
      "Current Test Previous: 76.54%\n",
      "Operational time of epoch #17: 3 min 47 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  18\n",
      "1230000 images\n",
      "1240000 images\n",
      "1250000 images\n",
      "1260000 images\n",
      "1270000 images\n",
      "Current Train: 82.87%\n",
      "Current Test: 65.75%\n",
      "Current Test Previous: 76.72%\n",
      "Operational time of epoch #18: 3 min 49 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  19\n",
      "1280000 images\n",
      "1290000 images\n",
      "1300000 images\n",
      "1310000 images\n",
      "1320000 images\n",
      "Current Train: 83.00%\n",
      "Current Test: 66.17%\n",
      "Current Test Previous: 76.65%\n",
      "Operational time of epoch #19: 3 min 51 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  20\n",
      "1330000 images\n",
      "1340000 images\n",
      "1350000 images\n",
      "1360000 images\n",
      "1370000 images\n",
      "Current Train: 83.14%\n",
      "Current Test: 66.42%\n",
      "Current Test Previous: 76.67%\n",
      "Operational time of epoch #20: 3 min 51 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  21\n",
      "1380000 images\n",
      "1390000 images\n",
      "1400000 images\n",
      "1410000 images\n",
      "1420000 images\n",
      "Current Train: 83.22%\n",
      "1430000 images\n",
      "Current Test: 66.65%\n",
      "Current Test Previous: 76.78%\n",
      "Operational time of epoch #21: 3 min 52 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  22\n",
      "1440000 images\n",
      "1450000 images\n",
      "1460000 images\n",
      "1470000 images\n",
      "Current Train: 83.34%\n",
      "1480000 images\n",
      "Current Test: 66.75%\n",
      "Current Test Previous: 76.71%\n",
      "Operational time of epoch #22: 3 min 54 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  23\n",
      "1490000 images\n",
      "1500000 images\n",
      "1510000 images\n",
      "1520000 images\n",
      "1530000 images\n",
      "Current Train: 83.45%\n",
      "Current Test: 67.00%\n",
      "Current Test Previous: 76.77%\n",
      "Operational time of epoch #23: 3 min 52 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  24\n",
      "1540000 images\n",
      "1550000 images\n",
      "1560000 images\n",
      "1570000 images\n",
      "1580000 images\n",
      "Current Train: 83.60%\n",
      "Current Test: 66.97%\n",
      "Current Test Previous: 76.68%\n",
      "Operational time of epoch #24: 3 min 53 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  25\n",
      "1590000 images\n",
      "1600000 images\n",
      "1610000 images\n",
      "1620000 images\n",
      "1630000 images\n",
      "Current Train: 83.69%\n",
      "Current Test: 67.10%\n",
      "Current Test Previous: 76.66%\n",
      "Operational time of epoch #25: 3 min 51 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  26\n",
      "1640000 images\n",
      "1650000 images\n",
      "1660000 images\n",
      "1670000 images\n",
      "1680000 images\n",
      "Current Train: 83.85%\n",
      "1690000 images\n",
      "Current Test: 67.15%\n",
      "Current Test Previous: 76.32%\n",
      "Operational time of epoch #26: 3 min 49 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  27\n",
      "1700000 images\n",
      "1710000 images\n",
      "1720000 images\n",
      "1730000 images\n",
      "Current Train: 84.05%\n",
      "1740000 images\n",
      "Current Test: 67.33%\n",
      "Current Test Previous: 76.35%\n",
      "Operational time of epoch #27: 3 min 53 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  28\n",
      "1750000 images\n",
      "1760000 images\n",
      "1770000 images\n",
      "1780000 images\n",
      "1790000 images\n",
      "Current Train: 84.21%\n",
      "Current Test: 67.38%\n",
      "Current Test Previous: 76.38%\n",
      "Operational time of epoch #28: 3 min 53 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  29\n",
      "1800000 images\n",
      "1810000 images\n",
      "1820000 images\n",
      "1830000 images\n",
      "1840000 images\n",
      "Current Train: 84.31%\n",
      "Current Test: 67.40%\n",
      "Current Test Previous: 76.49%\n",
      "Operational time of epoch #29: 3 min 50 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  30\n",
      "1850000 images\n",
      "1860000 images\n",
      "1870000 images\n",
      "1880000 images\n",
      "1890000 images\n",
      "Current Train: 84.41%\n",
      "Current Test: 67.62%\n",
      "Current Test Previous: 76.65%\n",
      "Operational time of epoch #30: 3 min 47 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  31\n",
      "1900000 images\n",
      "1910000 images\n",
      "1920000 images\n",
      "1930000 images\n",
      "1940000 images\n",
      "Current Train: 84.57%\n",
      "1950000 images\n",
      "Current Test: 68.00%\n",
      "Current Test Previous: 76.57%\n",
      "Operational time of epoch #31: 3 min 47 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960000 images\n",
      "1970000 images\n",
      "1980000 images\n",
      "1990000 images\n",
      "Current Train: 84.65%\n",
      "2000000 images\n",
      "Current Test: 68.35%\n",
      "Current Test Previous: 76.35%\n",
      "Operational time of epoch #32: 3 min 49 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  33\n",
      "2010000 images\n",
      "2020000 images\n",
      "2030000 images\n",
      "2040000 images\n",
      "2050000 images\n",
      "Current Train: 84.72%\n",
      "Current Test: 68.15%\n",
      "Current Test Previous: 76.55%\n",
      "Operational time of epoch #33: 3 min 50 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  34\n",
      "2060000 images\n",
      "2070000 images\n",
      "2080000 images\n",
      "2090000 images\n",
      "2100000 images\n",
      "Current Train: 84.78%\n",
      "Current Test: 68.40%\n",
      "Current Test Previous: 76.37%\n",
      "Operational time of epoch #34: 3 min 50 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  35\n",
      "2110000 images\n",
      "2120000 images\n",
      "2130000 images\n",
      "2140000 images\n",
      "2150000 images\n",
      "Current Train: 84.91%\n",
      "Current Test: 68.33%\n",
      "Current Test Previous: 76.49%\n",
      "Operational time of epoch #35: 3 min 50 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  36\n",
      "2160000 images\n",
      "2170000 images\n",
      "2180000 images\n",
      "2190000 images\n",
      "2200000 images\n",
      "Current Train: 85.00%\n",
      "2210000 images\n",
      "Current Test: 68.38%\n",
      "Current Test Previous: 76.60%\n",
      "Operational time of epoch #36: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  37\n",
      "2220000 images\n",
      "2230000 images\n",
      "2240000 images\n",
      "2250000 images\n",
      "Current Train: 85.12%\n",
      "2260000 images\n",
      "Current Test: 68.42%\n",
      "Current Test Previous: 76.49%\n",
      "Operational time of epoch #37: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  38\n",
      "2270000 images\n",
      "2280000 images\n",
      "2290000 images\n",
      "2300000 images\n",
      "2310000 images\n",
      "Current Train: 85.15%\n",
      "Current Test: 68.55%\n",
      "Current Test Previous: 76.46%\n",
      "Operational time of epoch #38: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  39\n",
      "2320000 images\n",
      "2330000 images\n",
      "2340000 images\n",
      "2350000 images\n",
      "2360000 images\n",
      "Current Train: 85.24%\n",
      "Current Test: 68.50%\n",
      "Current Test Previous: 76.52%\n",
      "Operational time of epoch #39: 3 min 47 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  40\n",
      "2370000 images\n",
      "2380000 images\n",
      "2390000 images\n",
      "2400000 images\n",
      "2410000 images\n",
      "Current Train: 85.24%\n",
      "Current Test: 68.77%\n",
      "Current Test Previous: 76.37%\n",
      "Operational time of epoch #40: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  41\n",
      "2420000 images\n",
      "2430000 images\n",
      "2440000 images\n",
      "2450000 images\n",
      "2460000 images\n",
      "Current Train: 85.34%\n",
      "2470000 images\n",
      "Current Test: 68.83%\n",
      "Current Test Previous: 76.25%\n",
      "Operational time of epoch #41: 3 min 47 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  42\n",
      "2480000 images\n",
      "2490000 images\n",
      "2500000 images\n",
      "2510000 images\n",
      "Current Train: 85.37%\n",
      "2520000 images\n",
      "Current Test: 68.90%\n",
      "Current Test Previous: 76.23%\n",
      "Operational time of epoch #42: 3 min 51 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  43\n",
      "2530000 images\n",
      "2540000 images\n",
      "2550000 images\n",
      "2560000 images\n",
      "2570000 images\n",
      "Current Train: 85.48%\n",
      "Current Test: 68.97%\n",
      "Current Test Previous: 76.02%\n",
      "Operational time of epoch #43: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  44\n",
      "2580000 images\n",
      "2590000 images\n",
      "2600000 images\n",
      "2610000 images\n",
      "2620000 images\n",
      "Current Train: 85.52%\n",
      "Current Test: 68.97%\n",
      "Current Test Previous: 75.96%\n",
      "Operational time of epoch #44: 3 min 54 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  45\n",
      "2630000 images\n",
      "2640000 images\n",
      "2650000 images\n",
      "2660000 images\n",
      "2670000 images\n",
      "Current Train: 85.60%\n",
      "Current Test: 69.30%\n",
      "Current Test Previous: 76.21%\n",
      "Operational time of epoch #45: 3 min 51 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  46\n",
      "2680000 images\n",
      "2690000 images\n",
      "2700000 images\n",
      "2710000 images\n",
      "2720000 images\n",
      "Current Train: 85.68%\n",
      "2730000 images\n",
      "Current Test: 69.27%\n",
      "Current Test Previous: 76.08%\n",
      "Operational time of epoch #46: 3 min 53 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  47\n",
      "2740000 images\n",
      "2750000 images\n",
      "2760000 images\n",
      "2770000 images\n",
      "Current Train: 85.78%\n",
      "2780000 images\n",
      "Current Test: 69.23%\n",
      "Current Test Previous: 75.92%\n",
      "Operational time of epoch #47: 3 min 53 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  48\n",
      "2790000 images\n",
      "2800000 images\n",
      "2810000 images\n",
      "2820000 images\n",
      "2830000 images\n",
      "Current Train: 85.85%\n",
      "Current Test: 69.53%\n",
      "Current Test Previous: 75.94%\n",
      "Operational time of epoch #48: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  49\n",
      "2840000 images\n",
      "2850000 images\n",
      "2860000 images\n",
      "2870000 images\n",
      "2880000 images\n",
      "Current Train: 85.96%\n",
      "Current Test: 69.75%\n",
      "Current Test Previous: 75.47%\n",
      "Operational time of epoch #49: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  50\n",
      "2890000 images\n",
      "2900000 images\n",
      "2910000 images\n",
      "2920000 images\n",
      "2930000 images\n",
      "Current Train: 86.07%\n",
      "Current Test: 70.08%\n",
      "Current Test Previous: 75.34%\n",
      "Operational time of epoch #50: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  51\n",
      "2940000 images\n",
      "2950000 images\n",
      "2960000 images\n",
      "2970000 images\n",
      "2980000 images\n",
      "Current Train: 86.19%\n",
      "2990000 images\n",
      "Current Test: 70.20%\n",
      "Current Test Previous: 75.38%\n",
      "Operational time of epoch #51: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  52\n",
      "3000000 images\n",
      "3010000 images\n",
      "3020000 images\n",
      "3030000 images\n",
      "Current Train: 86.30%\n",
      "3040000 images\n",
      "Current Test: 70.05%\n",
      "Current Test Previous: 75.20%\n",
      "Operational time of epoch #52: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  53\n",
      "3050000 images\n",
      "3060000 images\n",
      "3070000 images\n",
      "3080000 images\n",
      "3090000 images\n",
      "Current Train: 86.38%\n",
      "Current Test: 70.23%\n",
      "Current Test Previous: 75.22%\n",
      "Operational time of epoch #53: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  54\n",
      "3100000 images\n",
      "3110000 images\n",
      "3120000 images\n",
      "3130000 images\n",
      "3140000 images\n",
      "Current Train: 86.52%\n",
      "Current Test: 70.38%\n",
      "Current Test Previous: 75.17%\n",
      "Operational time of epoch #54: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  55\n",
      "3150000 images\n",
      "3160000 images\n",
      "3170000 images\n",
      "3180000 images\n",
      "3190000 images\n",
      "Current Train: 86.58%\n",
      "Current Test: 70.75%\n",
      "Current Test Previous: 75.16%\n",
      "Operational time of epoch #55: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  56\n",
      "3200000 images\n",
      "3210000 images\n",
      "3220000 images\n",
      "3230000 images\n",
      "3240000 images\n",
      "Current Train: 86.69%\n",
      "3250000 images\n",
      "Current Test: 70.70%\n",
      "Current Test Previous: 75.02%\n",
      "Operational time of epoch #56: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  57\n",
      "3260000 images\n",
      "3270000 images\n",
      "3280000 images\n",
      "3290000 images\n",
      "Current Train: 86.73%\n",
      "3300000 images\n",
      "Current Test: 70.78%\n",
      "Current Test Previous: 75.06%\n",
      "Operational time of epoch #57: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  58\n",
      "3310000 images\n",
      "3320000 images\n",
      "3330000 images\n",
      "3340000 images\n",
      "3350000 images\n",
      "Current Train: 86.81%\n",
      "Current Test: 70.93%\n",
      "Current Test Previous: 74.95%\n",
      "Operational time of epoch #58: 3 min 43 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  59\n",
      "3360000 images\n",
      "3370000 images\n",
      "3380000 images\n",
      "3390000 images\n",
      "3400000 images\n",
      "Current Train: 86.90%\n",
      "Current Test: 71.20%\n",
      "Current Test Previous: 74.89%\n",
      "Operational time of epoch #59: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  60\n",
      "3410000 images\n",
      "3420000 images\n",
      "3430000 images\n",
      "3440000 images\n",
      "3450000 images\n",
      "Current Train: 86.95%\n",
      "Current Test: 71.43%\n",
      "Current Test Previous: 74.79%\n",
      "Operational time of epoch #60: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  61\n",
      "3460000 images\n",
      "3470000 images\n",
      "3480000 images\n",
      "3490000 images\n",
      "3500000 images\n",
      "Current Train: 87.04%\n",
      "3510000 images\n",
      "Current Test: 71.58%\n",
      "Current Test Previous: 74.85%\n",
      "Operational time of epoch #61: 3 min 41 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  62\n",
      "3520000 images\n",
      "3530000 images\n",
      "3540000 images\n",
      "3550000 images\n",
      "Current Train: 87.06%\n",
      "3560000 images\n",
      "Current Test: 71.53%\n",
      "Current Test Previous: 74.96%\n",
      "Operational time of epoch #62: 3 min 43 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  63\n",
      "3570000 images\n",
      "3580000 images\n",
      "3590000 images\n",
      "3600000 images\n",
      "3610000 images\n",
      "Current Train: 87.10%\n",
      "Current Test: 71.70%\n",
      "Current Test Previous: 75.03%\n",
      "Operational time of epoch #63: 3 min 42 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3620000 images\n",
      "3630000 images\n",
      "3640000 images\n",
      "3650000 images\n",
      "3660000 images\n",
      "Current Train: 87.16%\n",
      "Current Test: 71.88%\n",
      "Current Test Previous: 74.97%\n",
      "Operational time of epoch #64: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  65\n",
      "3670000 images\n",
      "3680000 images\n",
      "3690000 images\n",
      "3700000 images\n",
      "3710000 images\n",
      "Current Train: 87.25%\n",
      "Current Test: 71.75%\n",
      "Current Test Previous: 74.96%\n",
      "Operational time of epoch #65: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  66\n",
      "3720000 images\n",
      "3730000 images\n",
      "3740000 images\n",
      "3750000 images\n",
      "3760000 images\n",
      "Current Train: 87.28%\n",
      "3770000 images\n",
      "Current Test: 71.97%\n",
      "Current Test Previous: 74.98%\n",
      "Operational time of epoch #66: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  67\n",
      "3780000 images\n",
      "3790000 images\n",
      "3800000 images\n",
      "3810000 images\n",
      "Current Train: 87.25%\n",
      "3820000 images\n",
      "Current Test: 72.08%\n",
      "Current Test Previous: 74.91%\n",
      "Operational time of epoch #67: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  68\n",
      "3830000 images\n",
      "3840000 images\n",
      "3850000 images\n",
      "3860000 images\n",
      "3870000 images\n",
      "Current Train: 87.32%\n",
      "Current Test: 72.17%\n",
      "Current Test Previous: 74.91%\n",
      "Operational time of epoch #68: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  69\n",
      "3880000 images\n",
      "3890000 images\n",
      "3900000 images\n",
      "3910000 images\n",
      "3920000 images\n",
      "Current Train: 87.38%\n",
      "Current Test: 72.30%\n",
      "Current Test Previous: 74.93%\n",
      "Operational time of epoch #69: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  70\n",
      "3930000 images\n",
      "3940000 images\n",
      "3950000 images\n",
      "3960000 images\n",
      "3970000 images\n",
      "Current Train: 87.47%\n",
      "Current Test: 72.40%\n",
      "Current Test Previous: 74.76%\n",
      "Operational time of epoch #70: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  71\n",
      "3980000 images\n",
      "3990000 images\n",
      "4000000 images\n",
      "4010000 images\n",
      "4020000 images\n",
      "Current Train: 87.53%\n",
      "4030000 images\n",
      "Current Test: 72.52%\n",
      "Current Test Previous: 74.73%\n",
      "Operational time of epoch #71: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  72\n",
      "4040000 images\n",
      "4050000 images\n",
      "4060000 images\n",
      "4070000 images\n",
      "Current Train: 87.58%\n",
      "4080000 images\n",
      "Current Test: 72.75%\n",
      "Current Test Previous: 74.58%\n",
      "Operational time of epoch #72: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  73\n",
      "4090000 images\n",
      "4100000 images\n",
      "4110000 images\n",
      "4120000 images\n",
      "4130000 images\n",
      "Current Train: 87.61%\n",
      "Current Test: 72.75%\n",
      "Current Test Previous: 74.44%\n",
      "Operational time of epoch #73: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  74\n",
      "4140000 images\n",
      "4150000 images\n",
      "4160000 images\n",
      "4170000 images\n",
      "4180000 images\n",
      "Current Train: 87.69%\n",
      "Current Test: 72.75%\n",
      "Current Test Previous: 74.47%\n",
      "Operational time of epoch #74: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  75\n",
      "4190000 images\n",
      "4200000 images\n",
      "4210000 images\n",
      "4220000 images\n",
      "4230000 images\n",
      "Current Train: 87.69%\n",
      "Current Test: 72.88%\n",
      "Current Test Previous: 74.60%\n",
      "Operational time of epoch #75: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  76\n",
      "4240000 images\n",
      "4250000 images\n",
      "4260000 images\n",
      "4270000 images\n",
      "4280000 images\n",
      "Current Train: 87.73%\n",
      "4290000 images\n",
      "Current Test: 72.92%\n",
      "Current Test Previous: 74.61%\n",
      "Operational time of epoch #76: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  77\n",
      "4300000 images\n",
      "4310000 images\n",
      "4320000 images\n",
      "4330000 images\n",
      "Current Train: 87.78%\n",
      "4340000 images\n",
      "Current Test: 73.05%\n",
      "Current Test Previous: 74.48%\n",
      "Operational time of epoch #77: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  78\n",
      "4350000 images\n",
      "4360000 images\n",
      "4370000 images\n",
      "4380000 images\n",
      "4390000 images\n",
      "Current Train: 87.87%\n",
      "Current Test: 73.42%\n",
      "Current Test Previous: 74.42%\n",
      "Operational time of epoch #78: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  79\n",
      "4400000 images\n",
      "4410000 images\n",
      "4420000 images\n",
      "4430000 images\n",
      "4440000 images\n",
      "Current Train: 87.92%\n",
      "Current Test: 73.47%\n",
      "Current Test Previous: 74.49%\n",
      "Operational time of epoch #79: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  80\n",
      "4450000 images\n",
      "4460000 images\n",
      "4470000 images\n",
      "4480000 images\n",
      "4490000 images\n",
      "Current Train: 88.03%\n",
      "Current Test: 73.72%\n",
      "Current Test Previous: 74.52%\n",
      "Operational time of epoch #80: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  81\n",
      "4500000 images\n",
      "4510000 images\n",
      "4520000 images\n",
      "4530000 images\n",
      "4540000 images\n",
      "Current Train: 88.08%\n",
      "4550000 images\n",
      "Current Test: 73.52%\n",
      "Current Test Previous: 74.57%\n",
      "Operational time of epoch #81: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  82\n",
      "4560000 images\n",
      "4570000 images\n",
      "4580000 images\n",
      "4590000 images\n",
      "Current Train: 88.19%\n",
      "4600000 images\n",
      "Current Test: 73.70%\n",
      "Current Test Previous: 74.67%\n",
      "Operational time of epoch #82: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  83\n",
      "4610000 images\n",
      "4620000 images\n",
      "4630000 images\n",
      "4640000 images\n",
      "4650000 images\n",
      "Current Train: 88.18%\n",
      "Current Test: 74.02%\n",
      "Current Test Previous: 74.65%\n",
      "Operational time of epoch #83: 3 min 46 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  84\n",
      "4660000 images\n",
      "4670000 images\n",
      "4680000 images\n",
      "4690000 images\n",
      "4700000 images\n",
      "Current Train: 88.21%\n",
      "Current Test: 73.85%\n",
      "Current Test Previous: 74.68%\n",
      "Operational time of epoch #84: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  85\n",
      "4710000 images\n",
      "4720000 images\n",
      "4730000 images\n",
      "4740000 images\n",
      "4750000 images\n",
      "Current Train: 88.29%\n",
      "Current Test: 74.08%\n",
      "Current Test Previous: 74.58%\n",
      "Operational time of epoch #85: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  86\n",
      "4760000 images\n",
      "4770000 images\n",
      "4780000 images\n",
      "4790000 images\n",
      "4800000 images\n",
      "Current Train: 88.36%\n",
      "4810000 images\n",
      "Current Test: 74.08%\n",
      "Current Test Previous: 74.70%\n",
      "Operational time of epoch #86: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  87\n",
      "4820000 images\n",
      "4830000 images\n",
      "4840000 images\n",
      "4850000 images\n",
      "Current Train: 88.35%\n",
      "4860000 images\n",
      "Current Test: 74.15%\n",
      "Current Test Previous: 74.83%\n",
      "Operational time of epoch #87: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  88\n",
      "4870000 images\n",
      "4880000 images\n",
      "4890000 images\n",
      "4900000 images\n",
      "4910000 images\n",
      "Current Train: 88.41%\n",
      "Current Test: 74.12%\n",
      "Current Test Previous: 74.68%\n",
      "Operational time of epoch #88: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  89\n",
      "4920000 images\n",
      "4930000 images\n",
      "4940000 images\n",
      "4950000 images\n",
      "4960000 images\n",
      "Current Train: 88.42%\n",
      "Current Test: 74.17%\n",
      "Current Test Previous: 74.79%\n",
      "Operational time of epoch #89: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  90\n",
      "4970000 images\n",
      "4980000 images\n",
      "4990000 images\n",
      "5000000 images\n",
      "5010000 images\n",
      "Current Train: 88.48%\n",
      "Current Test: 74.20%\n",
      "Current Test Previous: 74.74%\n",
      "Operational time of epoch #90: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  91\n",
      "5020000 images\n",
      "5030000 images\n",
      "5040000 images\n",
      "5050000 images\n",
      "5060000 images\n",
      "Current Train: 88.42%\n",
      "5070000 images\n",
      "Current Test: 74.08%\n",
      "Current Test Previous: 75.03%\n",
      "Operational time of epoch #91: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  92\n",
      "5080000 images\n",
      "5090000 images\n",
      "5100000 images\n",
      "5110000 images\n",
      "Current Train: 88.46%\n",
      "5120000 images\n",
      "Current Test: 74.22%\n",
      "Current Test Previous: 74.82%\n",
      "Operational time of epoch #92: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  93\n",
      "5130000 images\n",
      "5140000 images\n",
      "5150000 images\n",
      "5160000 images\n",
      "5170000 images\n",
      "Current Train: 88.48%\n",
      "Current Test: 74.12%\n",
      "Current Test Previous: 74.81%\n",
      "Operational time of epoch #93: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  94\n",
      "5180000 images\n",
      "5190000 images\n",
      "5200000 images\n",
      "5210000 images\n",
      "5220000 images\n",
      "Current Train: 88.49%\n",
      "Current Test: 74.30%\n",
      "Current Test Previous: 74.94%\n",
      "Operational time of epoch #94: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  95\n",
      "5230000 images\n",
      "5240000 images\n",
      "5250000 images\n",
      "5260000 images\n",
      "5270000 images\n",
      "Current Train: 88.55%\n",
      "Current Test: 74.17%\n",
      "Current Test Previous: 74.98%\n",
      "Operational time of epoch #95: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  96\n",
      "5280000 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5290000 images\n",
      "5300000 images\n",
      "5310000 images\n",
      "5320000 images\n",
      "Current Train: 88.51%\n",
      "5330000 images\n",
      "Current Test: 74.35%\n",
      "Current Test Previous: 74.90%\n",
      "Operational time of epoch #96: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  97\n",
      "5340000 images\n",
      "5350000 images\n",
      "5360000 images\n",
      "5370000 images\n",
      "Current Train: 88.55%\n",
      "5380000 images\n",
      "Current Test: 74.33%\n",
      "Current Test Previous: 74.91%\n",
      "Operational time of epoch #97: 3 min 48 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  98\n",
      "5390000 images\n",
      "5400000 images\n",
      "5410000 images\n",
      "5420000 images\n",
      "5430000 images\n",
      "Current Train: 88.57%\n",
      "Current Test: 74.35%\n",
      "Current Test Previous: 74.83%\n",
      "Operational time of epoch #98: 3 min 46 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  99\n",
      "5440000 images\n",
      "5450000 images\n",
      "5460000 images\n",
      "5470000 images\n",
      "5480000 images\n",
      "Current Train: 88.57%\n",
      "Current Test: 74.45%\n",
      "Current Test Previous: 74.90%\n",
      "Operational time of epoch #99: 3 min 43 sec\n",
      "==================== SUMMARY ====================\n",
      "        Best Train: 88.57% on 98 epoch\n",
      "         Best Test: 74.45% on 99 epoch\n",
      "Best Test Previous: 76.78% on 21 epoch\n"
     ]
    }
   ],
   "source": [
    "# train the 3-rd layer\n",
    "\n",
    "first_test = third_layer(file_name_net=\"saved_few_short_leaning_total_0.net\",\n",
    "                        file_name_csv='parameter_set_few_short_leaning_0.csv',\n",
    "                        adaptive_int=0.5, previous_epochs=0, epochs=100, \n",
    "                        train_loader=train_combi_loader, \n",
    "                        test_loader=test_letter_loader, \n",
    "                        test_previous_loader=test_MNIST_loader,\n",
    "                        model=mozafari, apr=apr, anr=anr, app=app, anp=anp, \n",
    "                        parametr_set=parametr_set, steps=0, percent=0, it_continues=False)\n",
    "\n",
    "parametr_set = first_test[0] \n",
    "counter = first_test[1] \n",
    "previous_epochs = first_test[2]\n",
    "apr = first_test[3] \n",
    "anr = first_test[4] \n",
    "app = first_test[5] \n",
    "anp = first_test[6]\n",
    "conv3_data_train = first_test[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA30AAAFGCAYAAADeqPb+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABoa0lEQVR4nO3dd3xUVfrH8c+hE0BCjaAmYG8oCip2sLdddV3LiorS1LW7NmQtq6vys6/rigULCopdARuKRLCAgqAgiIDSeyeE9Of3x5lhJslMkkkyM0n4vl+v+7pz7p1758xwSObJOec5zswQERERERGRuqlesisgIiIiIiIi8aOgT0REREREpA5T0CciIiIiIlKHKegTERERERGpwxT0iYiIiIiI1GEK+kREREREROqwpAZ9zrkbnHOznHO/OOduDBxr7Zz73Dk3L7Bvlcw6ioiIiIiI1GYuWev0OecOBEYBhwN5wKfA1cAAYL2ZDXHO3QG0MrPby7pX27ZtrVOnTnGucey2bt1Ks2bNkl0NqePUziTe1MYkEdTOJBHUziQRktXOpk2bttbM2kU616CqN3fOtQXWWezR437AZDPLDtznK+Bc4GygZ+A5w4FMoMygr1OnTkydOjXGl4+/zMxMevbsmexqSB2ndibxpjYmiaB2JomgdiaJkKx25pxbFO1cpYZ3OueaOueec85lA6uAbc654c65ljHcZhZwnHOujXMuBTgD2A1IM7MVAIF9+8rUUURERERERCo5vNM59wJwNPAwsBzYH/gnMM7MLo7hPv2Aa4AsYDawDbjCzFLDnrPBzErN63PODQQGAqSlpXUbNWpUzO8j3rKysmjevHmyqyF1nNqZxJvamCSC2pkkgtqZJEKy2lmvXr2mmVn3SOfKDPqcc0eY2ZQIxxcDfzWz78OO3QDcY2atK1NJ59yDwFLgBqCnma1wznUAMs1sn7Ku7d69u2l4p+yo1M4k3tTGJBHUziQR1M4kEZI4vDNq0Ffe8M4vnHPDnHMlJwSuIjTvDudcPeCowPFYKtY+sE8H/gK8AYwG+gSe0gf4MJZ7ioiIiIiISEh5Qd8BQCtgrnPu2kBwBzAYuN85t8A59zV+iOdfgLtifP13nXOzgTHANWa2ARgCnOycmwecHCiLiIiIiIhIJZSZvdPMFgPnOedOAp4CBjjnrjWzcc65/YC/AbsAnwHvmNmcWF7czI6NcGwdcGIs9xEREREREZHIKrRkg5l94Zw7CLgJGOucGwPcYmYPxLV2IiIiIiIiUiUVXrLBzArM7BFgX8Dhh3ze4pyr8lp/IiIiIiIiEh/lBn3OucOdc/92zj3unLvAzFaYWW/gLKA3MDMw/FNERERERERqmDJ76ZxzlwEvA38AG4EbnHNnm1lvM5vknOuGX2fvLefcl8BNZrYk3pUWEREREZEdgwFb8Qt7bwls+UAToHFgH/64MVCIXwA80pYTuL4gyr4o8LoubAsv7w4cF6f3Gi/lDc38JzDczPoCOOcuBF53zt1pZovMrAj4r3NuFD7L5mygRVxrLCIiIiKygyjCByL1wjZX4jn5hIKhkls2PpgpDGxFJR7n4oOpYFAV/jgbaAg0x3/Bb15iawrkBe6RE9hyw/a5gbpF2oJ1ssBWVOJxEaEgb2vgeE1xEXUv6GsPhK96/gO+nbUDFgUPmtkaoJ9zbmi111BEREREpJYxfECUg+9d2owfNrcpsI/2uOR+C5EDHkcoACyoYl3r4YO4ZiX2LfEB2jr8F/9gULglwms2pHTPW6PA8Yb4oKNh4HzzQLl+2HsI7oOPg3UqGXAGHzckFFiGB5vBx/XxQWmkrUmEeoXv6xMKQIOffXi5WcU/2hqjvKDvK+B259xGfNu7AVgL/BLpyWY2NdJxEREREZGawvCB2FZ8b1awZ2sVsAJYGWG/ER+I1C+xBYOEQkJBR3AIYUXUA3YCUsO23cMet8QHSuE9YMEteCwFHwxF2lLC6hgMssLr3wgfBJXsPSxPbuB9Ng5sFc4OKUlRXtB3JTAceA3fFuYBfzWzbfGumIiIiIhINEWEArfgkMRN+MBtFbA67HGwvPaoo8jDB3rlaQvsDHQA9gZaUXxoZPhWgP9S3aSMrWVgSw3bp+J7rWINuGqCYLAntUN5i7OvBE51zjUBmpjZxoTUSkRERETqpEJ8gBbeyxb+eCOwHj+kcH2Ex1lhzy9PGyAtsHUDsteuZa+OHWkG27cUQsMZ2+ODvPb4HjCRuqKii7MHe6tFREREpBYz/NC8PIon1QhPsrEVH2BtIBRsrQ87VkDkrIbBcnbYtrVEObeC9ayH711rA7TGB2774ocsNouy7UQoyGtH6S+6mb/9Rs+OHStYA5G6Qwuri4iIiNQCW/GJFdYE9hsJJdYouQUzHpbMxhjsVSsidi3wwVcqPuFFpAQXwWMpga1t2ONgj1rJfcket9TA67RE88REqouCPhEREZEYFRJazyuY9S/avCzDD5faHLZtKfE40rYJH9wFA73yEio0onRK/eb4ACr4ODiMMYVQ9sJIW0rguuDWKnBcRGonBX0iIiKyQ8ijeOC1GR9YbcDPGQvfgvPINhBayDl8OGSknrL6lA6e8gOvU5GU+o7iWRd3wicS6YLvMWsX2AcfpxJKX98MzUETkegU9ImIiEjSFTrHWiLPIVuPnwsWDLzySjwOLg4d3IdveYTWSCsvOUE9fK9WcA7ZrsBBhNb0Cl9zLPi4HqXnw4VvjfDB206EArmS5fDU+rUxi6OI1HwK+kRERKTKcgn1kgWHJIY/DmZdDJ9fVmyu2fHHl3n/xvgAKnxrGPY4eD4F3wPWOOxYU3xw1ZLiQVdLQvPUNIdMROoyBX0iIiI7sDz8wtMrCc0by4myZeF74iJtZc03CwZWOxGaU9aO4vPM1i1cSLdOnbbPHwufT5aKvrCIiFRFtf0Mdc4VAcuBfwPDzKwiw9dFRESkGhTiA7fVhJKEbCnxeHPg/MqwbX0F718PH5y1Ctv2LlFuQ2jOWZuwfUXmmmUuXEjPTp0qWBsREYlFdf7hbCL+98FTwG3A7tV4bxERkR1SHj7ZyEZC2RyXAIuAxYFtEbCU8pOFBBef3hm/3lnPwOPg1g7/i7xJhK0Bmm8mIlJbVVvQZ2Y9AZxzzYHjquu+IiIidUkRfhjliihbsPctGOhFGzZZH9gFSAeODuzT8YtSl0wSEhxWqflqIiI7pmofIm9mWcDH1X1fERGRmsrwQdqqsC18COWKsMer8UMxS0oFOgS2AwPlVHxykfB9K3xw1xHNcxMRkYqp8O8L59yrwHAzGx/H+oiIiNQYOYQCthUlHocHd6vx2StLaoDvedsZH6QdSmgoZYewbWd8hkkREZF4iOWPhH8CejvnlgMjgNfMbHZ8qiUiIlI9DJ91ck2JbR2hxbk3lXgcnDu3McL96uHnvgWDt/3wgV0wuAs+7oDPPKkhlSIikmyxBH1pwJ+By4Cbgduccz8Cw4E3zGxdHOonIiIC+Llwm/DLA2yk+HIB60vsg4+DAV6kXjjwiUnC12xriU90shc+82SwFy583w4/n05ERKS2qHDQZ2Z5wDvAO865NsDfgEvx2Tofc859gg8Ax5pZfkXu6Zy7CeiP/0PsTOAK4A5gAP73NMCdZqY5giIitdxW/DDIVWH7tYHjW4HswBb+eAuhAG8z/pdFNI0Ire/WCj+c8mB8kFZyCy4r0Bz1xImISN1XqTnggV69p4GnnXN7A/cB5+OHgG5wzr0BPGVm86Ldwzm3C3A9sL+ZbXPOvQVcFDj9hJk9Wpm6iYhI9cul9PDI4LaJ6It55+B73Fbhg7hIguu/NQNSSmy7Al0IJTAJ7sMfB4O8FLSkgIiISCSVTvzlnEsFLsT39h2Fzyr9AZAP9AUGOuf6m9lr5bx+U+dcPv739XKgU2XrJCKyozFCwxhz8MFZXmCfG1begu9VWxfYhz9ej//BHeRK7HOPPZacKK9fDz8ksinF13QLllvi57y1x88RaF/icdvA8xSsiYiIxE9MQZ9zrgFwJj7QOxNoDEwGrgJGmdnmwPNuAt4EHgAiBn1mtsw59yh+XdltwDgzG+ecOwq41jl3GTAV+IeZbajMmxMRqY2K8MMZwwO0tYSyRi4vsc+L4d4pQBtCwxs7BcqNAuetxB5g2fLldN1tt2JDI4OPW6HhkSIiIjWdMytrhkTYE517Gt+z1wZYhg/mXjGz36I8/xLgVTOL+H3AOdcKeDdwz43A2/g5g5/jv98YcD/Qwcz6Rrh+IDAQIC0trduoUaMq9D4SKSsri+bNmye7GlLHqZ3VHjn16rGuUSPWNm7MusaNWRt8HNhvaNSIzQ0asKVhQ4pc5L6vFvn5tM7Lo21uLq3z8miTl0eb3Fxa5efTqKiIhsHNrNjjpoWF7JSfT5OiopjrrTYmiaB2JomgdiaJkKx21qtXr2lm1j3SuViCvmzgQ+AVfK9cmRc65zoBx5vZ8CjnzwdOM7N+gfJlQA8z+3uJe4w1swPLeq3u3bvb1KlTK/Q+EikzM5OePXsmuxpSx6mdxZ/hh0eux/+FKpjSP/xxeNr/LVH2kXrkmgK74JOOpBHqgWtL8R65NoHzyVjLTW1MEkHtTBJB7UwSIVntzDkXNeiLZXhnBzPbVNEnm9lCYGEZT1kM9HDOpeCHd54ITHXOdTCzFYHnnAvMiqGOIiIVVgAsAX4H/gjsl+CDu+AWTP1fWM69muLnrwXT/7cAMsIet8AnHukY2IKBXks0n01ERETiK5agL8U5d5CZTYp00jl3LDDPzFZW5GZmNsU59w7wI/6713TgeWCYc64r/o/rC4ErY6ijiAh5RM80uQr/g+V3YBHFg7kG+GCsDT4jZHpgH9yCWSOD67mlhj1uGNd3JCIiIlJ5sQR9j+Ln/B8d5fwD+D+W96noDc3sHuCeEocvjaFOIrKDKMT3wi3ADxNYSyiQW1tivznKPeoRSl5yOH6NmN2BzoH9rlQhpbGIiIhIDRXL95vjgKFlnP8En8VTRKRSCvG9cHOA+fgAL7j9QfFlBcCnDw7PKLkHxTNLltyUaVJERER2RLEEfe3wf0SPZh0+z4CISJkK8IHc7BLbr1BsPbgWwJ7AQcBf8EHdHvi5cu3xi3lrPpyIiIhI2WIJ+lbhv3tFczB+dJWICNvw8+bCe+yCjxfhA7+gDPwC3icA+wce74XvtVNQJyIiIlI1sQR9Y4EBzrm3zWxi+AnnXE+gP/By9VVNRGqabHzAthA/vy64aPi6sC1Y3lDi2lR8L1034AJgX3yAty+gFZNERERE4ieWoO9fwJnABOfc58BMfIbNg4CT8Qu2l0zKIiK1RA6wosS2GB/gLcQHe6sjXNeM0HpybfBJUtoAOxMajrknPvuliIiIiCRehYM+M1vtnDscGIJfP++UwKlN+AXb7zSzVdVeQxGptCL8GnMro2zhAd7GCNc3xg+97AQcEva4E345g7ZAk7jVXkRERESqQ0zZyc1sNdDXOdcPn9jFAavNzOJROREpzvDB2RJgaWD7Pj2dMYQWE19X4nFBhPs0BTrge+P2B04MlEtubVG2SxEREZHarlJLUgWCvEgjvUSkCrbgA7rgtphQgBfcby150e6704zii4gfEPY4GNyFby1QghQRERGRHUXMQZ9z7kh8LoZUSncCmJndXw31Eql1DMjCJzDZGLbfiA/UsqNsmwgFeRtL3LMePmjbDegCnBF4vGtgvwsw56uvOOX44+P0rkRERESktqtw0OecawmMAY7GdxIYoc4CCzumoE/qlBx8RsplJbblYY/X4AO2ogrcrxGQErY1x8+ROxY/Ty4dH9Cl4wO+huXcb4FGV4uIiIhIGWLp6XsIOAy4DPgWv9zWqfjEfrfh8zycVs31E6myQnxQtgHYHGXbFDi/gdB8uOC2LcI9GwAd8T1tXfATXFuFbalh+1R8YJeCn0tXv5rfn4iIiIhIWWIJ+v4EDDOzkc65NoFjhWY2D79+3yfAY0Cf6q6kSLjgMMq1JbbVwCpCmSmDj9cErilLU/z8t1aB/R74v3AEy23wAV5wU4ITEREREaktYgn62gEzAo/zAvuUsPNjgXurXiURyMd3Jf8CzA5sv+IDu7WEGmBJTYA0fLKSzkCPwOM0fOC2U4StBZXMaCQiIiIiUgvE8l13Df57M2a2xTmXjV9zOSgFP11JpMK2Ab/hA7pf8cHdL4Fj+WHP6wzsh88g1DbC1i6w3wllpRQRERERCRdL0PcjcERYeTxwg3NuKn6a0nWB54iUYsAc4GtCAd6v+AmhwaGXDtgdv27cnwL7/YF9gWaJra6IiIiISJ0RS9D3InCFc66JmeXgk7dMBL7Cf19fC/yj+qsotVURMAX4AHgfmBc43hTYBz/08nJ8ULcvsFfgnIiIiIiIVJ8KB31mNhoYHVae65zbE+iF/37/jZltqP4qSm2SB3yJD/Q+xCdSaQCcANyET/faCSVBERERERFJlAoFfc65psADwAQzGxM8bmZbCAsEZceVCzyJX9djE3445unAufgFxVOTVTERERERkR1chYI+M9vmnLsKn2NDpJiPgBuB+fi5eAOBk/CZNEVEREREJLlimdM3HT/1SgTwc/Ruwgd9+wCf4odvioiIiIhIzRHL1Ko7gL7OubPjVRmpHbKAQcCB+Ew+jwI/o4BPRERERKQmiqWn7y5gA/Cec24l8Dt+mbVwZmb67l+HvY0fyrkc6IOfw9chmRUSEREREZEyxRL07Y1fUm1xoLxr9VdHarLH8WtydAPeAY5MbnVERERERKQCYlmyoVMc6yE13L/xXb3nAyOBhsmtjoiIiIiIVFBSl0tzzt3knPvFOTfLOfeGc66Jc661c+5z59y8wL5VMuu4ozNgMD7guxR4HQV8IiIiIiK1SYV7+pxz6RV5npktLv9Z4JzbBbge2D+wJMRbwEXA/sB4MxvinLsDn0Dm9orWU6qP4YdzPgEMAJ5Fi6qLiIiIiNQ2sczpW4iPA8pTP8bXb+qcywdS8PlBBgE9A+eHA5ko6Eu4IuBaYCg+Mn8ScMmskIiIiIiIVEosQV9fSgd99YHOwGXASuCZit7MzJY55x7FJ4bZBowzs3HOuTQzWxF4zgrnXPsY6ijVoBDoD7yCj7YfQgGfiIiIiEht5cwq0nlXzk2caw78APzXzCoU+AXm6r0LXAhsxK8G8A7wtJmlhj1vg5mVmtfnnBsIDARIS0vrNmrUqCq+i+qXlZVF8+bNk12NmBQ4x0P77suXaWlc/scfXLZokQK+Gq42tjOpXdTGJBHUziQR1M4kEZLVznr16jXNzLpHOlctQR+Ac+424Eoz26OCzz8fOM3M+gXKlwE9gBOBnoFevg5AppntU9a9unfvblOnTq3aG4iDzMxMevbsmexqVNgKfJftF8AQNKa2tqht7UxqH7UxSQS1M0kEtTNJhGS1M+dc1KCvOvNy5AG7xPD8xUAP51yKc87hg705wGj8ut8E9h9WYx0litFAF+AbYBgK+ERERERE6opY5vRF5Zw7GLgBmF3Ra8xsinPuHeBHoACYDjwPNAfecs71wweG51dHHSWybHyGzmeBrvglGfZLZoVERERERKRaxbJkwx9Ezt6ZCrQEsoArYnlxM7sHuKfE4Vx8r5/E2XTgYuBX4Bb8AuyNk1ojERERERGpbrH09H1F6aDPgA3AfOANM9tYTfWSOCoCHgfuBNoBnwMnJbVGIiIiIiISLxUO+szs8jjWQxKgAJgEPIhP1nIOfv5emyTWSURERERE4qta5vRJzZWD78l7DxgDrAOaAc8BA9D6eyIiIiIidV2Fs3c65+5wzn1bxvmvnXO3VE+1pCo2AW/gM+C0Bf4MvA+chl8YcRV+gUMFfCIiIiIidV8sPX0X40cFRjMZuBR4tEo1kkopwk+6fBG/wn0usDNwCfAXoCfQKFmVExERERGRpIkl6Nsdn+gxmrnAlVWrjsRqOfAK8BKwAJ9GtR/QG7/SfXUuxCgiIiIiIrVPLEFfPpBWxvmd8R1OEmf5wMf4JCwf4z/0nsC9wHlA02RVTEREREREapxYOoJ+AC5xzpWKKZxzzfBDO3+oropJZJlAF3zmzanA7cA8YAJ+KKcCPhERERERCRdLT99D+ESQ3znnHgJm4dfpOwgYhB/+eXW111AAWItfQH040Bk/b+9slH5VRERERETKFss6fROcc5cB/wNeDzvl8AkjLzez8dVcvx2e4efs3QJsxkfX/wRSklgnERERERGpPWLqKDKz151zo4FTgD3xAd88YJyZZcWhfju0OcBVwETgGOBZ4ICk1khERERERGqbmEcHBoK79+JQFwnIBf4N/B/QHJ+w5QqUiVNERERERGIXy+Lsf3bOPV3G+f86586snmrtuPKAv+KDvovwa2T0QwGfiIiIiIhUTiyxxK1AizLONwNuq1p1dmz5wN+AscBQ4FWgfVJrJCIiIiIitV0sQd8BlL0kwzQ05azSCoHL8ONm/4Ofy1cnFRTApk2h8u+/w6RJofJvv8GMGQmvVtLk5fnPpDpkZ8Ovv4buN2UK/OtfsHmzL//+O4wb518TYNs2WLs2dP3vv8MXX4TKmZkwbBiY+fKaNbBqVfXUVUREREQSJpagrzHQqIzzjVBSyUopwg/hHAU8DFyf3OpUv5yc0ONBg6BDh1D5qafgrLNC5UcfhdNOC5XvvRcuuihU/uQTePfdUPnXX2Hu3GqvMuCDnenTYeHC0LGZM2H9+srdb906eO45WLDAl7/+GlJSQkHv119Dy5ah8o8/wplnwvz5vvzNN3DSSaHrx42DQw+l8Zo1vjxiBOy3H6xY4cszZvjPr7DQl999F049NRT0PfEEtGsXOv/ii/58MMj7+GP4xz/AOV/+17/8/YPuuguOOy5Uvvtu+MtfQuU334RXX63cZ1Xdlizxn33w3+7nn+GWW2D5cl9etgw+/RS2bk1eHaMpKICvvgr9uwOsXFl9fywQERGROi+WoG8OUNacvT8Bcfr2XXcZfnHD4cB9+DG0dcqYMdC+ve9FAh/gPfhgKLD4+9/ho49Cz7/lFng9bEWQhg2hSZNQ+emn/fVBN9wAl18eKp99Npx/fqj84ovFg8QxY3xwFXT//TBqVKjco4cPboKOPBL+9z//uKgIunb1wRL4L93p6TB0qC9v2gT77w/Dh/vyqlWQmurrEDx/1VX+CzzA3nv7IHiXXXy5XTv/XoLl7Gx/j2AgUljoe+eCQVrTptCxIy4/35dPOMEHfi1b+nLfvr6Oqam+fOml/r03axZ6/n//G/q3GDDAB5ZB//oXzJkTKvfu7YP0oJ13hoMPDpWbN4dWrULlV16BF14IlUeO9L2P1cHMf57Z2b68erV/L8HA6PvvYffdYfJkX54923/2v/ziy/Pn+3+3rEDS4S++gNNPD/VkvvsuHHtsqLxpk//sg3Jy4I8/QuVBg4q3w3/+0wfcQStWhIJt8EHbypWh8v33+7YJvp3tvnuonRcVQc+e/vMD3x46dIDHHvPlrCw45RT/RwCADRv8/4vgZ71hAwwZ4nvRARYt8nX98Udf/uknOOggGB9YcWfVKt+G1asrIiJSd5hZhTbgSnyn1DBg57DjHYAX8SMUr67o/apz69atm9VEEyZMKPN8kZldZ/5N3Bko13pbt5r95z9m33/vy0uWmPXta/b779Vz/40bzVauDJWnTDGbNClUfvhhs8ceC5UPOMDsr38Nlffe2+zCC0Pl/fc3u/rqUHngQLMXXwyVP/7YbO5c/7igwOy998xmzvTlrVvNLr/cbMyYUPn8883GjvXlrCyzG24I1a+gwGzxYrPCwkq99WjKa2dJU1Rktnatf1xYaNaunVm/fr6cm2t2/fVmn33my1lZ/t/pww99ef16s6OOMnv7bV9evtysc2ezN97w5TlzzMBsxAhf/uUXXw6e/+MPs4svNps+3Ze3bvVtMdpnv3at2TffmOXk+PJ775kdd5xZXp4v33OPWcOGZtu2+XLv3ma77Ra6/u67zQYMCJUvu8y3+6CDDzY788xQuUOH0GcRLN9wQ6h89dVm774bKk+YYLZ0aei9PPOM2Y8/+vKKFWY9epi99ZYvL1xolppqNnJk8c/qtdd8+ddfzdLTfds2M5s/3+ycc0Lt+uOP/fO/+caXP//csnfeOXR+1iyzhx4yW7PGl7ds8f8+BQW+nJfnP8eiOvETTRKoxv4skzpF7UwSIVntDJhq0WK5aCciPtkvFVcUCPDWAKsDj4uA52O5V3VutTHoKzKzW8y/gX9YHQj4gl+Wt241a9nSbPDgpFZnu8JC/6U0aMECs1WrklefOKg1v8A2bTJbtsw/zsvzgUkwQN+61QfgL7/sy5s3m514otn77/vyhg1ml15q9uWXvpyVZfboo2azZ/tyfr7Z6tXVHlBv9+23Zk88ESp/9ZXZqFEVD2xGjQoFWWZmb74ZCqrMQgFTPBQVmWVnhwLY8uTmms2b568xM5syxVaedJIP7Mz8H0XA/wHDzOy553x5xQpffvJJX16/3pcff9xsjz1C5T/+8P9ulQ0Kf/3V7OefQ+W//rX4v83o0T7QlVqn1vwsk1pN7UwSoSYGfbEuzn6Vc+514HxgD0KLs79tZpPKvFiKuRd4FLgGeAT/QdZa11zj57pNnOjnqM2ZU3zeXjLVq+eHHQbtvnvy6rKj22knv4EftrthQ+hcSkpo6CVAixbFk8qkphafH9ismZ9vGNSggR8eGy9HHum3oPC5jBVx4YXFyxdcULxcv37l6lURzvmhwBXVqBHsuWeofPjhzBk8mLTg/+m+ff37Cd7zyCPhmWdCw4qPOsoPTU0JTPE++GA4+ujQMOP//MfPr9yyxb/vt97yPz/uv9+fHz8eNm6E887z5c8+88Nrg5/ZOefAXnvB6NG+nJMTGvJs5od3X389PPywL++zjx/ues01vvzmm3DEEdC5c+ia4OdUWOgTH6WkQOPGFf/MREREariYl38zs4nmRyWeYWanm9n1CvhisxQ/f+8y4CkSGPAtWOATdUyq4j9XQQF88IGfawTQrZufHxb84lVTAj4RiY9mzfwfVAC6dIGrrw4FgYcd5uc4BoOmE07wcwSDCYGuvtoHXsFAd9w4n6ApaOhQnyQo6Jln4L77QuXnnvMBXdCYMcX/ADBtGlx7rX+8bZsPSjt29OXVq+Fvf4OxY3154UL/Pl55xZcXLIDWrUPzgNeuhdtug6VLY/2EREREapSYevqkenwX2F9HnBdd37DBJ4C45hoYOBDatPHJI7Zs8ed/+sk/PuaY2O774Yfw17/67I6nn+7/8i8iUhF77+23oGHDip9/4YXiWVSffbZ4gqCyelmdgwPCVg5KSQklVgL/M/CXX/we/H3vvjuUkKh9e5+o6dBDffmbb+Dxx30SpF139dlfmzaNredURESkBogp6HPO7Q/cAHQDUikds5iZ7VE9Vau7puDXvzgoHjd/+22fnv7mm/1wqn33DQ17S031gV7QfffBt9/6LIThGTJL2rYNrrzSB5B9+/oMmWPG+F5DEZHq1KpV8SCvOkcONGjgM+wGtWxZPFtvairceGOofPbZ/g9lbdv68n33+Wy/ixb5nkyzUA+miIhIDVbhjibn3JHAVOAcYAWwO/B74HEGsAWYGMP99nHOzQjbNjvnbnTO3eucWxZ2/IxY3lBtMAUfNZe16GGlffABvP++H4LpnB9Gde65kZ/76qt+uYQmTfyXl1degdxcf27jRh8Qgj+/eHFojbMGDfzSC/Xi2k8pIpJ8wYAP/AiHwYNDQ1d79iy+juh//lN8iZjx44v/oe2FF2DChFD5669Da0WKiIjEUSzf2u8DlgH7AFcEjj1oZkcDPYFOwMiK3szM5ppZVzPrio+BsoH3A6efCJ4zs49jqGONl4+PnI+ozpuahdYbe+klP0emQQU6cZs1Cw1j+uoruOIKn1QB/Jpt554L+fk+eJwwwa+hJyKyozrmGLjuulD5rLP8nMWgZ54JJZgB6NOn+NqWgweHfsYWFcHJJ/vho+B/jv/tb6H1Grdt83+IC66VuWWLH3o6c6YvZ2X5n/fz54eeP2VK6I9zubl+FEdwqGxenu+1DP5hT0REdiixBH2HAy+a2Ub8Eg3brw8kcnkRuL+S9TgRWGBmiyp5fa0xE8ihmoO+K6/0izPn5vq/QFdmvknPnj7wu/hiX77rLp9coWFDX9YQJhGR4m691c+XDvr1V3j++VB57Fg/ZzBozpziQd64cdC/vy9v2gQzZsCKFb68dav/Q9z48b68ebMftj95si+vXAn9+sF3gVnif/wBPXr4ewZfa/fd4fPPfXn6dD9U9ssvffnnn30QO22aL69a5eu7aZMvr1jh520Hg8Zff4Wnn/bJbcAHl7//7keV1EQ5OaH3Av79z5sXKuflhTK3ikjlbNxY/P+V1GixBH31gcBPe7ID+7CJF8wGulSyHhcBb4SVr3XO/eyce8k51yraRbVR4Nc1ParzpqedBmec4VOtV8Vxx4Uy6h10UKgXUEREyudc8aUeunaFjIxQuU2b0B/l6teHY4/1867BzyecMycURLZq5QO5Pn18uUMH/wUrWO7UyWcfPeccX95tNz9cP5joJj3d9xQGf4536uQzowYT3eTl+T/qBevzzTfwpz/51wT/R8Azz/RD+wG+/973cm7b5stvvw177OEzogK88YYPIoOJwj7/3GdVzcvz5Rkz/HzIYJbn7Gw/kqSiNm0K1QXgnXeKJwHq188n3Anq1csv3xE0YEDx+ZqHHRZaFgR8r+vNN4fKp55aPIvsCSeElhUBn7X2nntC5UMPhUceCZUHDvTTLcC/54ce8p8x+M/koYdCAXx2tv/jQLC8aZP/rL/+OvT80aN9YC6STGvWhIK8/HzYZRefbAv8H1HOPddPMQqKZWTBli1+6a/gck7Tp/uleubO9eVJk/z/s9mzfXn0aP9zcdYsX/7uO7jkEli2zJd/+w3+97/QSLgZM+Cxx/z/t2D5mWdC5dWr/TXBzPRmoXPg/8iVmVnx91MDxZLIZTF+7h5mluOcWwIcBbwdON8V2BT50uicc42APwODAoeG4nsMLbB/DCiVHtI5NxAYCJCWlkZmDfyHyMrKKlWvD/fdl1atW/P7t9/yRxXu3XD9elKWLGHTwQf7FOPHHON/ScsOJ1I7E6lOamNJtHBh2ef/CPtNkpLiv7T89psvZ2T4Lyq//+7L++5bvHzPPf6LzurV1G/cmJT//Y+tq1ZRlJlJw6ZNafK//7F18WKKVq2iXvv21H//ffLnzYMFC2jarBktb7uNVbNnY7/9Rru5c+m4dSs/T56MNWzIbu++S6fhw5l05plQrx6dhw1jt1GjmJiWBs6x+7PPsut77zHxs8/AOTp+8AF7zZhB5r33ArDn00/TcuZMpj33HAD7/+tfNPv9d34IZGM94KmnaLpsGVMDa0pmmFHPjD8C7bT9ySdTVL8+awPlFv36AbAlUO5w4okU7LQTawLlPVJT2VZYyPJAee9Gjdi6aRPLAuV9Gjdmy/r128/vuddebC4sZHWgvF+bNqzfuJFVmZlQWEiP0aNZVq8eS1JTcQUFHH/nnfzerx+L8/Opt20bx915JwuuvJIlOTk02LKFY+6/n3kbNrAsJ4eGGzZw+KuvsiAlhZUFBaQsXszhffowZ9AgVp1yCk1WrmSfRx7hj7592XzAATRes4Z2Eyaw5vjjyU1Lo9G6daROn86G7t3JT031QadzmocfUOt+nhUV+X8/52i6bBmp06ax6rTTKGrUiPbjx5Px6qtMe+45ipo0oc1339F20iTmXXcdRU2b0mj9elxBAbnt2oFzNFm2jMZr1rCpa1cAdv7oI5otXsyCq6/25U8/pfGqVSwK/HGp9fffY86x4bDDADisTx9yOnZk5kMP+edfcw2bunRhW2YmDbKyOHjWLJZ9+y0rW7Wi4caNHHXeecy5805Wn3giTVau5OCbb2b+3//OumOOoenSpRw4eDDzbriBjYceyk6zZnHoddfx85AhrD/iCFrMmcN+kyczOzOTrBUraDF3LhlNm7Jg2jS2rV5NszVr2KVbNxbOnUve2rW0+fpr9vzyS2Z88w257dvTYfRo9nniCb5r147c9u3p+MEH7P2f//DN7ruT36oVu40axR7PPcekTp0oTEkhfeRIdh82jImffkpR48Z0fvFFdnvjDSZ+/vn2n1m7vP8+99w6nWHDdmf16sa0b59L//6/c9JJq0v9s9XIdhZt1faSG/A0MDOs/AB+itow4OXA46crer+w+5wNjItyrhMwq7x7dOvWraoL2MfFhAkTSh3bx8zOro6bn3eeWbt2ZllZ1XE3qcUitTOR6qQ2JlW2fr3Zr7+GyuPHmz36aKj84IO2rnv3UPmVV8zuuCNU/uILs3feCZW3bjUrLIxffatTUZFZTo5Zfn70clm2bTObPNls9Wpf/uknsyOOMJsyxZe//NIMzIL/Tz/5xJe//daXx441a9zY7Mcfffnnn80efNBs7VpfzskxKyio2vsL/y7y6admQ4eGyqNGmT35ZKj88stmjz0WKi9ZYrZuXeVfP0YTvvyy+Gc/e7bZihW+nJvr29706b68caPZGWeYvfeeL69ebda+vX8PZv66ffYxe/ttX/7jD18ePdqXf/nFrEULs/ff9+U5c8z23de3fzOzxYvN7rrLbP58X541y+yaa/xnYubbfMOGZnPn+vKrr/p/299+8+VPPvHfB9es8eWnnzZLTw/93xg0yKxBg9C/79//bta6dejD+Mc/zHr0CJX79zcL/3949tlme+4ZKn/ySajdlWf1arN//tPs6699eflys0svNfvmG19etMjs/PPNJk705c2bzcaNM1u3zkaMMMvIMHPO70eMqNhLBo0YYbbPblutHautc3qBvz43179GYaGNGGG2Z3qupbHSMtKL/PnZs81GjNj+2seTaQ+lDrGRrwY+u3nz7LO7v7aUpkXmuwH9lpISuX7J+r0JTLVoMVe0E6WeCOnAeUCTQLkhvlduPX7Y54tAs4reL+y+o4Arwsodwh7fBIwq7x61Jehbb77CD1bHzVesqPh/PKnT9IVc4k1tTBJB7aySCgr8l9lgIJOV5QPs7Gxf/vlns1tvDQV5L7zgv/4tX+7LQ4ea1a8fCny++MIHC8HrP/useAD+xhtmV18dKl95pVnHjqHyFVeY7b57qHzRRWb77RcqX3ih2ZFHhsonn2x2+OGh8i23+EAo6Jln/GsGffaZ2aRJofJdd5kNHx4qn3KKD2qDDjig2P0KGjc2u+02Xygq8pHFP//py/n5/rO5915fzs01O/RQs5EjfXnjRrOrrjL76itfXr3av58vv/TllSvNLrggFMisXGl2442hIPK333ygEwzAMzP96wfvN368WatWPsg380Hg7bebLV3qy5s2+cdhQXpZAdLYB2bY9W1GbD/34cO/mn33XYWuNTMb9fwmO2yXZZUKvsq7d7TzI0b4QKqswKqse5d3fVnnI51r2tTskUd8k2vbtvi54JaRUfr91+qgLx4bkAKsA1qGHXsNn+/kZ2B0eBAYbastQd+n5is8vio3DfyVQiRIX5Qk3tTGJBHUzhJoy5ZQD+PkyWZ33hkKJIYM8d90g+V77vHl4PMffNBsr71C30U+/tjs8cdD99640fdOliW8d3PcOLMxY0LlSy81u/baUPngg83OPTdU3ntvHzgFde3qe8fCr3/qqVD5uutCQZuZLejXz79m0Ntv++Bq+xMW+J7kGFSlZ2rkqwXWOb3AXxvsdargvWMNYCoa/FT0fHUHXq++arbLLpEDq7Q03yH68suRA7PBg/3fM3baKfL1jRr5Ts3GjaOfb9gw8rnyNudK/7sq6IvTVluCvnvNzJnZ5qrcdOBAs4MOqtpQDKlT9EVJ4k1tTBJB7awGqWl/XA7/zjN3bqhXshKqu51VpWcqWs/Sf/9rtmyZ3zdtWvx848Zm11/vA5zU1MhBSMuWfot0rkULswEDSr9ucGvY0I9QbdAg8vmddjLr06d08NSokdlf/hL5XPhzzjzTrFmzygVXVd1OPrny1372mVmHDpHP1ZaePs3qTaApwAFAi6rc5JRTfHaiYJZNERERkepU05K+hH/n2Xtv2HnnmG8xcqRPYnvCCcfTqZMvx3ptvXoUu9YMbruteJJH8OWbb4ZFi2DECJ/MddEi//xFi/xKLX37wlVXlb522zafvHWXXYonzA3KzfXLfw4Y4BP6RrJpU/EVS8Jt2eKXAy35ukH5+XDwwdFXY9m8GYYPL52YMy8P3nsPvvgietLOvDxYvjy0EkwkrVtHPt6+Pbz8cvTrnPN5rdLTI5/PyPAr2oQnVC55vqxzp5ziE/SmpBQ/l5ICDzwQvV41SQ37X113GT7oq/JSDeed59eGEhEREZFyjRwZHng5Fi3y5fDAL1pgV/xav+/b168K0rmzD2IiWb3a3+fSS0sHWDk5PoAJriYQSSBxbUTO+Xrstlvk8+npZQc/K1aUHeC8+Wb08+np0Zdudg6WLi373j/+WPb5p56KHFg9/jhcfnnZ9erUCR58sOzA7IEHop8v6xxA795+KdaMDP9eMzJ8uXfvyHWqaRT0Jch8fMabSi/Kbub/F0b704yIiIhIHRUtKCvrfFGRX9bthhui98atWhU5sBs40C/rdtNNpa/Ny/OrZB16aPSeqbS08gO3sgKzgQPLDnDS0/1yj5GClAcfrFrwU9b5Bx+MXu/g8cre+4EHyg+sqhqYlXW+IkFd795+JZ2iIr+vLQEfoDl98RQ+nvc185X9ubI3mzzZDxx+8cWqV0zqFM2DkXhTG5NEUDuTaKLNmxs2zCfIfPxxsyZNip+vVy/63LKSW716sc/xCibvKG9OX0ZG9HlgVU2mEnxOWQlVKpNBs7zzVa1XRc6XpapLOiRCTZzTl/SArTq22hD0XWNmzc2s0ulXiop8CmCtyycl6IuSxJvamCSC2plE+zK/226xB2Vg1ry5X3YvWgKO9u39EoJl3SMtLXrQVl69g+cqmwWzIueTpabWq6aoiUGfhncmyBTgMKDS6Vecg2OPhWbNqq9SIiIiItWkMkMww89Fmjt3yCGwZEn01/zf/6Kf27oV+vSJnoDj8cf90M+y5pg99lj5yTvKGvJXkeGGZQ0XrKnDCWtqvSQ6BX0JsA2YQRWSuDz/PPzrX/5/loiIiEglVSUwK+t8tHlx5Z1/4QU/7+7mmyPPnZs5E1pESXuekQF//3vZc9+gZOBlMc0Tq47kHQqQpCZokOwK7AimAwVUIYnL1Knw++81L4WyiIiI1BrBwCsYXAUDL/CBSFXO33FH5GQp11wD06b54C7S+eD10RQVwdChxV8XSicGKet8sP69e0Nm5lf07Nmz2GsEg7DBg2HxYh8sBgO+8GtFajNFEQkwObCvdND3/PPw8cfVVBsRERGpzSrbGzdoUOTA6+qr/ZpwV19dufOXXOJT9UeyaZMP+MpanuCNN3y2y0jS06uWkbGi1BsndZ2CvgSYAmQAsS8lSuina6NG1VchERERqbFinftW3jDKPn18UBVtbtyWLfD6635fmfMArVpFPp6e7q8ra97cRReVP3euts59E6kpFPQlwBQq2cu3cKH/Kf3++9VbIREREUmqysyN27YNbr89cm/bgAHQrRtcdlnp84WFvqetZcvIdcnIgHXryg7Myjv/3/9GX9cN6v7C1yI1nYK+OFsJLKKSSVzq1YOLL/Y/xUVERKTGqO5Mlf37w223wfXXRw7qLr3UB0nLlkWuz7Zt/u/E0XK+bdvmM13GY8HuiiQ8qfMLX4vUcAr64mxKYF+pnr70dHjuuVD6KREREak25QVuZV1X1hDLl1/2PW/h56+4Av70J78MwYABpQO7nBy/tMD69ZFf08z3mrVuHfl8Roaf/l9WJsuqBmZ1dfkBkR2Bgr44mww0BA6J9cLp02HevOqvkIiIyA6iKnPjyro+WqbKPn388gJ9+/qetXD5+TB2LIwbV/pckHOwyy6Rz2Vk+EQsTz1Vtd66qgZmCtxEaicFfXE2BTgYaBrrhf/4B5x+uv9NJCIisoOqznXj+veHm27yPWpXXRU9U+VDD/nz/foVv/6yy3zCkmiZKgsL/WtE45y/tqzeuP/7v6rNfdPcOBGJROv0xVEh8APQpzIXjxwJf/zhf2KLiIjUUSNHBtdHO77U+miVWTeuf3/46ScYNizyEMonnyy7Plu2wJ13Rj5XVOR77Fq1gg0bSp/PyIAnnvD51xYtKn0+OFujrHXlylszLvjeywritK6ciJSknr44WtSsGVlUMolLhw5w1FHVXCMREZHEqvgQS8eiRX5o5AUX+OP9+0fujbv8cujSxT832ty4SEEZ+L+lbthQdibKrKzof3PNzo6eqTKWIZZVmRsnIhIr9fTF0ZyddgIqkcRl+HCfV/mcc6q7SiIiIgkTradu0SLo2DFypsq8PHj7bWjf3gdwkRQUwJ57wqxZkc8H58ZFGoaZng6pqWX3tjVr5p8XrbeuvN646uitExGpTurpi6PZO+1Ea2DPWC987DF49dU41EhERKT6RevNu/POyD11gwf7bJbRFvt2DlatKrs37v33y54bN2RI1Xrb4p0QRUQkkRT0xdGcFi04Aoh5Vt706X4ygoiISDUpb5hlda45d8UVcPDBvpcrEudg7tzoKxKFz32L17pxUHZgpoQoIlKXaHhnnGwGFjZrVrkkLvXrR1+IR0REJEZlJUSByiVL+fFHHwAOHly6Ny8/H2bPhubN/fy4ktLTYe+9/bpz0YZYBl8fKj+MsqpDKDUEU0TqCvX0xclUwJyLPYnLhx/CXXf5CQsiIiIVVFZvXLR15a6+Gq65JvK5q67yAU+kZCo5OfD4435OXrQhmoWF8OyzsQyxtJh74ypyXkREFPTFzZTA/vBYL/zuO3jtNWigTlgREQmJdYjlgAE+y+VJJ0VfV27LFti0KfK5rCyYMiV6MpXgvLuyhmjGMsTyyy+/UtAmIhInSQv6nHP7OOdmhG2bnXM3OudaO+c+d87NC+xbJauOVTEZ2C07m5grP2QIzJ8fhxqJiEi8VWVuXHn3LRnUDRxYdsKUbdt8MuilSyGQTLqUjIzoQVtGhv91VFaylPbt/RDNqiQ8ERGR+Eta0Gdmc82sq5l1BboB2cD7wB3AeDPbCxgfKNc6PYBTV66s3MXq5RMRqXXKC8zKOx98TqSgMNK8uexsP/Ryr73KTpjy66/wzDPRA7PygraqrjknIiLJV1OGd54ILDCzRcDZwPDA8eHAOcmqVFUMAnpH+y0czfTpcNFFsGBBXOokIiJVF2tgNmAAHHIIXHZZ9MBtwAA4/3y/2Hh4UNinjw/qIq0XB37oZbdu0Xvygr14ZQVmFVkovCpZMEVEJPlqSpfSRcAbgcdpZrYCwMxWOOfaJ69aCbZiBUyeDI0bJ7smIiISQaRMlgMGwNdfRw/Mtm3zC4XPmBH5fE4OjBnj58eVVFgIS5ZEz4KZkQGjRpWuFxTvjYOyM1GWl6VSWSxFRGo3Z2bJrYBzjYDlwAFmtso5t9HMUsPObzCzUlPjnHMDgYEAaWlp3UaNGpWoKldYVlYWzZs3T3Y1pI5TO5N429Ha2BdftGfYsN1Zvbox7dvn0r//75x00moALrqoB6tWNYl4nXOGWemVWdPSchg1anLUa4PnTzjh+IjXO2fceeccHn10H3Jz628/3rhxIbfcMnd73cqqd22wo7UzSQ61M0mEZLWzXr16TTOz7hFPmllSN/xwznFh5blAh8DjDsDc8u7RrVs3q4kmTJiQ7CrIDkDtTOKtJraxESPMMjLMnPP7ESOq774pKWZ+gKXfGjUyO+ccs7POKn48fHPO7LXXSl+bkhKqW6R7h5/PyIh874yM+L7nmqImtjOpe9TOJBGS1c6AqRYlXqoJc/r+RmhoJ8Bo2L6meR/gw4TXKBlycuDww+H995NdExGRGq0qCVHKOpebC//4R+l5d3l58MEHfq5as2aR65SeDpdcUrW5cRVJmKJ5cyIiUhlJDfqccynAycB7YYeHACc75+YFzg1JRt0Sbt06aNlS8/lEZIdQlaUNoiVMuekm+PRTv3xBv36l16x78UW/DGrJgPGKK+CAAyA1NfK8OvBB2syZ8NxzVQvMyjqvLJgiIhIvSU3kYmbZQJsSx9bhs3nuWHbZBT7/PNm1EBGpsJEjfQC2eLHv6XrggeIBSrTzkZKhDBzoH5d1fv58HwRGS5iyZg2cfnrkc9u2+SyZkeTnw7x5cM01/rXXrCn9nPAsmFD2+64KJUwREZF4qCnZO0VEpIYJBW3HlwpuKhu45eXBXXdF7qm7+WZo08bvI52/917fA9aokb9PSTvvDO+9B0cf7XvxYlFQAE88Ad27Vy0LpoiISE1UE+b0CcBJJ/nJJCIi1ai8YZRlXRcaBum2D5F88kmYNQtuuSVyYPb3v8NVV5UOnILn+/aFZcsiv+bq1b6nbnWUhJPO+XMvvRR5iOWjj8KRR4Z65UrKyPBbJBVZz05ERKS2UtBXUxx0EOyxR7JrISJRVDZ4quq15V1f3rnKJDxZsgRuvLF00LZtm58316ULrFwZua6bN/ukJyWvDde6deTjO+8M333n95Gkp0PbtlVLiFJeshRQwhQREamDoqX1rE2blmyQHZnaWfyVl2q/qteWlYq/rOujnRs61GzGDLP27SMvAdC6tdnw4WbXX2/WuHHppQeiLUsQ3N56y6xdu7KXFyhr+YHyPpOqfN4V/Uzr8tIHtZV+lkkiqJ1JItTEJRuSHrBVx1brg768vLjWQ+o2/QKLv/LWTzOLHkjstlv0wOudd8wGDTJr0qT4uSZNzAYPNhs71qxt28jXN29u1qxZ+QFaZbZWrcx23rns91zVwK28wEuB2Y5HP8skEdTOJBFqYtCn4Z01wU03wX77xZ55QESqTaRhjtu2wSefRM8WuWiRT0py7bU+M2T4MMrLL/f3WbIk8rXr18Nf/woPPeSX6QyXk+OHG551FqxdG/n6rCzYujX6+3n7bUhLi3xul118JkznIp/fuNHPjytvaYKqrElXlaUNREREJDbK3lkTHHecn8QS7RuYiMRVpEyTffr49dvy8/1/zUh/k2nQwAdthYWlzxUU+DXfdtrJz3MraZdd4OOPoWvXyPd2DiZPhnPOgRUrSp8PJiSJFJBmZPiAMjc3cibK//s/P4U4PT3y9enpJZcmMNLTXamlCcrLYqkslyIiIjWDevpqggsugH/+M9m1EKnzIvXmmcGtt5ZOPFJYCE2a+J6+aNkiX3nF97ZF+3tNbi4880zka//v/3z+pmiZJtPT4fDD4ZFHKp+UpCoJT4LXL1wIX375lXrbREREajEFfcm2dSts2ZLsWojUeZEyWV5+ObRvH7knDfwQytNO88+LFjw1blx24FYdgVe06yuyvEBZwyS1PIGIiMiOQUFfsr33HrRsCb/9luyaiNQIlV2eoKzzW7dGXleuoMAHdtGWEAgP5soKniraY1bZwKu866sy901z50REROo+BX3JduihcN99sPvuya6JSEJUdl25SOcGDIBhw2DNGnj6aV8OP9+nD3ToAC1aRF9XLjcXnnqq/LXbylLVHjMFXiIiIhJPCvqS7YAD/Hy+BsqpIzVHPHrbguciBXVDh8LXX8MNN5TujcvO9sMr+/SJvFj4gAF+iOZ11/lyuMJC2LQJ7rkH2rWL/F4rMgSzIhS4iYiISE2lSCOZiorg559h//2hUaNk10YEiJzJcuDA0Plo53r39tcOGBAKvhYtgn79fEDXtSsMGhQ5qPv738uuU0FB2ef/+18f9EWSk+ODvj33jJzJMnwIpgI1ERERqYvU05dM8+fDIYfAa68luyZSx1S2N84Mbr89cmB2zTV+i3SuXz/Yd1+49NLSvW25ufDss3DVVbBhQ/Q6f/IJdOwY+VxGRmiJgkjnrr02+vngvDwlLREREZEdlYK+ZEpLgzfegFNOSXZNpA4pa15ctPNXXOH//rDzzrBsWeT7btrkt0hyc6FLl8jrzYEPspYtg912i3w+I8NnyXz44covT1DeedAQTBEREdkxKehLppYt4aKLon8TFilDsLfuhBOOL9ZbN3hw5N64q67yC3b361f6fH4+zJrlA69WrSK/Xnp69KUJMjLg7bfL7m3r2NEvZB6v5QnUkyciIiISmYK+ZPrqK1i8ONm1kBqq4glR3PbeuhNO8MciycqC2bN9r1wkhYUwfLifHxcpMHvwQb9Vpbct3ssTqCdPREREpDQlckkWMzjnHLjgAnjuuWTXRmqYaMlU8vL83LnrrovcW/fVV9CkiU9eUlJGhg/6OnWKHBiGz30D32O4eLE//sADxQOoaOcqcq0SpoiIiIgkloK+ZBo/Hpo2TXYtpAaKNkSzb9+yrzPz69aVlaXygQfKPg9lB2blBW0K6kRERERqFg3vTBbn/MLs++2X7JpIHFVmvbs1a6IP0QR47z3YZZfI5yqy5pzmvomIiIjsWNTTlyyZmX483sknJ7smEiexrnfXty888gj88kv0e2ZkwLnn+uuqsuaceuNEREREdhzq6UuWIUPg1luTXQupoki9dbm5fm5dtDXt+vaF/v1Ln8vL8xk0b765/IQpxXvrTL11IiIiIhKVgr5kefNNv0mNVvEMmn5/2WXQvDn07Bl9Tbu8vMiJVsBnnfy//4NBgyqe5fLLL79SpkoRERERiSqpQZ9zLtU5945z7lfn3Bzn3JHOuXudc8ucczMC2xnJrGPctGwJ++yT7FoI0QO7SEFd377w5z/75RX79i3dW1dU5HPzjB4Nu+4a+fUyMspezy5Iyw+IiIiISHVIdk/ff4BPzWxf4GBgTuD4E2bWNbB9nLzqxcnUqX4xtKysZNdkhxBrb13fvnDeeaXnzIHvpRszxv8T5uVFfr2sLPjTn/wI3mhDNMtbz05EREREpLokLehzzu0EHAe8CGBmeWa2MVn1SahPP/UTt+rXT3ZNao2yArfyrisZ1A0c6JdGHD8err02cmD33nuljwc5B/Pnl99bV1aWTGXQFBEREZFESWZP3+7AGuBl59x059ww51yzwLlrnXM/O+decs61SmId42PwYFi2TGv0VVC0wC18GGa0gPDOOyMnU7nqKjjpJNi4MfJrBgOxSIJBXUV668oaoqnhmyIiIiKSCM7MkvPCznUHJgNHm9kU59x/gM3A08BawID7gQ5mVmpJaufcQGAgQFpaWrdRo0YlrO4VlZWVRfPmzZNdjVrhiy/aM2zY7qxe3Zj27XPp3/93TjppNQAXXtiD1aublLqmbdscLr98If/9717k5oZ6TRs0KKJr1w3k5dXn559bAi7CKxqPPvoz//d/+7BmTel7p6Xl0L//7zz66D7F7t24cSG33DJ3e93KqneiqJ1JvKmNSSKonUkiqJ1JIiSrnfXq1WuamXWPdC6ZQd/OwGQz6xQoHwvcYWZnhj2nEzDWzA4s617du3e3qVOnxrG2lZOZmUnPnj2LH1yyBB5+2I8rVCIXoPR6dgANGsAhh/gslzNnxn5P56BHD39tpKmTGRm+dy3Sa6ekhIZajhzpO2YXL/Y9fA88UPN65CK2M5FqpDYmiaB2JomgdiaJkKx25pyLGvQlbXinma0EljjngpHPicBs51yHsKedC8xKeOXiad48ePllJXEJc9ttpYdgFhTA9Ol+uGaLFpGva9267Pt++y08+2ws692VnlunIZgiIiIiUtslO3vndcBI59zPQFfgQeBh59zMwLFewE1JrF/1O+EEv4DbIYckuyYJFWne3Q8/wAUXwPLlka8pLPRLHwwdGjlwe+qpqiVTCVJgJyIiIiJ1WYNkvriZzQBKdkFemoSqJNYOlrWz5BDK4CLmRUV+ucKddoLNm0tfFx64QfRhlpGGZ5ZMpqJATkRERER2VMnu6duxFBXBOef47qsdyODBkRcxT031Qdwzz1Q+C6aWPhARERERKVtSe/p2OOvW+W6uaOsE1FGLF0c+vmmT7+UrryevPOrJExERERGJTkFfIrVr57OT7CA2boR77/Vr60USHL4JCtxEREREROJFwzulWoQnasnIgP79Ya+9fLKVE08svQ59yeGbIiIiIiISHwr6Eunii+Huu5Ndi2oXTNSyaJHv1Vu8GF580S+pMG0afPEFvPCC5t2JiIiIiCSDhncmUuPGfqtjIiVqAb+wenBlCg3fFBERERFJDgV9ifTyy8muQVxES9SyZEli6yEiIiIiIqVpeGeiRMtmUoutWeNHrFYkUYuIiIiIiCSHgr5EuflmOPbYZNeiSsKTtbRrB7vvDu+8A3/5S/nr7ImIiIiISHIo6EuU/faDHj2SXYtKK5msZe1aP4/v/vvh3Xe1QLqIiIiISE2lOX2JMnBgsmtQJZGStRQVwdChcPvtStQiIiIiIlJTqacvEXJzobAw2bWokmjJWqIdFxERERGRmkFBXyK89hqkpsKyZcmuSaV17Bj5uJK1iIiIiIjUbAr6EuGAA2DAgOiRUy2w556ljylZi4iIiIhIzaegLxGOPBIef9xnOamFZs+GSZPg1FOVrEVEREREpLZRIpd4y8+H1at9L18tDfruuAOaN4cRI6Bt22TXRkREREREYqGevnibMQN23RVGj052TSpl0iQYM8Zn6FTAJyIiIiJS+yjoi7ddd4WnnoIjjkh2TWJmBrfd5jspb7wx2bUREREREZHK0PDOeOvQAa67Ltm1qJT334fJk+GFF3zSFhERERERqX3U0xdv338PmzcnuxYxy8+HQYNgv/3g8suTXRsREREREaksBX1xVC8nB446Ch59NNlVidmLL8Jvv8GQIdBA/cEiIiIiIrWWvs7HkdWvD2PHQufOya5KTLKy4N574Zhj4E9/SnZtRERERESkKtTTF0fWsCGcdhrss0+yq1IhI0dCp07QogWsWgUnnlhrV5kQEREREZGApAZ9zrlU59w7zrlfnXNznHNHOudaO+c+d87NC+xbJbOOVZE6fTrMnJnsalTIyJEwcCAsWhQ69sgj/riIiIiIiNReye7p+w/wqZntCxwMzAHuAMab2V7A+EC5VtrrP/+BwYOTXY0KGTwYsrOLH8vOrjXVFxERERGRKJI2p885txNwHHA5gJnlAXnOubOBnoGnDQcygdsTX8Oqm/ngg/To2jXZ1aiQxYtjOy4iIiIiIrVDMnv6dgfWAC8756Y754Y555oBaWa2AiCwb5/EOlZJTseOsP/+ya5Ghey2W+Tj6emJrYeIiIiIiFSvZGbvbAAcClxnZlOcc/8hhqGczrmBwECAtLQ0MjMz41LJymo5YwYtVqwg06xWZEPJyNifxYuLx9eNGxdyySVzycxcnaRaSUVkZWXVuPYvdYvamCSC2pkkgtqZJEJNbGfOzJLzws7tDEw2s06B8rH4oG9PoKeZrXDOdQAyzazM9Jfdu3e3qVOnxrvKsendm5zx42mycmWya1KuOXOga1fo1g2WL/dDOtPT4YEHoHfvZNdOypOZmUnPnj2TXQ2pw9TGJBHUziQR1M4kEZLVzpxz08yse6RzSevpM7OVzrklzrl9zGwucCIwO7D1AYYE9h8mq45V8sorzHj3XXokux7lKCqCAQOgeXP44ANoX2sH04qIiIiISCTJXpz9OmCkc64R8DtwBX6e4VvOuX7AYuD8JNav8ho2JGfnnZNdi3I9/zx88w28/LICPhERERGRuiipQZ+ZzQAidUGemOCq7JCWLYPbb/eLsPfpk+zaiIiIiIhIPCR7nT5Jouuug7w8ePbZWpFrRkREREREKiHZwzslSd5/329DhsCeeya7NiIiIiIiEi/q6duBjBwJnTpBvXrw17/6tfluvjnZtRIRERERkXhS0LeDGDkSBg6ERYvAzGftXLMG3nor2TUTEREREZF4UtC3gxg8GLKzix/LyfHHRURERESk7lLQtwMw8wuuRxLtuIiIiIiI1A0K+uqY8Hl7nTrBfffBMcf4wC+S9PRE1k5ERERERBJNQV8dUnLe3qJFcM89MGsW9O8PKSnFn5+SAg88kJy6ioiIiIhIYijoq0MizdsDaNkSXngBnn8eMjL8mnwZGb7cu3fi6ykiIiIiIomjdfrqkGjz85Yu9fvevRXkiYiIiIjsaBT01QFmvtcuGs3bExERERHZcWl4Zy23di2cey5cdRUccAA0bVr8vObtiYiIiIjs2BT01TLh2TnT0mCPPeCTT+Dxx+Gnn/zcPc3bExERERGRIA3vrEWC2TmDyVpWr/bB3QMPwE03+WOatyciIiIiIuHU01eLRMrOaQbPPZec+oiIiIiISM2noK8WiZadM9pxERERERERBX21xLZt0Lhx5HPKzikiIiIiItEo6KsFcnPhL3+BnBxo1Kj4OWXnFBERERGRsiiRSw2Xlwfnnw+ffgrDhkGTJn5u3+LFvofvgQeUuEVERESkJsnPz2fp0qXk5OQkuyqSBC1btmTOnDlxu3+TJk3YddddadiwYYWvUdBXg+Xnw9/+BmPGwDPPQL9+/riCPBEREZGaa+nSpbRo0YJOnTrhnEt2dSTBtmzZQosWLeJybzNj3bp1LF26lM6dO1f4Og3vrGHC1+FLTYX33oMnn4Srr05yxURERESkQnJycmjTpo0CPql2zjnatGkTcy+yevpqkJLr8GVnQ8OG0LZtcuslIiIiIrFRwCfxUpm2pZ6+GiTSOnz5+f64iIiIiEhFbNy4kWeeeSbm68444ww2btxY/RWSpEtq0OecW+icm+mcm+Gcmxo4dq9zblng2Azn3BnJrGMiaR0+EREREamqaEFfYWFhmdd9/PHHpKamxqlWkkw1YXhnLzNbW+LYE2b2aFJqk0QdO8KyZaWPax0+EREREamoO+64gwULFtC1a1caNmxI8+bN6dChAzNmzGD27Nmcc845LFmyhJycHG644QYGDhwIQKdOnZg6dSpZWVmcfvrpHHPMMXz77bfssssufPjhhzRt2jTJ70wqqyYEfYJfmqFJk9LHtQ6fiIiISO11IzCjmu/ZFXiyjPNDhgxh1qxZzJgxg8zMTM4880xmzZq1PdvjSy+9ROvWrdm2bRuHHXYY5513Hm3atCl2j3nz5vHGG2/wwgsvcMEFF/Duu+9yySWXVPM7kURJ9pw+A8Y556Y55waGHb/WOfezc+4l51yrZFUuke64AxYsgOuvh4wMcM7vn39eSzSIiIiISOUdfvjhxdL7P/XUUxx88MH06NGDJUuWMG/evFLXdO7cma5duwLQrVs3Fi5cmKDaSjwku6fvaDNb7pxrD3zunPsVGArcjw8I7wceA/qWvDAQJA4ESEtLIzMzM2GVrqisrKwK1WvixLY88cSB/OUvSzn33Pmce27x8zXwrUkNUtF2JlJZamOSCGpnkgiJamctW7Zky5YtgP8yGw9byjiXlZVFUVERW7ZsITs7m8aNG2+vz6RJk/jss88YN24cKSkpnHHGGaxfv54tW7ZgZmRlZZGVlUXDhg23X1NQUMDWrVu3l6VshYWFcf+scnJyYmrLSQ36zGx5YL/aOfc+cLiZTQyed869AIyNcu3zwPMA3bt3t549e8a/wjHKzMykvHotWACPPQaHHw5vvLErjRrtmpjKSZ1RkXYmUhVqY5IIameSCIlqZ3PmzInb4twV0aFDB7Zu3UqLFi1ISUmhQYMG2+uTn59P27ZtSUtL49dff+WHH34gJSWFFi1a4JyjefPmANSrV2/7NY0bNyY/Pz+p76k2iefi7EFNmjThkEMOqfDzkxb0OeeaAfXMbEvg8SnAfc65Dma2IvC0c4FZyapjvOXkwPnnQ/368Oab0KhRsmskIiIiIrVdmzZtOProoznwwANp2rQpaWlp28+ddtppPPvssxx00EHss88+9OjRI4k1lURJZk9fGvB+YHHBBsDrZvapc+4151xX/PDOhcCVSathnIwc6dfeW7TIl//xD+jUKalVEhEREZE65PXXX494vHHjxnzyyScRzwXn7bVt25ZZs0L9Lrfccku1108SK2lBn5n9Dhwc4filSahOwowcCQMHFl+EfehQOOQQJWwREREREZHql+zsnTucwYOLB3zgy4MHJ6c+IiIiIiJStynoS7DFi2M7LiIiIiIiUhUK+hIsPT224yIiIiIiIlWhoC/B7o+wWEtKCjzwQOLrIiIiIiIidZ+CvgQLZuls2xacg4wMeP55JXEREREREZH4UNCXYGPHQsOGflH2oiJYuFABn4iIiIhUn40bN/LMM89U6tonn3yS7JJZB6XWU9CXYGPGwPHHw047JbsmIiIiIlITjBzpR4PVq+f3I0dW7X4K+qSkZC7OvsNZsADmzIEr69xy8yIiIiJSGSXXcF60yJeh8qPB7rjjDhYsWEDXrl05+eSTad++PW+99Ra5ubmce+65/Otf/2Lr1q1ccMEFLF26lMLCQu666y5WrVrF8uXL6dWrF23btmXChAnV8yYl6RT0JdDYsX5/1lnJrYeIiIiIJMaNN8KMGdHPT54MubnFj2VnQ79+8MILka/p2hWefDL6PYcMGcKsWbOYMWMG48aN45133uH777/HzPjzn//MxIkTWbNmDR07duSjjz4CYNOmTbRs2ZLHH3+cCRMm0LZt2xjepdR0Gt6ZQGPHwn77wR57JLsmIiIiIlITlAz4yjseq3HjxjFu3DgOOeQQDj30UH799VfmzZtHly5d+OKLL7j99tuZNGkSLVu2rJ4XlBpJPX0JsnkzfPWV/2uPiIiIiOwYyuqRAz+Hb9Gi0sczMiAzs+qvb2YMGjSIKyPML5o2bRoff/wxgwYN4pRTTuHuu++u+gtKjaSevgQZNw7y8+FPf0p2TURERESkpnjgAb9mc7iqruHcokULtmzZAsCpp57KSy+9RFZWFgDLli1j9erVLF++nJSUFC655BJuueUWfvzxx1LXSt2hnr4EGTsWWrWCI49Mdk1EREREpKYIJmsZPBgWL4b0dB/wVWVJrzZt2nD00Udz4IEHcvrpp3PxxRdzZOBLaPPmzRkxYgTz58/n1ltvpV69ejRs2JChQ4cCMHDgQE4//XQ6dOigRC51iIK+BCgshI8+gjPOgAb6xEVEREQkTO/e1b9u8+uvv16sfMMNNxQr77HHHpx66qmlrrvuuuu47rrrqrcyknQa3pkA338Pa9cqa6eIiIiIiCSegr4EGDMG6teH005Ldk1ERERERGRHo6AvAcaOhWOPhdTUZNdERERERER2NAr64mzRIpg5U0M7RUREREQkORT0xdnYsX6vpRpERERERCQZFPTF2dixsNdesPfeya6JiIiIiIjsiBT0xdG2bfX58kv18omIiIhI4mzcuJFnnnmm0tc/+eSTZGdnx3TNpEmTOOCAA+jatSvbtm2r9GvH4owzzmDjxo1xuffUqVO5/vrr43LvZFDQF0fTprUiL0/z+UREREQkcZIR9I0cOZJbbrmFGTNm0LRp05hfs7CwMOZrPv74Y1LjlCmxe/fuPPXUU3G5dzIo6Iujb79tQ8uWcMwxya6JiIiIiOwo7rjjDhYsWEDXrl259dZbAXjkkUc47LDDOOigg7jnnnsA2Lp1K2eeeSYHH3wwBx54IG+++SZPPfUUy5cvp1evXvTq1avUvcePH88hhxxCly5d6Nu3L7m5uQwbNoy33nqL++67j94lVplfuHAh++67L3369OGggw7ir3/96/aAslOnTtx3330cc8wxvP3224wbN44jjzySQw89lPPPP5+srCw++eQTLrjggu33y8zM5E+BYXSdOnVi7dq1ADz++OMceOCBHHjggTz55JPbX/vAAw/cfu2jjz7KvffeC8BTTz3F/vvvz0EHHcRFF11U6n1mZmZyVqDn5t5776VPnz6ccsopdOrUiffee4/bbruNLl26cNppp5Gfnw/Afffdx2GHHcYRRxzBwIEDMTMAfvjhBw466CCOPPJIbr311u11Kiws5NZbb93+7/Lcc88BsGLFCo477ji6du3KgQceyKRJkyr0714WBX1xMHIkZGTAJ5/sTH4+vPVWsmskIiIiIknTsye88op/nJ/vyyNG+HJ2ti+/+aYvb9rky++958tr1/rymDG+vHJluS83ZMgQ9thjD2bMmMEjjzzCuHHjmDdvHt9//z0zZsxg2rRpTJw4kU8//ZSOHTvy008/MWvWLE477TSuv/56OnbsyIQJE5gwYUKx++bk5HD55Zfz5ptvMnPmTAoKChg6dCj9+/fnz3/+M4888ggjR44sVZ+5c+cycOBAfv75Z3baaadivZBNmjTh66+/5qSTTuLf//43X3zxBT/++CPdu3fn8ccf5+STT2by5Mls3boVgDfffJMLL7yw2P2nTZvGyy+/zJQpU5g8eTIvvPAC06dPL/czmj59Oj///DPPPvtsuZ/pggUL+Oijj/jwww+55JJL6NWrFzNnzqRp06Z89NFHAFx77bX88MMPTJkyhW3btjE2kNHxiiuu4Nlnn+W7776jfv362+/54osv0rJlS3744Qd++OEHXnjhBf744w9ef/11Tj31VGbMmMFPP/1E165dy61feZIa9DnnFjrnZjrnZjjnpgaOtXbOfe6cmxfYt0pmHWM1ciQMHAiLFwM4srN9OUL7FxERERGJu3HjxjFu3DgOOeQQDj30UH799VfmzZtHly5d+OKLL7j99tuZNGkSLVu2LPM+c+fOpXPnzuwdyFDYp08fJk6cWO7r77bbbhx99NEAXHLJJXz99dfbzwUDuMmTJzN79myOPvpounbtyvDhw1m0aBENGjTgtNNOY8yYMRQUFPDRRx9x9tlnF7v/119/zbnnnkuzZs1o3rw5f/nLX8rtHTvooIPo3bs3I0aMoEGDBuW+h9NPP52GDRvSpUsXCgsLOe200wDo0qULCxcuBGDChAkcccQR9OjRgy+//JJffvmFjRs3smXLFo466igALr744u33HDduHK+++ipdu3bliCOOYN26dcybN4/DDjuMl19+mXvvvZeZM2fSokWLcutXnvLfYfz1MrO1YeU7gPFmNsQ5d0egfHtyqha7wYP9H2zCZWf74yV6u0VERERkR5CZGXrcsGHxckpK8XLLlsXLbdsWL++8c8wvb2YMGjSIK6+8stS5adOm8fHHHzNo0CBOOeUU7r777jLvUxnOuajlZs2abb/3ySefzBtvvFHq+gsvvJD//e9/tG7dmsMOO6xUEBStXg0aNKCoqGh7OScnZ/vjjz76iIkTJzJ69Gjuv/9+fvnllzKDv8aNGwNQr149GjZsuP091KtXj4KCAnJycvj73//O1KlTSU1N5bHHHiMnJ6fMz8zM+O9//8upp55a6tzEiRP56KOPuPTSS7n11lu57LLLot6nImri8M6zgeGBx8OBc5JXldj5Hr6KHxcRERERqU4tWrRgy5Yt28unnnoqL730EllZWQAsW7aM1atXs3z5clJSUrjkkku45ZZb+PHHHyNeH7TvvvuycOFC5s+fD8Brr73G8ccfX259Fi9ezHfffQfAG2+8wTEREl706NGDb775Zvu9s7Oz+e233wDo2bMnP/74Iy+88EKpoZ0Axx13HB988AHZ2dls3bqV999/n2OPPZa0tDRWr17NunXryM3N3T7csqioiCVLltCrVy8efvhhNm7cuP2zqaxgQNm2bVuysrJ45513AGjVqhUtWrRg8uTJAIwaNWr7NaeeeipDhw7dPifwt99+Y+vWrSxatIj27dszYMAA+vXrt/3fpSqS3dNnwDjnnAHPmdnzQJqZrQAwsxXOufZJrWGM0tNh0aLIx0VERERE4q1NmzYcffTRHHjggZx++uk88sgjzJkzhyOPPBKA5s2bM2LECObPn8+tt966vfdq6NChAAwcOJDTTz+dDh06FJvX16RJE15++WXOP/98CgoKOOyww7jqqqvKrc9+++3H8OHDufLKK9lrr724+uqrSz2nXbt2vPLKK/ztb38jNzcXgH//+9/svffe1K9fn7POOotXXnmF4cOHl7r20EMP5fLLL+fwww8HoH///hxyyCEA3H333RxxxBF07tyZfffdF/AJVC655BI2bdqEmXHTTTdVOQtoamoqAwYMoEuXLuy2224cdthh28+9+OKLDBgwgGbNmtGzZ8/tw2j79+/PwoULOfTQQzEz2rVrxwcffEBmZiaPPPIIDRs2pHnz5rz66qtVqhuAq2w3bXVwznU0s+WBwO5z4DpgtJmlhj1ng5mVmtfnnBsIDARIS0vrFh41J9MXX7Tn0Uf3ITc3NEmzceNCbrllLiedtDqJNZO6Kisri+bNmye7GlKHqY1JIqidSSIkqp21bNmSPffcM+6vUxssWrSICy64gClTpiS7KglTWFhYLGFLeLt7/PHHWblyJQ8//HCVXmP+/Pls2rSp2LFevXpNM7PukZ6f1J4+M1se2K92zr0PHA6scs51CPTydQAiRkqBXsHnAbp37249e/ZMUK3L1rMn7Lefn8O3eLGRnu544IH69O69P7B/sqsndVBmZiY1pf1L3aQ2JomgdiaJkKh2NmfOnGpJvlEXNG/enHr16u1Qn8eWLVuKvd+PP/6Yhx56iIKCAjIyMnjllVeq/Hk0adJke29mRSQt6HPONQPqmdmWwONTgPuA0UAfYEhg/2Gy6lhZvXv7LTPzK/0CExEREZEdVqdOnZg1a1ayq5FUF154YcS5iImUzJ6+NOD9QOabBsDrZvapc+4H4C3nXD9gMXB+EusoIiIiIiJSqyUt6DOz34GDIxxfB5yY+BqJiIiIiFQPMyu1VIFIdahMTpaauGSDiIiIiEit1aRJE9atW1fpde1EojEz1q1bR5MmTWK6LtlLNoiIiIiI1Cm77rorS5cuZc2aNcmuiiRBTk5OzEFZLJo0acKuu+4a0zUK+kREREREqlHDhg3p3LlzsqshSZKZmRlTZs1E0PBOERERERGROkxBn4iIiIiISB2moE9ERERERKQOc3Uhq5Bzbg2wKNn1iKAtsDbZlZA6T+1M4k1tTBJB7UwSQe1MEiFZ7SzDzNpFOlEngr6ayjk31cy6J7seUrepnUm8qY1JIqidSSKonUki1MR2puGdIiIiIiIidZiCPhERERERkTpMQV98PZ/sCsgOQe1M4k1tTBJB7UwSQe1MEqHGtTPN6RMREREREanD1NMnIiIiIiJShynoiwPn3GnOubnOufnOuTuSXR+pG5xzuznnJjjn5jjnfnHO3RA43to597lzbl5g3yrZdZXazTlX3zk33Tk3NlBWG5Nq55xLdc6945z7NfBz7Ui1NalOzrmbAr8vZznn3nDONVEbk6pyzr3knFvtnJsVdixqu3LODQrEBHOdc6cmp9YK+qqdc64+8D/gdGB/4G/Ouf2TWyupIwqAf5jZfkAP4JpA27oDGG9mewHjA2WRqrgBmBNWVhuTePgP8KmZ7QscjG9zamtSLZxzuwDXA93N7ECgPnARamNSda8Ap5U4FrFdBb6nXQQcELjmmUCskHAK+qrf4cB8M/vdzPKAUcDZSa6T1AFmtsLMfgw83oL/grQLvn0NDzxtOHBOUioodYJzblfgTGBY2GG1MalWzrmdgOOAFwHMLM/MNqK2JtWrAdDUOdcASAGWozYmVWRmE4H1JQ5Ha1dnA6PMLNfM/gDm42OFhFPQV/12AZaElZcGjolUG+dcJ+AQYAqQZmYrwAeGQPskVk1qvyeB24CisGNqY1LddgfWAC8HhhIPc841Q21NqomZLQMeBRYDK4BNZjYOtTGJj2jtqsbEBQr6qp+LcEwpUqXaOOeaA+8CN5rZ5mTXR+oO59xZwGozm5bsukid1wA4FBhqZocAW9EwO6lGgTlVZwOdgY5AM+fcJcmtleyAakxcoKCv+i0Fdgsr74ofTiBSZc65hviAb6SZvRc4vMo51yFwvgOwOln1k1rvaODPzrmF+KHpJzjnRqA2JtVvKbDUzKYEyu/gg0C1NakuJwF/mNkaM8sH3gOOQm1M4iNau6oxcYGCvur3A7CXc66zc64RfvLm6CTXSeoA55zDz3+ZY2aPh50aDfQJPO4DfJjoukndYGaDzGxXM+uE/9n1pZldgtqYVDMzWwkscc7tEzh0IjAbtTWpPouBHs65lMDvzxPxc+HVxiQeorWr0cBFzrnGzrnOwF7A90monxZnjwfn3Bn4eTH1gZfM7IHk1kjqAufcMcAkYCah+VZ34uf1vQWk43/JnW9mJScYi8TEOdcTuMXMznLOtUFtTKqZc64rPmFQI+B34Ar8H6PV1qRaOOf+BVyIz349HegPNEdtTKrAOfcG0BNoC6wC7gE+IEq7cs4NBvri2+GNZvZJ4mutoE9ERERERKRO0/BOERERERGROkxBn4iIiIiISB2moE9ERERERKQOU9AnIiIiIiJShynoExERERERqcMU9ImIiIiIiCSBc26hc+6LeL+Ogj4REREREZE6TEGfiIiIiIhIHaagT0REREREpA5T0CciIiIiInWWcy7NOfesc26Zcy7POTffOTfIOVcvcL6Tc86cc/90zl0ZOJ/jnJvunDslwv12c86NcM6tCTzvJ+fc5RGe5wL3m+acy3bObXDOfe2cOzvCcw9zzn3jnNvmnFvinLs5wnPOc85Ncc5tcs5tDdRzaIU+AzOr0IclIiIiIiJSmzjn2gI/AE2A54HlwNHApcBzZnaVc64T8AfwE5AGPAPkAFcC6cAJZvZ12P2mA22A/wLLgAsC97zVzB4Ne+1nA/fIBD4C8oDDgC1m9vfAcxYGju8EvAb8DlwIHA+cZmafBZ53IvB54F7vAfnA7sDpZnZQuZ+Dgj4REREREamLnHPPAecBXcxsRdjxB4E7gH3xQdcfQAFwgJn9FnhOO2AeMMfMjgwcexT4B8UDsobAV8AhwK5mts45d1zg2CtAXwsLupxzLlgOBH0Z+ODt08CxxsBiYKKZnR849gTQF2htZoWxfg4a3ikiIiIiInWOc84B5wMfA/nOubbBDfgMcECvsEs+DgZ8AGa2BhgJ9HDOtQkcPguYFQz4As/LB57A9yaeGDh8fmA/2Er0spUsAwuDAV/gfC4wGd+TF7QRaAacHnhfMVHQJyIiIiIidVE7oBV+KOeaEltm4Dntw54/N8I9gsc6he3nRHje7MC+c2C/J7DezJZXoJ4LIxzbALQOKz8TeI0xwArn3BvOub8FehnL1aAiTxIREREREallgh1cbwLDojzn97DHkea9VbRXLfg8CytXdB5dtOGa21/bzNY45w4FTgBOA04BLgJudc4dY2bZZb2Agj4REREREamL1gCbgUZm9kW0JwUSuYCf31fS3oH9osB+YZTn7Rt2HvxcwFOdc7uY2bKKVzk6MysAxgU2nHNX43sAzweGl3WthneKiIiIiEidE0h48jbwZ+fcYSXPO+daBJKmBJ3hnNs77Hw74GJgipmtDRweA3Rxzp0c9rwGwI34jJ/B4PLtwP7fJefgVWZOXticwnDTA/vU8q5XT5+IiIiIiNRVg4CewCTn3IvAz0AL4ADgr0CXsOf+AnzlnPsfkItfbqE5cFvYc/4PP6zyA+dccMmG8wkt2bAewMwmOueGAf2BTs65Mfgsod2AbOCaGN/HMOdce2A8PrNnW+AqYCswuryLFfSJiIiIiEidFJgLdwTwT+BsYAA+E+Y84H5gJbBz4Onv4IeE3grshk/Y8iczmxh2v7XOuaOBh/ABXQt8spe+ZvZyiZcfCMwI7B/EB3u/AA9X4q2MAPoF6t8aWAt8B9xvZn+Ud7HW6RMRERERkR1W2OLsd5nZv5NcnbjQnD4REREREZE6TEGfiIiIiIhIHaagT0REREREpA7TnD4REREREZE6TD19IiIiIiIidZiCPhERERERkTpMQZ+IiIiIiEgdpqBPRERERESkDlPQJyIiIiIiUocp6BMREREREanD/h9P/nhT+W8tfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "curve_graph(parametr_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
